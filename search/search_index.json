{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"AI Notes","text":"<p>Concise notes on generative modeling\u2014diffusion models, flow matching / CNFs, and transformer-based architectures (ViT/DiT).</p>"},{"location":"index.html#posts","title":"Posts","text":"<ul> <li>Diffusion Models Intro</li> <li>Diffusion \u2014 Compare and Code</li> <li>Diffusion \u2014 Flow Matching</li> <li>Diffusion \u2014 Mathematics Foundation</li> <li>Diffusion \u2014 Interlude \u03b1 (1757)</li> <li>Diffusion \u2014 CFM and ELBO</li> <li>Transformer</li> <li>ViT and DiT</li> </ul>"},{"location":"posts/diffusion-models-intro.html","title":"Diffusion Models Intro","text":""},{"location":"posts/diffusion-models-intro.html#chapter-1-from-fluid-mechanics-to-the-manifold-hypothesis","title":"Chapter 1 \u2014 From fluid mechanics to the manifold hypothesis","text":"<p>This chapter stays in the Euclidean setting: states are vectors \\(x\\in\\mathbb{R}^D\\) and time is \\(t\\in[0,1]\\). We use \u201cfluid\u201d terminology only as the mathematics of transport: trajectories (ODEs), distribution evolution, and conservation laws.</p>"},{"location":"posts/diffusion-models-intro.html#11-continuous-normalizing-flows-cnfs","title":"1.1 Continuous Normalizing Flows (CNFs)","text":"<p>We begin from the Lagrangian (particle) view: model a velocity field and move samples by an ODE. The corresponding Eulerian (density) view will appear in Section 1.2.</p> <p>Let</p> \\[ v:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}^D,\\qquad (t,x)\\mapsto v(t,x) \\] <p>be a time-dependent vector field (velocity). We will work in the Euclidean data space \\(\\mathbb{R}^D\\), with data points \\(x=(x_1,\\dots,x_D)\\in\\mathbb{R}^D\\).</p> <p>Two fundamental objects in flow-based generative modeling are:</p> <ul> <li>a probability density path \\(p:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}_{\\ge 0}\\), written as \\(p_t(x):=p(t,x)\\), such that \\(\\int_{\\mathbb{R}^D} p_t(x)\\,dx=1\\) for every \\(t\\in[0,1]\\);</li> <li>a time-dependent vector field \\(v_t(\\cdot):=v(t,\\cdot)\\) that transports particles (and hence pushes densities forward).</li> </ul> <p>Given \\(v_t\\), define its flow map \\(\\phi_t:\\mathbb{R}^D\\to\\mathbb{R}^D\\) as the solution of the ODE</p> \\[ \\frac{d}{dt}\\phi_t(x)=v_t(\\phi_t(x)),\\tag{1} \\] <p>with initial condition</p> \\[ \\phi_0(x)=x.\\tag{2} \\] <p>Under standard regularity assumptions (e.g., \\(v_t\\) Lipschitz in \\(x\\) with suitable growth), \\(\\phi_t\\) is well-defined, and for each fixed \\(t\\) it is invertible (indeed a homeomorphism). If we further assume enough differentiability of \\(v\\) in \\(x\\) (e.g., \\(C^1\\) in \\(x\\)), then \\(\\phi_t\\) is (locally) a diffeomorphism. This is the continuous-time analog of composing many small invertible maps (normalizing flows).</p> <p>The defining modeling choice of a Continuous Normalizing Flow (CNF) (Chen et al., 2018) is to parameterize the vector field by a neural network \\(v_t(x;\\theta)\\). This induces a learnable family of flow maps \\(\\phi_t(\\cdot;\\theta)\\) via (1)\u2013(2).</p>"},{"location":"posts/diffusion-models-intro.html#push-forward-how-a-cnf-transports-densities","title":"Push-forward: how a CNF transports densities","text":"<p>Let \\(p_0\\) be a simple base density (e.g., \\(\\mathcal{N}(0,I)\\)) and define \\(X_t:=\\phi_t(X_0)\\) with \\(X_0\\sim p_0\\). The time-\\(t\\) density is the push-forward of \\(p_0\\) by \\(\\phi_t\\):</p> \\[ p_t = (\\phi_t)_\\# p_0.\\tag{3} \\] <p>When \\(\\phi_t\\) is a diffeomorphism, the push-forward has the familiar change-of-variables form:</p> \\[ (\\phi_t)_\\# p_0(x) = p_0(\\phi_t^{-1}(x))\\; \\Big|\\det\\frac{\\partial \\phi_t^{-1}}{\\partial x}(x)\\Big|.\\tag{4} \\] <p>Equivalently, \\(p_0(x)=p_t(\\phi_t(x))\\big|\\det(\\partial_x\\phi_t(x))\\big|\\).</p> <p>We say that a vector field \\(v_t\\) generates a density path \\((p_t)\\) if its flow \\(\\phi_t\\) satisfies (3). One practical way to check whether a candidate \\((p_t,v_t)\\) is consistent is the continuity equation, which we introduce next.</p> <p>For the full classical fluid-mechanics PDE system (beyond this kinematic ODE viewpoint), see Interlude \\(\\alpha\\) \u2014 Year 1757.</p> <p>For a more detailed treatment of first-order ODEs and the viewpoint of an ODE with a random initial condition (random initial value problem) \\(\\mathbf{X}_t=\\phi_t(\\mathbf{X}_0)\\), see Mathematics Foundation.</p>"},{"location":"posts/diffusion-models-intro.html#12-density-conservation-eulerian-view-the-continuity-equation","title":"1.2 Density conservation (Eulerian view): the continuity equation","text":"<p>Switch from particles to distributions. Let \\(\\mu_t\\) be the law of a random variable \\(\\mathbf{x}_t\\in\\mathbb{R}^D\\). If \\(\\mu_t\\) admits a density \\(p_t\\) with respect to Lebesgue measure, we write \\(\\mu_t(dx)=p_t(x)\\,dx\\).</p> <p>The conservation-of-mass statement for transport by the vector field \\(v_t\\) is the continuity equation</p> \\[ \\partial_t p_t(x) + \\nabla\\!\\cdot\\big(p_t(x)\\,v(t,x)\\big)=0, \\qquad x\\in\\mathbb{R}^D,\\; t\\in[0,1]. \\] <p>Interpretation: probability mass is neither created nor destroyed; it is only moved by the vector field \\(v\\).</p> <p>Two equivalent \u201cbookkeeping\u201d forms (assuming enough smoothness) are useful:</p> <p>1) Along trajectories (material derivative). If \\(x(t)\\) solves \\(\\dot x(t)=v(t,x(t))\\), then</p> \\[ \\frac{d}{dt}p_t(x(t)) \\;=\\; \\partial_t p_t(x(t)) + \\nabla p_t(x(t))\\cdot v(t,x(t)) \\;=\\; -\\,p_t(x(t))\\,\\nabla\\!\\cdot v(t,x(t)). \\] <p>So regions with positive divergence expand and lower density; negative divergence compress and raise density.</p> <p>2) Jacobian form (volume-element conservation). If the flow map \\(\\phi_{s\\to t}\\) is differentiable in \\(a\\) and \\(J_{s\\to t}(a):=\\det(\\nabla_a\\phi_{s\\to t}(a))\\), then</p> \\[ p_t(\\phi_{s\\to t}(a))\\,J_{s\\to t}(a)=p_s(a). \\] <p>This is the precise version of \u201cmass in a moving infinitesimal volume element is conserved\u201d.</p> <p>Here \\(\\phi_{s\\to t}\\) denotes the flow map generated by \\(v\\) from time \\(s\\) to time \\(t\\).</p> <p>Remark: in measure-theoretic terms, transport by the flow map means \\(\\mu_t=(\\phi_{s\\to t})_\\#\\mu_s\\). The PDE above is the density-level expression of this push-forward relation.</p>"},{"location":"posts/diffusion-models-intro.html#13-the-manifold-hypothesis-a-precise-formulation","title":"1.3 The manifold hypothesis (a precise formulation)","text":"<p>Let \\(\\mu_\\text{data}\\) be the data distribution on \\(\\mathbb{R}^D\\) (a probability measure; it may or may not have a density).</p> <p>An idealized, mathematically clean version of the manifold hypothesis is:</p> <ul> <li>There exists a \\(d\\)-dimensional embedded \\(C^1\\) submanifold \\(\\mathcal{M}\\subset\\mathbb{R}^D\\) with \\(d\\ll D\\) such that</li> </ul> \\[ \\mathrm{supp}(\\mu_\\text{data}) \\subseteq \\mathcal{M}. \\] <p>A more realistic (noise-thickened) version is:</p> <ul> <li>There exists \\(\\sigma&gt;0\\) such that most mass lies in a tubular neighborhood of \\(\\mathcal{M}\\):</li> </ul> \\[ \\mu_\\text{data}\\big(\\{x\\in\\mathbb{R}^D:\\mathrm{dist}(x,\\mathcal{M})\\le \\sigma\\}\\big)\\ge 1-\\varepsilon, \\] <p>for a small \\(\\varepsilon\\in[0,1)\\).</p> <p>Important technical point: if \\(\\mathrm{supp}(\\mu_\\text{data})\\subseteq\\mathcal{M}\\) with \\(d&lt;D\\), then \\(\\mu_\\text{data}\\) is typically singular with respect to Lebesgue measure on \\(\\mathbb{R}^D\\); in particular, an ambient-space density \\(p_\\text{data}(x)\\) may not exist.</p>"},{"location":"posts/diffusion-models-intro.html#14-how-flow-models-relate-to-but-do-not-equal-manifold-learning","title":"1.4 How flow models relate to (but do not equal) manifold learning","text":"<p>A (continuous-time) flow model in \\(\\mathbb{R}^D\\) typically chooses a base distribution \\(\\mu_1\\) (often \\(\\mathcal{N}(0,I)\\)) and a diffeomorphic map \\(\\psi_{1\\to 0}\\) (generated by an ODE), then defines the model distribution by push-forward:</p> \\[ \\mu_\\theta := (\\psi_{1\\to 0})_\\# \\mu_1. \\] <p>This connects to the manifold hypothesis in a specific way:</p> <ul> <li>A diffeomorphism \\(\\psi_{1\\to 0}:\\mathbb{R}^D\\to\\mathbb{R}^D\\) maps absolutely continuous measures to absolutely continuous measures. Therefore, starting from \\(\\mu_1\\) with a smooth, full-dimensional density (e.g., Gaussian), an invertible flow model cannot represent an exactly low-dimensional, manifold-supported \\(\\mu_\\text{data}\\) in the idealized sense above.</li> <li>What a flow can do is concentrate mass near low-dimensional structure (a thin neighborhood of \\(\\mathcal{M}\\)) while remaining a full-dimensional density in \\(\\mathbb{R}^D\\). This is a transport statement, not an explicit reconstruction of \\(\\mathcal{M}\\) (no charts/atlas are learned).</li> </ul> <p>This is one reason diffusion-style constructions add noise along a path: intermediate distributions become \u201cthickened\u201d and typically admit well-behaved ambient densities, making training and reverse-time generation well-posed.</p>"},{"location":"posts/diffusion-models-intro.html#141-how-the-manifold-viewpoint-helps-and-what-diffusion-is-actually-doing","title":"1.4.1 How the manifold viewpoint helps, and what diffusion is actually doing","text":"<p>In image generation, a \u201cmanifold\u201d is typically a shorthand for the empirical observation that natural images occupy a very thin subset of \\(\\mathbb{R}^D\\): most variability can be explained by far fewer degrees of freedom than \\(D=H\\times W\\times C\\). In an idealized form, one writes \\(\\mathrm{supp}(\\mu_\\text{data})\\subseteq\\mathcal{M}\\) for a low-dimensional \\(\\mathcal{M}\\subset\\mathbb{R}^D\\); in a realistic form, \\(\\mu_\\text{data}\\) concentrates in a small neighborhood of \\(\\mathcal{M}\\).</p> <p>The manifold viewpoint clarifies why diffusion adds noise. If data are extremely \u201cthin\u201d (close to a low-dimensional set), then objects like an ambient-space density \\(p_\\text{data}(x)\\) or an ambient score \\(\\nabla_x\\log p_\\text{data}(x)\\) may be ill-behaved or not even well-defined. Diffusion constructs a Gaussian-perturbation path (schematically \\(x_t=\\alpha(t)x_0+\\sigma(t)\\epsilon\\)), which \u201cthickens\u201d the distribution so that for \\(t&gt;0\\) the marginal \\(p_t\\) is typically a regular, full-dimensional density on \\(\\mathbb{R}^D\\). The learned score/velocity field then tells you how to move samples from noise back toward the high-density region near the data, but it does not explicitly recover a geometric object \\(\\mathcal{M}\\) (no charts, projections, or tangent structure are output).</p>"},{"location":"posts/diffusion-models-intro.html#142-what-kinds-of-image-generative-models-are-manifold-learning","title":"1.4.2 What kinds of image generative models are manifold learning?","text":"<p>Models are closer to \u201cmanifold learning\u201d when they explicitly posit (and learn) a low-dimensional parameterization of images, i.e., a map \\(g:\\mathbb{R}^d\\to\\mathbb{R}^D\\) with \\(d\\ll D\\) such that typical images satisfy \\(x\\approx g(z)\\).</p> <ul> <li>Autoencoders (AE/DAE) and VAEs: learn an encoder/decoder pair and a low-dimensional latent \\(z\\). This makes the \u201cdata live near a low-dimensional set\u201d idea explicit (though VAEs add stochasticity and optimize a likelihood bound rather than directly estimating \\(\\mathcal{M}\\)).</li> <li>GANs / implicit generative models: a generator \\(x=g_\\theta(z)\\) with \\(z\\in\\mathbb{R}^d\\) defines (in the idealized deterministic case) a distribution supported on a \\(d\\)-dimensional set \\(\\mathrm{Im}(g_\\theta)\\). This is geometrically close to learning a manifold-like image set, even if the learned set is only approximate and the notion of \u201cmanifold\u201d may fail globally.</li> <li>Latent generative models (e.g., latent diffusion): learn a low-dimensional representation via an autoencoder, then run diffusion (or another density model) in latent space. This is often a practical middle ground: \u201cmanifold-like\u201d structure is delegated to the autoencoder, while diffusion handles distribution modeling in the latent.</li> </ul> <p>In particular, a VAE makes the low-dimensional structure explicit via a latent variable \\(z\\in\\mathbb{R}^d\\) (with \\(d\\ll D\\)) and a decoder distribution \\(p_\\theta(x\\mid z)\\) on \\(x\\in\\mathbb{R}^D\\). With a prior \\(p(z)\\) (often \\(\\mathcal{N}(0,I_d)\\)) and an encoder \\(q_\\phi(z\\mid x)\\), it is trained by maximizing the ELBO:</p> \\[ \\log p_\\theta(x) \\;\\ge\\; \\mathbb{E}_{z\\sim q_\\phi(z\\mid x)}\\big[\\log p_\\theta(x\\mid z)\\big] -\\mathrm{KL}\\big(q_\\phi(z\\mid x)\\,\\|\\,p(z)\\big). \\] <p>Geometrically, the mean decoder map \\(g_\\theta(z):=\\mathbb{E}[x\\mid z]\\) can be viewed as a learned low-dimensional \u201csurface\u201d, while the decoder noise determines how thick the model distribution is around that surface; this is why VAEs feel \u201cmanifold-flavored\u201d but are not necessarily learning a strict manifold-supported distribution in \\(\\mathbb{R}^D\\).</p> <p>These approaches make the low-dimensional structure explicit via \\(z\\mapsto x\\). By contrast, standard diffusion/score/flow-matching methods (as used in image generation) are usually framed as learning dynamics in the ambient Euclidean space \\(\\mathbb{R}^D\\) (or in a learned latent space), rather than directly estimating the manifold \\(\\mathcal{M}\\) itself.</p>"},{"location":"posts/diffusion-models-intro.html#15-bridge-to-the-rest-of-the-intro","title":"1.5 Bridge to the rest of the intro","text":"<p>We will reuse the same transport backbone:</p> <ul> <li>Choose a probability path \\((\\mu_t)_{t\\in[0,1]}\\) (or densities \\((p_t)\\) when they exist).</li> <li>Learn dynamics (ODE or SDE) that generate that path.</li> <li>Sample by numerically integrating the learned dynamics backward from a simple endpoint distribution.</li> </ul>"},{"location":"posts/diffusion-models-intro.html#chapter-2-flow-matching","title":"Chapter 2 \u2014 Flow Matching","text":"<p>Before introducing flow matching, it is helpful to recall what a CNF gives us \u201cin closed form\u201d (as an operator), and what remains expensive in practice.</p> <p>Consider a CNF defined by the ODE</p> \\[ \\frac{d}{dt}X_t = v(t,X_t;\\theta),\\qquad t\\in[0,1],\\qquad X_0\\sim p_0. \\] <p>Even when the solution is not available analytically, it always admits the integral form</p> \\[ X_t = X_0 + \\int_0^t v(s,X_s;\\theta)\\,ds, \\] <p>which is what numerical ODE solvers approximate.</p> <p>If the flow map \\(\\phi_t\\) is a diffeomorphism and the density \\(p_t\\) exists, then along trajectories \\(t\\mapsto X_t\\) the log-density obeys the instantaneous change-of-variables formula</p> \\[ \\frac{d}{dt}\\log p_t(X_t) = -\\,\\nabla\\!\\cdot v(t,X_t;\\theta), \\] <p>hence</p> \\[ \\log p_1(X_1)=\\log p_0(X_0)-\\int_0^1 \\nabla\\!\\cdot v(t,X_t;\\theta)\\,dt. \\] <p>This provides a principled likelihood bookkeeping rule for CNFs, but it is often computationally heavy in high dimension because it couples an ODE solve with repeated divergence (trace) evaluations.</p> <p>Flow matching takes the complementary Eulerian density-evolution viewpoint from Section 1.2: rather than training the model primarily through likelihood computation, we specify (or construct) a target probability path \\((p_t)\\) and train a vector field \\(v(t,x;\\theta)\\) so that its induced density evolution matches that path (via the continuity equation).</p>"},{"location":"posts/diffusion-models-intro.html#21-constructing-p_tu_t-from-conditional-probability-paths-and-vector-fields","title":"2.1 CONSTRUCTING \\(p_t,u_t\\) FROM CONDITIONAL PROBABILITY PATHS AND VECTOR FIELDS","text":"<p>Let \\(X_1\\sim q(x_1)\\) denote the (unknown) data distribution; we only have sample access to \\(q\\). We would like a probability path \\((p_t)_{t\\in[0,1]}\\) such that \\(p_0=p\\) is simple (e.g., \\(\\mathcal{N}(0,I)\\)) and \\(p_1\\approx q\\), together with a vector field \\(u_t\\) that generates this path (so that \\((p_t,u_t)\\) satisfy the continuity equation).</p> <p>The main difficulty is not that CNFs are \u201cincalculable\u201d, but that the marginal objects \\(p_t\\) and \\(u_t\\) are generally not available in closed form, so na\u00efvely we cannot (i) sample \\(x\\sim p_t(x)\\) for arbitrary \\(t\\), nor (ii) evaluate \\(u_t(x)\\) to supervise a neural vector field.</p> <p>A key idea in flow matching is to construct the marginal path and vector field by mixing conditional paths that are defined per data sample.</p> <p>Theorem 1 (marginalizing conditional paths and vector fields). Fix a family of conditional probability paths \\(\\{p_t(\\cdot\\mid x_1)\\}_{x_1}\\) such that</p> <ul> <li>\\(p_0(x\\mid x_1)=p(x)\\) for all \\(x_1\\), and</li> <li>\\(p_1(x\\mid x_1)\\) is concentrated around \\(x_1\\) (e.g., \\(p_1(x\\mid x_1)=\\mathcal{N}(x\\mid x_1,\\sigma^2 I)\\) for a small \\(\\sigma&gt;0\\)).</li> </ul> <p>Define the marginal (mixture) path</p> \\[ p_t(x)=\\int_{\\mathbb{R}^D} p_t(x\\mid x_1)\\,q(x_1)\\,dx_1.\\tag{6} \\] <p>In particular,</p> \\[ p_1(x)=\\int_{\\mathbb{R}^D} p_1(x\\mid x_1)\\,q(x_1)\\,dx_1 \\approx q(x).\\tag{7} \\] <p>Assume \\(p_t(x)&gt;0\\) for all \\(t\\in[0,1]\\) and \\(x\\in\\mathbb{R}^D\\). Let \\(u_t(x\\mid x_1)\\) be conditional vector fields that generate the conditional paths \\(p_t(\\cdot\\mid x_1)\\). Define the marginal vector field</p> \\[ u_t(x)=\\int_{\\mathbb{R}^D} u_t(x\\mid x_1)\\,\\frac{p_t(x\\mid x_1)\\,q(x_1)}{p_t(x)}\\,dx_1.\\tag{8} \\] <p>Then the pair \\((p_t,u_t)\\) satisfies the continuity equation. (As the paper emphasizes: \u201cthe marginal vector field ... generates the marginal probability path\u201d.)</p> <p>Explanation (what this buys us). Theorem 1 gives a mathematically clean bridge between:</p> <ul> <li>a per-sample design \\(\\big(p_t(\\cdot\\mid x_1),u_t(\\cdot\\mid x_1)\\big)\\), where \\(x_1\\sim q\\) is available from the dataset, and</li> <li>a global (marginal) density path \\(p_t\\) and its generator \\(u_t\\), which are guaranteed to be consistent through the continuity equation.</li> </ul> <p>This resolves the practical bottleneck in the marginal formulation: we do not need closed-form access to \\(p_t\\) or \\(u_t\\). Instead, we can sample \\(x_1\\sim q\\), sample \\(x\\sim p_t(\\cdot\\mid x_1)\\), and compute \\(u_t(x\\mid x_1)\\) to build a tractable training objective (developed next via conditional flow matching).</p> <p>In words: since for each fixed \\(x_1\\) the conditional pair \\(\\big(p_t(\\cdot\\mid x_1),u_t(\\cdot\\mid x_1)\\big)\\) satisfies the conditional continuity equation, Theorem 1 shows that the induced marginal pair \\((p_t,u_t)\\) (via the mixture constructions (6)\u2013(8)) satisfies the marginal continuity equation as well.</p> <p>The proof of Theorem 1 can be found in the appendix of Flow Matching for Generative Modeling (see References). For an additional exposition, see introduction-B-flow-matching.</p>"},{"location":"posts/diffusion-models-intro.html#22-conditional-flow-matching","title":"2.2 CONDITIONAL FLOW MATCHING","text":"<p>Operationally, CFM makes training possible by working with per-sample training pairs: sample \\(x_1\\sim q\\), sample \\(x\\sim p_t(\\cdot\\mid x_1)\\), compute the conditional target \\(u_t(x\\mid x_1)\\), and regress \\(v(t,x;\\theta)\\) toward it.</p> <p>The mixture constructions (6)\u2013(8) show that a marginal path \\(p_t\\) and a marginal vector field \\(u_t\\) exist and satisfy the continuity equation. However, because \\(q\\) is only accessible through samples, the integrals in (6)\u2013(8) are typically intractable. In particular, we cannot na\u00efvely compute \\(u_t(x)\\), so we cannot directly build an unbiased estimator of the marginal flow-matching regression loss</p> \\[ \\mathcal{L}_{\\mathrm{FM}}(\\theta) := \\mathbb{E}_{t\\sim U[0,1],\\,x\\sim p_t}\\Big[\\|v(t,x;\\theta)-u_t(x)\\|^2\\Big].\\tag{5} \\] <p>Instead, conditional flow matching replaces the marginal target \\(u_t(x)\\) by the per-sample conditional target \\(u_t(x\\mid x_1)\\), yielding the CFM objective</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) := \\mathbb{E}_{t\\sim U[0,1],\\,x_1\\sim q,\\,x\\sim p_t(\\cdot\\mid x_1)} \\Big[\\|v(t,x;\\theta)-u_t(x\\mid x_1)\\|^2\\Big].\\tag{9} \\] <p>This objective is tractable as long as we can (i) sample \\(x\\sim p_t(\\cdot\\mid x_1)\\) and (ii) evaluate \\(u_t(x\\mid x_1)\\), both of which can be arranged by design since they are defined on a per-sample basis.</p> <p>Theorem 2 (FM and CFM are equivalent up to a constant). Assume \\(p_t(x)&gt;0\\) for all \\(x\\in\\mathbb{R}^D\\) and \\(t\\in[0,1]\\), and that the constructions in (6)\u2013(8) are well-defined. Then</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta)=\\mathcal{L}_{\\mathrm{FM}}(\\theta)+C, \\] <p>where \\(C\\) does not depend on \\(\\theta\\). In particular,</p> \\[ \\nabla_\\theta \\mathcal{L}_{\\mathrm{FM}}(\\theta)=\\nabla_\\theta \\mathcal{L}_{\\mathrm{CFM}}(\\theta). \\] <p>Explanation (why the gradients match). Intuitively, (8) says that the marginal target is a posterior average: \\(u_t(x)=\\mathbb{E}[u_t(x\\mid X_1)\\mid X_t=x]\\). Expanding the square and applying the law of total expectation shows that the only difference between (5) and (9) is a conditional-variance term \\(\\mathbb{E}\\big[\\|u_t(X_t\\mid X_1)\\|^2-\\|u_t(X_t)\\|^2\\big]\\), which is independent of \\(\\theta\\). Therefore, optimizing the tractable conditional objective (9) is equivalent (in expectation) to optimizing the intractable marginal objective (5).</p> <p>The proof of Theorem 2 can be found in Flow Matching for Generative Modeling and in Flow Matching Guide and Code (see References). For an additional exposition, see introduction-B-flow-matching.</p>"},{"location":"posts/diffusion-models-intro.html#23-conditional-probability-paths-and-vector-fields","title":"2.3 CONDITIONAL PROBABILITY PATHS AND VECTOR FIELDS","text":"<p>The CFM objective is general: it works with any choice of conditional probability paths \\(p_t(\\cdot\\mid x_1)\\) and conditional vector fields \\(u_t(\\cdot\\mid x_1)\\) (as long as they are sampleable/evaluable). A particularly convenient family is given by Gaussian conditional paths, because both sampling and closed-form conditional targets can be obtained.</p>"},{"location":"posts/diffusion-models-intro.html#gaussian-conditional-paths","title":"Gaussian conditional paths","text":"<p>Fix \\(x_1\\in\\mathbb{R}^D\\). Consider a conditional probability path of the form</p> \\[ p_t(x\\mid x_1)=\\mathcal{N}\\!\\big(x\\mid \\mu_t(x_1),\\sigma_t(x_1)^2 I\\big),\\qquad t\\in[0,1],\\tag{10} \\] <p>where \\(\\mu:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}^D\\) is a time-dependent mean and \\(\\sigma:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}_{&gt;0}\\) is a time-dependent scalar standard deviation. We typically set</p> \\[ \\mu_0(x_1)=0,\\qquad \\sigma_0(x_1)=1, \\] <p>so that \\(p_0(x\\mid x_1)=\\mathcal{N}(0,I)=:p(x)\\) for all \\(x_1\\), and</p> \\[ \\mu_1(x_1)=x_1,\\qquad \\sigma_1(x_1)=\\sigma_{\\min}, \\] <p>so that \\(p_1(\\cdot\\mid x_1)\\) is concentrated near \\(x_1\\) when \\(\\sigma_{\\min}\\) is small.</p>"},{"location":"posts/diffusion-models-intro.html#a-canonical-conditional-flow-affine-map","title":"A canonical conditional flow (affine map)","text":"<p>Many vector fields can generate the same density path (e.g., one can add a component \\(w_t\\) such that \\(\\nabla\\!\\cdot(p_t w_t)=0\\)), but for Gaussian paths it is natural to choose the simplest canonical transport: an affine map that turns standard Gaussian noise into the desired Gaussian.</p> <p>Define the conditional (affine) flow map</p> \\[ \\psi_t(x_0;x_1):=\\sigma_t(x_1)\\,x_0+\\mu_t(x_1).\\tag{11} \\] <p>If \\(x_0\\sim \\mathcal{N}(0,I)\\), then \\(\\psi_t(x_0;x_1)\\sim \\mathcal{N}(\\mu_t(x_1),\\sigma_t(x_1)^2 I)\\). In push-forward notation,</p> \\[ (\\psi_t(\\cdot;x_1))_\\#\\,p(\\cdot)=p_t(\\cdot\\mid x_1).\\tag{12} \\] <p>This flow induces a conditional vector field \\(u_t(\\cdot\\mid x_1)\\) defined implicitly by</p> \\[ \\frac{d}{dt}\\psi_t(x_0;x_1)=u_t(\\psi_t(x_0;x_1)\\mid x_1).\\tag{13} \\] <p>Reparameterizing \\(x\\sim p_t(\\cdot\\mid x_1)\\) via \\(x=\\psi_t(x_0;x_1)\\) with \\(x_0\\sim p(x_0)=\\mathcal{N}(0,I)\\), the CFM objective (9) can be written as</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) = \\mathbb{E}_{t\\sim U[0,1],\\,x_1\\sim q,\\,x_0\\sim p} \\Big[\\big\\|v(t,\\psi_t(x_0;x_1);\\theta)-\\tfrac{d}{dt}\\psi_t(x_0;x_1)\\big\\|^2\\Big].\\tag{14} \\] <p>Theorem 3 (closed-form conditional vector field for Gaussian paths). Let \\(p_t(x\\mid x_1)\\) be the Gaussian conditional path in (10) and \\(\\psi_t(\\cdot;x_1)\\) be the affine flow map in (11). Then the (unique) vector field that realizes (13) is</p> \\[ u_t(x\\mid x_1) = \\frac{\\partial_t \\sigma_t(x_1)}{\\sigma_t(x_1)}\\big(x-\\mu_t(x_1)\\big) \\;+\\;\\partial_t\\mu_t(x_1).\\tag{15} \\] <p>Consequently, \\(u_t(\\cdot\\mid x_1)\\) generates the Gaussian path \\(p_t(\\cdot\\mid x_1)\\) (equivalently, \\((p_t(\\cdot\\mid x_1),u_t(\\cdot\\mid x_1))\\) satisfy the conditional continuity equation).</p> <p>Derivation (one line). Differentiate (11) in time: \\(\\frac{d}{dt}\\psi_t(x_0;x_1)=\\partial_t\\sigma_t(x_1)\\,x_0+\\partial_t\\mu_t(x_1)\\). Since \\(x=\\psi_t(x_0;x_1)=\\sigma_t(x_1)x_0+\\mu_t(x_1)\\), we have \\(x_0=(x-\\mu_t(x_1))/\\sigma_t(x_1)\\), which substituted back yields (15).</p> <p>The proofs and additional discussion can be found in Flow Matching for Generative Modeling and Flow Matching Guide and Code (see References).</p>"},{"location":"posts/diffusion-models-intro.html#24-examples-special-instances-of-gaussian-conditional-probability-paths","title":"2.4 Examples: special instances of Gaussian conditional probability paths","text":"<p>The Gaussian construction above is fully general: we may choose any differentiable \\(\\mu_t(x_1)\\) and \\(\\sigma_t(x_1)\\) satisfying desired boundary conditions and obtain a closed-form conditional target \\(u_t(x\\mid x_1)\\) via Theorem 3. Below are two illustrative design choices.</p>"},{"location":"posts/diffusion-models-intro.html#example-i-diffusion-inspired-conditional-paths-ve-vp","title":"Example I: diffusion-inspired conditional paths (VE / VP)","text":"<p>Many diffusion models induce Gaussian conditionals \\(p_t(x\\mid x_1)\\) at arbitrary times \\(t\\), with specific \\(\\mu_t(x_1)\\) and \\(\\sigma_t(x_1)\\). In the flow-matching setting, we can simply take these conditionals as a probability-path design choice and obtain a deterministic conditional vector field by plugging them into (15).</p> <p>(a) Reversed VE (noise \\(\\to\\) data). A variance-exploding (VE) conditional path can be written as</p> \\[ p_t(x\\mid x_1)=\\mathcal{N}\\!\\big(x\\mid x_1,\\sigma_{1-t}^2 I\\big),\\tag{16} \\] <p>where \\(\\sigma_s\\) is increasing with \\(\\sigma_0=0\\) and \\(\\sigma_1\\) large. Here \\(t=1\\) corresponds to a distribution concentrated at \\(x_1\\), while \\(t=0\\) is a very wide Gaussian (an approximation to \u201cnoise\u201d in practice). In this case \\(\\mu_t(x_1)=x_1\\) and \\(\\sigma_t(x_1)=\\sigma_{1-t}\\), so (15) gives</p> \\[ u_t(x\\mid x_1)= -\\frac{\\sigma'_{1-t}}{\\sigma_{1-t}}\\,(x-x_1),\\tag{17} \\] <p>where \\(\\sigma'_s=\\frac{d}{ds}\\sigma_s\\).</p> <p>(b) Reversed VP (noise \\(\\to\\) data). A variance-preserving (VP) conditional path can be written as</p> \\[ p_t(x\\mid x_1)=\\mathcal{N}\\!\\big(x\\mid \\alpha_{1-t}x_1,\\,(1-\\alpha_{1-t}^2)I\\big),\\tag{18} \\] <p>where</p> \\[ \\alpha_t := \\exp\\!\\Big(-\\frac12 T(t)\\Big),\\qquad T(t):=\\int_0^t \\beta(s)\\,ds, \\] <p>and \\(\\beta\\) is a nonnegative noise-rate schedule. When \\(T(1)\\) is large, \\(p_0(\\cdot\\mid x_1)\\approx \\mathcal{N}(0,I)\\) and \\(p_1(\\cdot\\mid x_1)\\) concentrates at \\(x_1\\). Here \\(\\mu_t(x_1)=\\alpha_{1-t}x_1\\) and \\(\\sigma_t(x_1)=\\sqrt{1-\\alpha_{1-t}^2}\\), and (15) yields</p> \\[ u_t(x\\mid x_1)=\\frac{\\alpha'_{1-t}}{1-\\alpha_{1-t}^2}\\big(\\alpha_{1-t}x-x_1\\big),\\tag{19} \\] <p>where \\(\\alpha'_s=\\frac{d}{ds}\\alpha_s\\). (Since \\(\\alpha\\) is decreasing when \\(\\beta&gt;0\\), \\(\\alpha'_s&lt;0\\), so the drift indeed points toward \\(x_1\\) as \\(t\\to 1\\).)</p> <p>Remark: these diffusion-inspired paths are typically derived from stochastic diffusion processes and may only approach an idealized \u201cpure noise\u201d distribution asymptotically; in practice one works with a finite terminal time and an approximate Gaussian endpoint.</p>"},{"location":"posts/diffusion-models-intro.html#example-ii-optimal-transport-inspired-conditional-paths-linear-meanstd","title":"Example II: optimal-transport-inspired conditional paths (linear mean/std)","text":"<p>An arguably simpler design is to let the mean and standard deviation evolve linearly in time:</p> \\[ \\mu_t(x_1)=t\\,x_1,\\qquad \\sigma_t(x_1)=1-(1-\\sigma_{\\min})t.\\tag{20} \\] <p>Plugging (20) into (15) gives the conditional vector field</p> \\[ u_t(x\\mid x_1)=\\frac{x_1-(1-\\sigma_{\\min})x}{1-(1-\\sigma_{\\min})t}.\\tag{21} \\] <p>The corresponding affine flow is</p> \\[ \\psi_t(x_0;x_1)=(1-(1-\\sigma_{\\min})t)x_0+t x_1.\\tag{22} \\] <p>In this case the CFM loss (14) becomes</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) = \\mathbb{E}_{t\\sim U[0,1],\\,x_1\\sim q,\\,x_0\\sim p} \\Big[\\big\\|v(t,\\psi_t(x_0;x_1);\\theta)-\\big(x_1-(1-\\sigma_{\\min})x_0\\big)\\big\\|^2\\Big].\\tag{23} \\] <p>Compared with diffusion-inspired choices, the OT-style conditional vector field often has a simpler structure (e.g., its direction can be constant in time up to a scalar factor), which can make the regression task easier.</p> <p>For practical experimental-design details (e.g., path/schedule choices, loss weighting, and numerical solvers), see introduction-B-flow-matching.</p>"},{"location":"posts/diffusion-models-intro.html#25-practical-notes-implementation-gotchas","title":"2.5 Practical notes (implementation \u201cgotchas\u201d)","text":"<p>This chapter intentionally focuses on the modeling algebra. In practice, a few design choices matter disproportionately:</p> <ul> <li>Endpoints and numerical stability. Many choices make \\(u_t(x\\mid x_1)\\) contain factors like \\(1/\\sigma_t(x_1)\\) or \\(1/(1-\\alpha_t^2)\\); avoid singular endpoints by using \\(\\sigma_{\\min}&gt;0\\), clipping \\(t\\) away from \\(\\{0,1\\}\\), or using a schedule that keeps denominators bounded.</li> <li>How to sample time \\(t\\). Uniform \\(t\\sim U[0,1]\\) is the default in the theory, but non-uniform sampling or explicit weights \\(w(t)\\) in the regression loss can improve conditioning (e.g., not over-emphasizing near-singular regions).</li> <li>Parameterization of the learned field. Even when the target is a conditional vector field, different parameterizations of \\(v(t,x;\\theta)\\) (predicting a velocity vs. predicting an equivalent noise-like quantity) can change optimization behavior while representing the same underlying solution.</li> <li>Choice of conditional path family. Diffusion-inspired vs. OT-inspired conditionals can change the geometry of trajectories (e.g., \u201cstraight\u201d vs. \u201cnoisy/curved\u201d conditionals), which changes the difficulty of the regression problem and the behavior of sampling.</li> <li>Sampling solver and error. Training uses exact conditional targets, but generation still integrates an ODE induced by the learned \\(v_\\theta\\); solver choice and step count (and whether to use adaptive stepping) can materially affect sample quality and speed.</li> </ul> <p>For a more hands-on discussion of these choices (including code-level details), see introduction-B-flow-matching.</p>"},{"location":"posts/diffusion-models-intro.html#chapter-3-diffusion-models-a-noising-path-and-a-learnable-reverse-process","title":"Chapter 3 \u2014 Diffusion models: a noising path and a learnable reverse process","text":"<p>In ODE-based flow models, the dynamics are deterministic: under standard regularity, the flow map is (locally) invertible and the Eulerian density evolution obeys the continuity equation. In diffusion models, the forward dynamics are stochastic (a Markov kernel rather than a bijection), so density evolution must account for diffusion and is governed by the Fokker\u2013Planck equation.</p> <p>The key design choice in diffusion models is to pick a probability path that connects data \\(\\mu_0=\\mu_\\text{data}\\) to a simple distribution \\(\\mu_1\\) (usually close to \\(\\mathcal{N}(0,I)\\)), by injecting Gaussian noise according to a schedule. This makes intermediate marginals \u201cthick\u201d (typically admitting nice ambient-space densities), and it gives a principled way to define a reverse-time generative dynamics.</p> <p>We present both the discrete-time (DDPM-style) and continuous-time (SDE-style) viewpoints. Detailed derivations about SDEs and the Fokker\u2013Planck equation are collected separately in Mathematics Foundation.</p>"},{"location":"posts/diffusion-models-intro.html#31-eulerian-view-density-evolution-by-fokkerplanck","title":"3.1 Eulerian view: density evolution by Fokker\u2013Planck","text":"<p>To mirror the Eulerian viewpoint of Section 1.2, we start from density evolution rather than from a discrete Markov chain.</p> <p>Let \\(t\\in[0,1]\\). Consider a forward It\u00f4 SDE</p> \\[ dX_t = f(X_t,t)\\,dt + g(t)\\,dW_t,\\qquad X_0\\sim \\mu_\\text{data}, \\] <p>where \\(W_t\\) is Brownian motion. If the time-\\(t\\) law \\(\\mu_t=\\mathcal{L}(X_t)\\) admits a density \\(\\mu_t(dx)=p_t(x)\\,dx\\), then \\(p_t\\) satisfies the Fokker\u2013Planck equation</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\big(f(x,t)p_t(x)\\big)+\\frac12 g(t)^2\\,\\Delta p_t(x). \\] <p>This is the stochastic analog of the continuity equation: the drift \\(f\\) transports mass (a CE-like term), while the Brownian noise adds a second-order diffusion term.</p> <p>The \u201cschedule\u201d viewpoint appears here as the choice of coefficients \\((f,g)\\), which determines the entire marginal path \\((p_t)\\). In diffusion modeling we choose \\((f,g)\\) so that \\(p_1\\) is simple (approximately \\(\\mathcal{N}(0,I)\\)) and \\(p_0\\) matches the data distribution.</p>"},{"location":"posts/diffusion-models-intro.html#32-reverse-time-generation-score-enters-the-dynamics","title":"3.2 Reverse-time generation: score enters the dynamics","text":"<p>The key generative fact is that the reverse-time dynamics involve the score \\(\\nabla_x\\log p_t(x)\\). Informally, if we run time backward from \\(t=1\\) to \\(t=0\\), the reverse-time SDE has the form (here written for the common case where \\(g(t)\\) is a scalar diffusion coefficient, i.e., isotropic noise depending only on time)</p> \\[ dX_t = \\Big(f(X_t,t)-g(t)^2\\,\\nabla_x\\log p_t(X_t)\\Big)\\,dt + g(t)\\,d\\bar W_t, \\qquad t:1\\to 0, \\] <p>where \\(\\bar W_t\\) is a Brownian motion in reverse time.</p> <p>For background on SDEs, It\u00f4 interpretation, and the Fokker\u2013Planck equation (including derivations), see Mathematics Foundation.</p> <p>There is also an associated probability flow ODE (deterministic dynamics with the same marginals \\((p_t)\\)):</p> \\[ \\frac{d}{dt}X_t = f(X_t,t)-\\frac12 g(t)^2\\,\\nabla_x\\log p_t(X_t). \\] <p>Once we can approximate the score, we can sample either by integrating the reverse SDE (stochastic sampler) or the probability flow ODE (deterministic sampler).</p>"},{"location":"posts/diffusion-models-intro.html#33-learning-the-score-why-training-is-tractable","title":"3.3 Learning the score (why training is tractable)","text":"<p>Even though the marginal density \\(p_t(x)\\) is unknown (and is generally difficult to model in closed form, regardless of whether it is introduced marginally or via conditional constructions), the forward diffusion/noising mechanism is known and sampleable by design. Concretely, we can draw \\(x_0\\sim q\\) from the dataset, sample noise \\(\\varepsilon\\), and generate \\(x_t\\sim p_t\\) by running the forward corruption process.</p> <p>This avoids the main intractability encountered in marginal flow matching: we do not need to evaluate a marginal vector field \\(u_t(x)\\) that involves posterior normalization by \\(p_t(x)\\). Instead, we obtain unbiased training pairs \\((t,x_t)\\) directly, and then fit a neural network \\(s_\\theta(x,t)\\approx \\nabla_x\\log p_t(x)\\) via denoising score matching objectives.</p>"},{"location":"posts/diffusion-models-intro.html#34-discrete-time-ddpm-as-a-practical-discretization","title":"3.4 Discrete-time DDPM as a practical discretization","text":"<p>After fixing the continuous-time (Eulerian) picture, we can introduce DDPM as a convenient discrete-time construction of the same \u201cdesign a noising path, learn a reverse process\u201d idea.</p> <p>Fix an integer \\(T\\). The forward process is a Markov chain</p> \\[ q(x_{0:T}) = q(x_0)\\prod_{k=1}^T q(x_k\\mid x_{k-1}), \\] <p>where \\(q(x_0)=\\mu_\\text{data}\\) and</p> \\[ q(x_k\\mid x_{k-1})=\\mathcal{N}\\!\\big(\\sqrt{1-\\beta_k}\\,x_{k-1},\\;\\beta_k I\\big), \\qquad k=1,\\dots,T, \\] <p>with noise schedule \\((\\beta_k)\\). Define \\(\\alpha_k:=1-\\beta_k\\) and \\(\\bar\\alpha_k:=\\prod_{s=1}^k \\alpha_s\\). Then</p> \\[ q(x_k\\mid x_0)=\\mathcal{N}\\!\\big(\\sqrt{\\bar\\alpha_k}\\,x_0,\\;(1-\\bar\\alpha_k)I\\big), \\] <p>equivalently</p> \\[ x_k=\\sqrt{\\bar\\alpha_k}\\,x_0+\\sqrt{1-\\bar\\alpha_k}\\,\\varepsilon,\\qquad \\varepsilon\\sim\\mathcal{N}(0,I). \\] <p>Generation runs the chain backward, sampling \\(p_\\theta(x_{k-1}\\mid x_k)\\). A common parameterization predicts \\(\\varepsilon_\\theta(x_k,k)\\), which can be converted to an estimate \\(\\hat x_0(x_k,k)\\) and hence to a reverse mean. The ELBO view and its reduction to a denoising regression loss are given in Chapter 4.</p>"},{"location":"posts/diffusion-models-intro.html#chapter-4-a-flow-first-physical-view-of-diffusion-with-ddpm-elbo-as-a-special-case","title":"Chapter 4 \u2014 A flow-first (physical) view of diffusion, with DDPM-ELBO as a special case","text":"<p>The \u201cphysical\u201d intuition is: diffusion models are stochastic flows of particles. We track particles by an SDE (Lagrangian view), and we track their law by a PDE (Eulerian view). The PDE is not an extra constraint we impose; it is the density-level consequence of the particle dynamics.</p>"},{"location":"posts/diffusion-models-intro.html#41-stochastic-flows-lagrangian-rightarrow-fokkerplanck-eulerian","title":"4.1 Stochastic flows (Lagrangian) \\(\\Rightarrow\\) Fokker\u2013Planck (Eulerian)","text":"<p>Consider the forward SDE on \\(\\mathbb{R}^D\\)</p> \\[ dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t,\\qquad t\\in[0,1],\\qquad X_0\\sim \\mu_\\text{data}. \\] <p>If the marginal law \\(\\mu_t=\\mathcal{L}(X_t)\\) admits a density \\(p_t\\) and regularity is sufficient, then \\(p_t\\) evolves by the Fokker\u2013Planck equation</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\big(f(x,t)p_t(x)\\big) + \\frac12 g(t)^2\\,\\Delta p_t(x). \\] <p>In other words, the SDE defines a stochastic flow of measures \\((\\mu_t)\\), and Fokker\u2013Planck is its Eulerian \u201cmass conservation + diffusion\u201d statement. (A step-by-step derivation is in Mathematics Foundation, Appendix B.)</p> <p>Reverse-time generation is another stochastic flow. To move probability mass from a simple \\(\\mu_1\\) back to \\(\\mu_0\\), we run a reverse-time dynamics whose drift depends on the score \\(\\nabla_x\\log p_t\\). This is the origin of \u201clearn the score/velocity field, then integrate backward\u201d.</p>"},{"location":"posts/diffusion-models-intro.html#42-the-vp-diffusion-as-a-canonical-forward-sde-a-continuous-scheduler","title":"4.2 The VP diffusion as a canonical forward SDE (a continuous scheduler)","text":"<p>A widely used forward process is the variance-preserving (VP) SDE, parameterized by a scalar noise-rate schedule \\(\\beta(t)\\ge 0\\):</p> \\[ dX_t = -\\frac12\\beta(t)\\,X_t\\,dt + \\sqrt{\\beta(t)}\\,dW_t. \\] <p>It is a linear SDE, and (conditionally on \\(X_0=x_0\\)) its marginal is Gaussian:</p> \\[ X_t = \\alpha(t)\\,x_0 + \\sigma(t)\\,\\varepsilon,\\qquad \\varepsilon\\sim\\mathcal{N}(0,I), \\] <p>for explicit \\(\\alpha(t)\\in(0,1]\\) and \\(\\sigma(t)\\ge 0\\) determined by \\(\\beta(t)\\). One common convention is</p> \\[ \\alpha(t)=\\exp\\!\\Big(-\\frac12\\int_0^t \\beta(s)\\,ds\\Big), \\qquad \\sigma(t)^2 = 1-\\alpha(t)^2, \\] <p>so that \\(X_t\\mid X_0=x_0\\sim \\mathcal{N}(\\alpha(t)x_0,\\sigma(t)^2 I)\\). This is the continuous-time analog of the discrete identity \\(x_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\varepsilon\\) from Chapter 3.</p>"},{"location":"posts/diffusion-models-intro.html#43-ddpm-as-a-time-discretization-of-a-stochastic-flow","title":"4.3 DDPM as a time discretization of a stochastic flow","text":"<p>DDPM\u2019s forward Markov chain</p> \\[ q(x_t\\mid x_{t-1})=\\mathcal{N}\\!\\big(\\sqrt{1-\\beta_t}\\,x_{t-1},\\;\\beta_t I\\big) \\] <p>can be viewed as a time discretization of a VP-type SDE (with a suitable mapping between \\(\\{\\beta_t\\}\\) and \\(\\beta(t)\\)). From the flow viewpoint:</p> <ul> <li>the schedule \\(\\{\\beta_t\\}\\) (or \\(\\beta(t)\\)) specifies how the stochastic flow gradually destroys information,</li> <li>the model learns a reverse-time flow that restores structure from noise.</li> </ul>"},{"location":"posts/diffusion-models-intro.html#44-elbo-for-ddpm-likelihood-as-stepwise-flow-matching-across-time","title":"4.4 ELBO for DDPM: likelihood as stepwise flow-matching across time","text":"<p>Let the learned reverse process be</p> \\[ p_\\theta(x_{0:T}) = p(x_T)\\prod_{t=1}^T p_\\theta(x_{t-1}\\mid x_t), \\qquad p(x_T)=\\mathcal{N}(0,I). \\] <p>Using the forward chain \\(q(x_{0:T})=q(x_0)\\prod_{t=1}^T q(x_t\\mid x_{t-1})\\) as a variational distribution over latents \\(x_{1:T}\\), we get a variational lower bound:</p> \\[ \\log p_\\theta(x_0) \\ge \\mathbb{E}_{q(x_{1:T}\\mid x_0)}\\big[\\log p_\\theta(x_{0:T})-\\log q(x_{1:T}\\mid x_0)\\big]. \\] <p>After algebra, this ELBO decomposes into KL terms at each step:</p> \\[ \\begin{aligned} \\log p_\\theta(x_0)\\;\\ge\\;&amp; \\mathbb{E}_q\\big[\\log p_\\theta(x_0\\mid x_1)\\big] -\\mathrm{KL}\\big(q(x_T\\mid x_0)\\,\\|\\,p(x_T)\\big) \\\\ &amp;-\\sum_{t=2}^T \\mathbb{E}_q\\Big[ \\mathrm{KL}\\big(q(x_{t-1}\\mid x_t,x_0)\\,\\|\\,p_\\theta(x_{t-1}\\mid x_t)\\big) \\Big]. \\end{aligned} \\] <p>Here \\(q(x_{t-1}\\mid x_t,x_0)\\) is the true reverse posterior induced by the forward Gaussian chain; it has a closed-form Gaussian expression, so these KL terms are tractable once \\(p_\\theta(x_{t-1}\\mid x_t)\\) is Gaussian.</p>"},{"location":"posts/diffusion-models-intro.html#45-the-usual-noise-prediction-loss-as-a-special-case-of-the-elbo","title":"4.5 The usual noise-prediction loss as a special case of the ELBO","text":"<p>In the common DDPM parameterization, one chooses \\(p_\\theta(x_{t-1}\\mid x_t)\\) to be Gaussian with a variance schedule fixed in advance, and a mean that is expressed via a network \\(\\varepsilon_\\theta(x_t,t)\\) (or equivalently \\(x_{0,\\theta}(x_t,t)\\)). Under this choice, each KL term above reduces (up to an additive constant and a time-dependent weight) to an \\(\\ell_2\\) regression loss:</p> \\[ \\mathbb{E}_{t,x_0,\\varepsilon}\\big[w(t)\\,\\|\\varepsilon-\\varepsilon_\\theta(x_t,t)\\|^2\\big]. \\] <p>So, on the flow axis, the \u201cdenoising MSE\u201d objective is one particular way of fitting a reverse-time stochastic flow so that it matches the forward flow\u2019s stepwise posteriors.</p> <p>Remark: the exact weight \\(w(t)\\) depends on the schedule \\(\\beta_t\\) and the variance parameterization in \\(p_\\theta(x_{t-1}\\mid x_t)\\); different \u201cpredict \\(\\varepsilon\\)\u201d vs \u201cpredict \\(x_0\\)\u201d parameterizations correspond to the same ELBO written in different coordinates.</p>"},{"location":"posts/diffusion-models-intro.html#chapter-5-flow-vs-diffusion-what-is-fundamentally-different","title":"Chapter 5 \u2014 Flow vs diffusion: what is fundamentally different?","text":"<p>Both flow models and diffusion models are \u201cdynamics-based\u201d generative models: they define a time-indexed family of random variables \\((X_t)\\) and use a learned field to transform a simple distribution into a complicated one. The crucial differences are in the type of dynamics, the mathematical object that evolves, and the training signal that is tractable.</p>"},{"location":"posts/diffusion-models-intro.html#51-deterministic-ode-flows-vs-stochastic-sde-flows","title":"5.1 Deterministic ODE flows vs stochastic SDE flows","text":"<ul> <li>Flow / CNF (ODE). A continuous normalizing flow evolves particles deterministically:</li> </ul> \\[ \\frac{d}{dt}X_t=v(t,X_t;\\theta). \\] <p>Under standard regularity (e.g., Lipschitz in \\(x\\)), the solution is unique and defines a (locally) invertible flow map \\(\\phi_{s\\to t}\\). Distribution evolution is push-forward: \\(\\mu_t=(\\phi_{0\\to t})_\\#\\mu_0\\).</p> <ul> <li>Diffusion (SDE). A diffusion model starts from a stochastic forward process:</li> </ul> \\[ dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t. \\] <p>Even with \\(X_0\\) fixed, \\(X_t\\) remains random because of Brownian noise. The evolution is therefore not a bijection \\(x_0\\mapsto x_t\\), but a Markov transition kernel \\(P_{s\\to t}(x,\\cdot)\\) acting on measures.</p>"},{"location":"posts/diffusion-models-intro.html#52-eulerian-density-evolution-continuity-equation-vs-fokkerplanck","title":"5.2 Eulerian density evolution: continuity equation vs Fokker\u2013Planck","text":"<ul> <li>ODE \\(\\Rightarrow\\) continuity equation (CE). If \\(X_t\\) follows an ODE and admits a density \\(p_t\\), then</li> </ul> \\[ \\partial_t p_t(x)+\\nabla\\!\\cdot\\big(p_t(x)\\,v(t,x)\\big)=0. \\] <p>This is pure transport: probability mass is conserved and advected by \\(v\\).</p> <ul> <li>SDE \\(\\Rightarrow\\) Fokker\u2013Planck. If \\(X_t\\) follows an It\u00f4 SDE and admits a density, then</li> </ul> \\[ \\partial_t p_t(x)=-\\nabla\\!\\cdot\\big(f(x,t)p_t(x)\\big)+\\frac12 g(t)^2\\,\\Delta p_t(x), \\] <p>which adds a second-order diffusion term. This difference is not cosmetic: the diffusion term reflects the fact that noise spreads mass and destroys invertibility.</p>"},{"location":"posts/diffusion-models-intro.html#53-what-is-designed-and-what-is-learned","title":"5.3 What is \u201cdesigned\u201d and what is \u201clearned\u201d","text":"<ul> <li> <p>Diffusion: the forward noising mechanism (equivalently \\((f,g)\\) or a discrete schedule) is designed so that we can generate samples \\(x_t\\sim p_t\\) from data \\(x_0\\sim q\\). The learned object is typically a score model \\(s_\\theta(x,t)\\approx \\nabla_x\\log p_t(x)\\) (or an equivalent parameterization such as \\(\\varepsilon_\\theta\\)).</p> </li> <li> <p>Flow / CNF: the learned object is directly a velocity field \\(v(t,x;\\theta)\\). A likelihood formula exists in principle via \\(\\frac{d}{dt}\\log p_t(X_t)=-\\nabla\\!\\cdot v(t,X_t;\\theta)\\), but it can be computationally heavy in high dimension.</p> </li> <li> <p>Flow matching: sits between the two viewpoints. It also learns an ODE velocity field \\(v(t,x;\\theta)\\), but it trains it using an Eulerian \u201cmatch a path\u201d idea (via CE), using conditional constructions to avoid intractable marginal objects.</p> </li> </ul>"},{"location":"posts/diffusion-models-intro.html#54-practical-consequence-why-training-looks-different","title":"5.4 Practical consequence: why training looks different","text":"<ul> <li> <p>In marginal flow matching, the marginal target \\(u_t(x)\\) is a posterior average and typically involves normalization by \\(p_t(x)\\), making it hard to compute with only sample access to \\(q\\). Conditional flow matching (CFM) resolves this by training on per-sample pairs \\((x,u_t(x\\mid x_1))\\) with \\(x_1\\sim q\\).</p> </li> <li> <p>In diffusion, we do not need to evaluate \\(p_t(x)\\) to generate training inputs: by design, the forward corruption mechanism provides unbiased samples \\(x_t\\sim p_t\\) together with supervision signals for denoising/score matching.</p> </li> </ul>"},{"location":"posts/diffusion-models-intro.html#55-relation-not-a-contradiction-probability-flow-ode","title":"5.5 Relation (not a contradiction): probability flow ODE","text":"<p>Although diffusion is fundamentally stochastic, the same marginal path \\((p_t)\\) can often be realized by a deterministic ODE (the probability flow ODE)</p> \\[ \\frac{d}{dt}X_t=f(X_t,t)-\\frac12 g(t)^2\\,\\nabla_x\\log p_t(X_t), \\] <p>which shares the same one-time marginals as the SDE when the score is exact. This provides a conceptual bridge: diffusion models can be sampled either stochastically (reverse SDE) or deterministically (PF-ODE), once \\(\\nabla_x\\log p_t\\) is learned.</p>"},{"location":"posts/diffusion-models-intro.html#references","title":"References","text":"<ol> <li>Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, David Duvenaud. Neural Ordinary Differential Equations. NeurIPS (2018). arXiv:1806.07366 (DOI: <code>https://doi.org/10.48550/arXiv.1806.07366</code>). <code>https://arxiv.org/abs/1806.07366</code></li> <li>Flow Matching (blog post). Cambridge Machine Learning Group (Jan 20, 2024). <code>https://mlg.eng.cam.ac.uk/blog/2024/01/20/flow-matching.html#mjx-eqn%3Aeq%3Ag2g</code></li> <li>Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, Matt Le. Flow Matching for Generative Modeling. arXiv:2210.02747 (DOI: <code>https://doi.org/10.48550/arXiv.2210.02747</code>). <code>https://arxiv.org/abs/2210.02747</code></li> <li>Lagrangian and Eulerian specification of the flow field. Wikipedia. <code>https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field</code></li> <li>Yaron Lipman, Marton Havasi, Peter Holderrieth, Neta Shaul, Matt Le, Brian Karrer, Ricky T. Q. Chen, David Lopez-Paz, Heli Ben-Hamu, Itai Gat. Flow Matching Guide and Code. arXiv:2412.06264 (DOI: <code>https://doi.org/10.48550/arXiv.2412.06264</code>). <code>https://arxiv.org/abs/2412.06264</code></li> <li>Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, Surya Ganguli. Deep Unsupervised Learning using Nonequilibrium Thermodynamics. ICML (2015). arXiv:1503.03585 (DOI: <code>https://doi.org/10.48550/arXiv.1503.03585</code>). <code>https://arxiv.org/abs/1503.03585</code></li> <li>Jonathan Ho, Ajay Jain, Pieter Abbeel. Denoising Diffusion Probabilistic Models. NeurIPS (2020). arXiv:2006.11239 (DOI: <code>https://doi.org/10.48550/arXiv.2006.11239</code>). <code>https://arxiv.org/abs/2006.11239</code></li> <li>Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole. Score-Based Generative Modeling through Stochastic Differential Equations. ICLR (2021). arXiv:2011.13456 (DOI: <code>https://doi.org/10.48550/arXiv.2011.13456</code>). <code>https://arxiv.org/abs/2011.13456</code></li> </ol>"},{"location":"posts/flow-bedrock.html","title":"Flow Bedrock","text":"<p>This note documents a small ODE-based simulator I built to develop intuition for flow models (continuous normalizing flows / flow matching) and their relationship to diffusion models (typically defined via SDEs).</p> <p>The simulator evolves many particles \\(x(t)\\in\\mathbb{R}^2\\) under a time-dependent velocity field \\(v(x,t)\\) by numerically integrating the ODE $$ \\frac{d x(t)}{d t} = v(x(t), t), \\qquad t\\in[0,1]. $$ It is primarily a visualization tool: trajectories and densities make the abstract objects in the math (vector fields, marginals \\(p_t\\), couplings between \\(p_0\\) and \\(p_1\\)) easier to reason about.</p> <p>GitHub: https://github.com/GDP-lab/flow_bedrock</p> <ul> <li>Particles as images. In the simulator, each particle is one sample \\(x\\) (think: one image in pixel/latent space). The animation is the evolution of a population of such samples under an ODE; nothing in the dynamics refers to human-interpretable \u201cparts\u201d of an image.</li> <li>Toy shapes as low-dimensional structure. The 2D targets (two moons, ring, S-curve, PS5-like outline) are deliberately chosen to concentrate probability mass near an approximately 1D set in \\(\\mathbb{R}^2\\). The PS5 example keeps a nonzero thickness to make sampling/visualization easier; conceptually it is still \u201cnear a curve\u201d rather than filling the plane.</li> <li>Analogy to real images. In high-dimensional image spaces, data are widely modeled as lying near a low-dimensional subset (informally, a \u201cdata manifold\u201d). Flow/diffusion training learns a vector field (or score/denoiser) that matches the statistics of that distribution; it does not need to explicitly represent what each image \u201ccontains\u201d.</li> <li>Text-to-image as conditioning. Text-to-image models learn a conditional distribution \\(p_{\\mathrm{data}}(x\\mid c)\\) where \\(c\\) is a text condition/embedding. Conditioning changes the target conditional density over image space (and hence the learned dynamics), which you can view as injecting language-level statistical information that reshapes where trajectories concentrate at \\(t=1\\).</li> </ul>"},{"location":"posts/flow-bedrock.html#1-flow-matching","title":"1. Flow Matching","text":""},{"location":"posts/flow-bedrock.html#11-hand-crafted-velocity-fields","title":"1.1 Hand-Crafted Velocity Fields","text":"<p>This section collects three hand-crafted velocity fields \\(v(x,t)\\) used in the simulator: <code>two_moons</code>, <code>ring</code>, and <code>s_curve</code>. In my implementation, all three live in the same file <code>handcrafted.py</code>.</p> <p>The system evolution is always the ODE $$ \\dot x(t) = v(x(t), t), \\qquad x(t)\\in\\mathbb{R}^2,\\ t\\in[0,1], $$ integrated numerically (e.g. RK4). The \u201cmanifold-like\u201d shapes in the particle cloud come from the structure of \\(v\\):</p> <ul> <li>a contracting (normal) component that pulls points toward some geometric set (a curve or a ring), and</li> <li>a tangential / drift component that moves points along that set (plus small time-varying or bending terms).</li> </ul> <p>The dispatcher is: <pre><code>def velocity_field(x: torch.Tensor, t: float, condition: str) -&gt; torch.Tensor:\n    if condition == \"two_moons\":\n        return _two_moons(x, t)\n    if condition == \"ring\":\n        return _ring(x, t)\n    if condition == \"s_curve\":\n        return _s_curve(x, t)\n    return _two_moons(x, t)\n</code></pre></p> <p>Below, I write \\(x=(x,y)\\in\\mathbb{R}^2\\) and use the 90\u00b0 rotation matrix $$ R = \\begin{pmatrix}0 &amp; -1\\ 1 &amp; 0\\end{pmatrix}, \\qquad R x = (-y, x). $$</p>"},{"location":"posts/flow-bedrock.html#two-moons-two_moons","title":"Two Moons (<code>two_moons</code>)","text":"<p>This field projects each point to the nearer of two fixed semicircular arcs (\u201cmoons\u201d), pulls it toward that arc, and adds a mild swirl to encourage motion along the arc.</p> <p>Mathematically, it is well-approximated by $$ v(x,t) \\;=\\; \\alpha\\bigl(P_{\\mathrm{moon}}(x)-x\\bigr) + \\beta(t)\\,R x, $$ where \\(P_{\\mathrm{moon}}(x)\\) is \u201cproject to the nearer moon arc\u201d (the code\u2019s <code>target</code>), \\(\\alpha=2.1\\), and $$ \\beta(t) = 0.18 + 0.05\\sin(2\\pi t). $$</p> <pre><code>def _two_moons(x: torch.Tensor, t: float) -&gt; torch.Tensor:\n    # Project points to canonical two-moons arcs and pull toward them.\n    theta1 = torch.atan2(x[:, 1], x[:, 0] + 1.0).clamp(0.0, math.pi)\n    moon1 = torch.stack((-1.0 + torch.cos(theta1), torch.sin(theta1)), dim=1)\n\n    theta2 = torch.atan2(-(x[:, 1] + 0.5), -(x[:, 0] - 1.0)).clamp(0.0, math.pi)\n    moon2 = torch.stack((1.0 - torch.cos(theta2), -torch.sin(theta2) - 0.5), dim=1)\n\n    d1 = torch.sum((x - moon1) ** 2, dim=1, keepdim=True)\n    d2 = torch.sum((x - moon2) ** 2, dim=1, keepdim=True)\n    target = torch.where(d1 &lt;= d2, moon1, moon2)\n\n    pull = (target - x) * 2.1\n    swirl = torch.stack((-x[:, 1], x[:, 0]), dim=1) * (0.18 + 0.05 * math.sin(2.0 * math.pi * t))\n    return pull + swirl\n</code></pre> <p>Why it yields two \u201cmoons\u201d: - <code>pull</code> is a strong normal contraction onto the arcs (two attraction basins, because of the nearest-arc selection). - <code>swirl</code> is tangential-ish motion that prevents purely radial collapse and helps spread mass along the arcs.</p>"},{"location":"posts/flow-bedrock.html#ring-ring","title":"Ring (<code>ring</code>)","text":"<p>This field stabilizes the radius around a (slightly time-varying) target radius and adds a strong tangential rotation.</p> <p>Let \\(r=\\|x\\|\\) and \\(r_0(t)=1.7+0.2\\sin(2\\pi t)\\). The vector field is $$ v(x,t) \\;=\\; 0.8\\,(r_0(t)-r)\\,\\frac{x}{r} \\;+\\; 1.5\\,R x. $$</p> <pre><code>def _ring(x: torch.Tensor, t: float) -&gt; torch.Tensor:\n    r = torch.linalg.norm(x, dim=1, keepdim=True).clamp_min(1e-4)\n    ring_r = 1.7 + 0.2 * math.sin(2.0 * math.pi * t)\n    radial = (ring_r - r) * (x / r) * 0.8\n    tangential = torch.stack((-x[:, 1], x[:, 0]), dim=1) * 1.5\n    return radial + tangential\n</code></pre> <p>Why it yields a ring: - the first term is radial negative feedback: if \\(r&lt;r_0(t)\\) it pushes outward; if \\(r&gt;r_0(t)\\) it pulls inward. - the second term is (approximately) tangential rotation, which preserves radius and circulates mass along the ring.</p>"},{"location":"posts/flow-bedrock.html#s-curve-s_curve","title":"S-Curve (<code>s_curve</code>)","text":"<p>This field contracts points vertically onto a target graph \\(y^\\*(x)=\\tanh(2.2x)\\), adds constant drift in \\(x\\), and adds a small vertical bending term.</p> <p>Writing \\(x=(x,y)\\), the field is $$ v(x,y) = \\Bigl(0.35,\\ 1.25\\bigl(\\tanh(2.2x)-y\\bigr) + 0.4\\sin(2.5x)\\Bigr). $$</p> <pre><code>def _s_curve(x: torch.Tensor, _t: float) -&gt; torch.Tensor:\n    target_y = torch.tanh(2.2 * x[:, 0])\n    to_curve = torch.stack((torch.zeros_like(target_y), target_y - x[:, 1]), dim=1) * 1.25\n    drift = torch.tensor([0.35, 0.0], device=x.device, dtype=x.dtype).expand_as(x)\n    bend = torch.stack((torch.zeros_like(x[:, 0]), torch.sin(2.5 * x[:, 0]) * 0.4), dim=1)\n    return to_curve + drift + bend\n</code></pre> <p>Why it yields an S-shaped \u201cmanifold\u201d: - <code>to_curve</code> is a normal contraction onto the graph \\(y=\\tanh(2.2x)\\). - <code>drift</code> moves particles forward in \\(x\\), so they traverse the curve rather than freezing in place. - <code>bend</code> adds a controlled thickness/shape variation in \\(y\\) as a function of \\(x\\).</p>"},{"location":"posts/flow-bedrock.html#why-these-produce-manifold-like-distributions","title":"Why these produce \u201cmanifold-like\u201d distributions","text":"<p>All three share the same pattern: attraction to a low-dimensional geometric set (a stable curve/ring) plus motion along that set. Under the ODE pushforward, an initial blob (e.g. a Gaussian) is rapidly compressed in the normal directions and stretched/transported tangentially, resulting in particle clouds that concentrate near a 1D shape in \\(\\mathbb{R}^2\\).</p>"},{"location":"posts/flow-bedrock.html#12-learned-velocity-fields","title":"1.2 Learned Velocity Fields","text":"<p>In the <code>flow_bedrock</code> codebase, the <code>learned</code> mode replaces the hand-crafted \\(v(x,t)\\) with a neural velocity field \\(v_\\theta(x,t)\\) and then runs the same ODE integrator. Concretely, the code is organized as:</p> <ul> <li>Model definition + inference wrapper: <code>learned.py</code></li> <li>Training script: <code>rf_two_moons.py</code></li> <li>Target distribution samplers: <code>target_distributions.py</code></li> <li>Simulator mode switch + ODE calls: <code>state.py</code></li> <li>ODE integrators (Euler/RK4): <code>ode.py</code></li> </ul>"},{"location":"posts/flow-bedrock.html#1-what-is-the-model","title":"1) What is the model?","text":"<p>In <code>learned.py</code>, the model <code>VelocityMLP</code> implements a map $$ v_\\theta:\\ \\mathbb{R}^2\\times[0,1)\\to\\mathbb{R}^2, \\qquad v_\\theta(x,t)=\\mathrm{MLP}_\\theta([x,y,t]). $$ At inference time, the scalar \\(t\\) is broadcast to shape \\([N,1]\\) to match a batch of \\(N\\) particles, and wrapped with \\(t\\mapsto t\\bmod 1\\) to keep it in \\([0,1)\\).</p>"},{"location":"posts/flow-bedrock.html#2-how-is-it-trained","title":"2) How is it trained?","text":"<p>The training in <code>rf_two_moons.py</code> is \u201cRF-style\u201d straight-line supervision:</p> <ul> <li>sample \\(x_0\\sim\\mathcal{N}(0,I)\\) (Gaussian source),</li> <li>sample \\(x_1\\sim p_{\\mathrm{data}}\\) using <code>target_distributions.py</code>,</li> <li>sample \\(t\\sim\\mathrm{Unif}[0,1]\\),</li> <li>define the bridge point \\(x_t=(1-t)x_0+t x_1\\),</li> <li>set the target velocity \\(v_{\\mathrm{target}} = x_1-x_0\\) (constant along the line).</li> </ul> <p></p> <p>The figure above shows what the target samples \\(x_1\\sim p_{\\mathrm{data}}\\) look like in practice (i.e. the distribution that the model is trained to transport to).</p> <p>Then \\(\\theta\\) is fit by mean-squared error $$ \\min_\\theta\\ \\mathbb{E}\\bigl[\\ |v_\\theta(x_t,t) - (x_1-x_0)|^2\\ \\bigr], $$ where the expectation is over the sampling procedure above.</p>"},{"location":"posts/flow-bedrock.html#3-how-is-the-checkpoint-loaded","title":"3) How is the checkpoint loaded?","text":"<p>The backend route <code>POST /model/load</code> in <code>app.py</code> dispatches into <code>state.py</code>, which calls the <code>LearnedField.load(...)</code> wrapper in <code>learned.py</code> to construct the MLP (with the saved hyperparameters such as width/depth), load the <code>state_dict</code>, and set <code>eval()</code> mode.</p>"},{"location":"posts/flow-bedrock.html#4-how-is-learned-used-in-the-simulator-loop","title":"4) How is <code>learned</code> used in the simulator loop?","text":"<p>Each simulation tick in <code>state.py</code> selects a velocity function based on the current <code>mode</code>. If <code>mode=learned</code> and a checkpoint has been loaded, it uses the learned field \\(v_\\theta(x,t)\\); otherwise it falls back to <code>handcrafted.py</code>. Either way, the state is advanced by the shared ODE integrators in <code>ode.py</code> by stepping $$ \\dot x(t) = v_\\theta(x(t), t) $$ with the chosen solver (Euler/RK4).</p>"},{"location":"posts/interlude-alpha-year-1757.html","title":"Interlude \\(\\alpha\\) \u2014 Year 1757","text":""},{"location":"posts/interlude-alpha-year-1757.html#alpha1-a-classical-fluid-mechanics-brief","title":"\\(\\alpha\\)1. A classical fluid-mechanics brief","text":"<p>Timeline and the world</p> <p>1) Calculus (late 1600s)</p> <p> </p> <p>2) Montesquieu and The Spirit of Laws (1748)</p> <p>https://en.wikipedia.org/wiki/The_Spirit_of_Laws</p> <p> </p> <p>3) Diderot, d\u2019Alembert, and the Encyclop\u00e9die (1751)</p> <p>https://en.wikipedia.org/wiki/Encyclop%C3%A9die</p> <p> </p> <p>4) Voltaire and the Lisbon earthquake (1755)   - Event: the 1755 Lisbon earthquake.   - Links: https://en.wikipedia.org/wiki/Voltaire | https://en.wikipedia.org/wiki/1755_Lisbon_earthquake</p> <p>5) Euler in Berlin (1755\u20131757)   - Why this is \u201cgenesis\u201d for fluid dynamics: fluids are treated as continuous fields, not discrete particles.   - Academic note: Euler formalizes \\(\\rho\\) (density) and \\(p\\) (pressure) as spatial fields and writes down the inviscid equations we still use today.   - Primary source: Euler, L. (1757). \u201cPrincipes g\u00e9n\u00e9raux du mouvement des fluides\u201d. M\u00e9moires de l'Acad\u00e9mie des Sciences de Berlin.   - https://en.wikipedia.org/wiki/Euler_equations_(fluid_dynamics)</p> <p></p> <p></p> <p>Close of this brief: the modern \u201cflow matching\u201d story is basically a machine-learning re-telling of classical transport, learn a time-dependent vector field, then integrate its trajectories. - Eulerian viewpoint: describe the whole medium by fields over space-time.   - State variables live on space-time: \\(\\rho(x,t)\\) (density), \\(v(x,t)\\) (velocity), and often \\(p(x,t)\\) (pressure) and/or \\(e(x,t)\\) (internal energy).   - Think \u201cfield snapshot\u201d: at any fixed \\(t\\), you can draw arrows \\(v(\\cdot,t)\\) and a scalar map \\(\\rho(\\cdot,t)\\). Motion is encoded by how those fields evolve in \\(t\\).   - The bridge to particle motion is the trajectory / characteristic \\(x(t)\\) that satisfies \\(\\dot x(t)=v(x(t),t)\\). Along that path, the rate of change of any field \\(f(x,t)\\) is the material derivative (Eq. (1)).</p> <ul> <li> <p>That single operator \\(D/Dt\\) is the conceptual hinge: Eulerian fields + Newtonian time evolution.</p> </li> <li> <p>Newton\u2019s laws as constraints (continuum mechanics viewpoint):</p> </li> <li>Setup: take any control volume \\(\\Omega\\) fixed in space with boundary \\(\\partial\\Omega\\) and outward normal \\(n\\). Newton\u2019s laws apply to the mass and momentum in that volume.</li> <li> <p>Mass conservation (Newton does not create/destroy mass): integral form (Eq. (2)), differential form (Eq. (3)).</p> </li> <li> <p>Momentum conservation (Newton\u2019s 2nd law, \\(F=ma\\)):</p> <p>Integral form (Eq. (4)).</p> <p>Here \\(b(x,t)\\) is body force per unit mass (e.g., gravity), and \\(\\sigma(x,t)\\) is the Cauchy stress tensor encoding surface forces.</p> </li> <li> <p>Newton\u2019s 3rd law (action = reaction) implies local balance of internal forces, which yields a symmetric stress tensor in the classical setting: \\(\\sigma=\\sigma^\\top\\).</p> </li> <li> <p>For an inviscid fluid (no shear stress), stress reduces to isotropic pressure: \\(\\sigma = -p I\\). Plugging this into the momentum balance yields the Euler equations:</p> <p>Differential form (Eq. (5)).</p> <p>The acceleration term \\(\\partial_t v + (v\\cdot\\nabla)v\\) is exactly \\(Dv/Dt\\): Newton\u2019s law written in Eulerian coordinates.   - Closure: mass + momentum are not enough; you typically need an equation of state \\(p=p(\\rho,\\ldots)\\) and/or an energy equation. (For many ML \u201cflow\u201d analogies we keep only the kinematic core: a vector field that transports density.)</p> </li> </ul> <p>Numbered equations:</p> <p>Material derivative</p> \\[ \\frac{D f}{D t} = \\partial_t f + v\\cdot\\nabla f. \\tag{1} \\] <p>Mass conservation (integral form)</p> \\[ \\frac{d}{dt}\\int_{\\Omega}\\rho\\,dx = -\\int_{\\partial\\Omega}\\rho v\\cdot n\\,dS. \\tag{2} \\] <p>Continuity equation (differential form)</p> \\[ \\partial_t \\rho + \\nabla\\cdot(\\rho v)=0. \\tag{3} \\] <p>Momentum balance (integral form)</p> \\[ \\frac{d}{dt}\\int_{\\Omega}\\rho v\\,dx = \\int_{\\Omega}\\rho b\\,dx + \\int_{\\partial\\Omega}\\sigma n\\,dS. \\tag{4} \\] <p>Euler equations (inviscid, differential form)</p> \\[ \\rho\\big(\\partial_t v + (v\\cdot\\nabla)v\\big) = -\\nabla p + \\rho b. \\tag{5} \\] <p>How flow models reuse this math (vs. what remains \u201cphysics constraints\u201d):</p> <ul> <li>What a flow model actually uses (kinematics / transport):</li> <li>A learned time-dependent vector field \\(v_\\theta(x,t)\\) defines an ODE \\(\\dot x(t)=v_\\theta(x(t),t)\\) (characteristics).</li> <li>Probability mass is transported by that field through the continuity / Liouville equation (Eq. (3)). This is the backbone behind CNFs and flow matching: it tells you how \\(\\rho(x,t)\\) changes when particles move with velocity \\(v\\).</li> <li>A commonly used derived identity along trajectories is the log-density evolution:<ul> <li>\\(\\frac{d}{dt}\\log \\rho(x(t),t) = -\\nabla\\cdot v(x(t),t)\\).</li> <li>This is just Eq. (3) rewritten on characteristics (and is where the \\(\\nabla\\cdot v\\) term in continuous normalizing flows comes from).</li> </ul> </li> <li> <p>Eq. (1) (material derivative) is often used as notation to make these \u201calong a trajectory\u201d statements compact, but it is not an extra assumption.</p> </li> <li> <p>What is mostly not enforced in ML flows (dynamics / constitutive physics):</p> </li> <li>Eq. (4) and Eq. (5) become relevant only if you want \\(v\\) to be physically correct for an actual fluid (pressure, stress, body forces, plus a closure / equation of state).</li> <li>In generative modeling, \\(v_\\theta\\) is typically free to be whatever field best transports \\(p_0\\to p_1\\); we do not solve for \\(p\\) or \\(\\sigma\\) and we do not impose Newtonian momentum balance unless we are doing physics-informed modeling.</li> </ul>"},{"location":"posts/introduction-B-flow-matching.html","title":"Section B \u2014 Flow Matching as the default protagonist","text":"<p>Thesis opener (to avoid confusion). Flow models borrow the mathematical language of classical transport/fluids (vector fields, continuity, trajectories). They are not claiming that \u201cimages behave like fluids\u201d in any physical sense. (for now...)</p> <ul> <li>Why it still matters for image generation:</li> <li>An image is just a point \\(x\\in\\mathbb{R}^d\\) (a very high-dimensional coordinate), and a dataset defines a distribution \\(p_\\text{data}(x)\\).</li> <li>Generative modeling can be phrased as moving probability mass from a simple base distribution to \\(p_\\text{data}\\).</li> <li>A time-dependent vector field \\(v_\\theta(x,t)\\) provides a deterministic \u201ctransport plan\u201d for that mass; sampling is integrating an ODE.</li> <li>Intuition is basically:</li> <li>If there exists a well-posed deterministic flow \\(\\psi_{0\\to 1}\\) (generated by an ODE) such that \\(p_\\text{data} = (\\psi_{0\\to 1})_\\# p_0\\), then generation can be done by ODE integration\u2014noise and SDEs are optional modeling/training choices, not a requirement. and the moving path is like the path of the missile.</li> <li>The connection to fluids is conceptual (transport/fields), not semantic (\u201cwater-like images\u201d).</li> <li>The payoff is a clean, classical, deterministic backbone; we add stochasticity later only when we choose to.</li> </ul>"},{"location":"posts/introduction-B-flow-matching.html#b0-section-goal","title":"B0. Section goal","text":"<ul> <li>Treat flow/ODE as the mainline</li> <li>Training = learn a vector field</li> <li>Sampling = numerical integration (Euler/Heun/RK)</li> </ul>"},{"location":"posts/introduction-B-flow-matching.html#interlude-alpha-year-1757","title":"Interlude \\(\\alpha\\) \u2014 Year 1757","text":"<ul> <li>interlude-alpha-year-1757.md</li> </ul>"},{"location":"posts/introduction-B-flow-matching.html#b1-flow-model","title":"B1. Flow Model","text":"<p>We define \\(\\mathbf{x}\\) as a random vector, i.e., a random variable taking values in \\(\\mathbb{R}^d\\). This narrows the scope of \u201crandom variable\u201d to the Euclidean setting, which is the convenient regime for the mathematical discussion that follows (e.g., addition, scalar multiplication, and density/flow-based transformations).</p> <p>In this post, we stick to this convention and represent our data (images) as vectors in \\(\\mathbb{R}^d\\). This is mainly a modeling choice rather than a conceptual departure: the intuition is the same as treating an image as a point in a high-dimensional space, which is standard in much of the generative modeling literature.</p> <p>A notation we will use frequently is the expectation. If \\(\\mathbf{x}\\) has density \\(p\\) on \\(\\mathbb{R}^d\\) and \\(f:\\mathbb{R}^d\\to\\mathbb{R}\\) is integrable, we define:</p> \\[ \\mathbb{E}\\big[f(\\mathbf{x})\\big] = \\int_{\\mathbb{R}^d} f(x)\\,p(x)\\,dx. \\tag{1} \\] <p>Another recurring object is the conditional expectation. A good engineering way to read \\(\\mathbb{E}[\\mathbf{x}\\mid \\mathbf{y}]\\) is: use \\(\\mathbf{y}\\) to predict \\(\\mathbf{x}\\), and choose the predictor that minimizes mean squared error. Concretely, given two \\(\\mathbb{R}^d\\)-valued random vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), define the best approximating function \\(g_\\star\\) in the least-squares sense:</p> \\[ g_\\star \\;:=\\; \\arg\\min_{g:\\mathbb{R}^d\\to\\mathbb{R}^d}\\; \\mathbb{E}\\big[\\lVert \\mathbf{x} - g(\\mathbf{y})\\rVert^2\\big]. \\tag{2} \\] <p>We will write densities without subscripts (e.g., \\(p(x,y)\\), \\(p(x\\mid y)\\), \\(p(y)\\)) when the meaning is clear from context. For \\(y\\in\\mathbb{R}^d\\) such that \\(p(y)&gt;0\\), the conditional expectation function is then:</p> \\[ \\mathbb{E}[\\mathbf{x}\\mid \\mathbf{y}=y] \\;:=\\; g_\\star(y) \\;=\\; \\int_{\\mathbb{R}^d} x\\,p(x\\mid y)\\,dx. \\tag{3} \\]"},{"location":"posts/introduction-B-flow-matching.html#b11-prerequisites-smoothness-lipschitzness-and-ode-order","title":"B1.1. Prerequisites: smoothness, Lipschitzness, and ODE order","text":"<p>Before we talk about diffeomorphisms and push-forward maps, it helps to keep three easy-to-mix concepts separate.</p> <ul> <li>Smoothness is a property of a function of \\(x\\) (e.g., \\(T(x)\\) or \\(u(x,t)\\)), not a property of \u201cthe space \\(\\mathbb{R}^d\\)\u201d. Not every function can be differentiated indefinitely (e.g., \\(|x|\\) is not differentiable at \\(x=0\\)). In many flow-model derivations we assume \\(C^1\\) regularity in \\(x\\) so that Jacobians / divergences are well-defined and change-of-variables statements are clean.</li> <li>Second-order dynamics can be rewritten as a first-order system by augmenting the state. For example, \\(\\ddot x(t)=a(x(t),\\dot x(t),t)\\) becomes a first-order system by introducing \\(w(t)=\\dot x(t)\\) and treating \\((x(t),w(t))\\) as the state.</li> </ul> <p>Finally, a regularity condition that shows up repeatedly for ODEs is local Lipschitzness (in \\(x\\)).</p> <p>A function \\(f:\\mathbb{R}^d\\to\\mathbb{R}^m\\) is locally Lipschitz if for every compact set \\(K\\subset\\mathbb{R}^d\\) there exists a constant \\(L_K&lt;\\infty\\) such that for all \\(x,x'\\in K\\), $$ \\lVert f(x)-f(x')\\rVert \\le L_K\\,\\lVert x-x'\\rVert. \\tag{4} $$</p> <p>Intuition: on any bounded region, \\(f\\) cannot change \u201ctoo fast\u201d. For ODEs \\(\\dot x=u(x,t)\\), local Lipschitzness of \\(u(\\cdot,t)\\) (together with mild conditions in \\(t\\)) is a standard way to guarantee well-posed trajectories (in particular, uniqueness).</p>"},{"location":"posts/introduction-B-flow-matching.html#b12-diffeomorphisms-and-push-forward-maps-definitions","title":"B1.2. Diffeomorphisms and push-forward maps (definitions)","text":"<p>At a high level, a (normalizing) flow model does two things:</p> <ol> <li>It applies a deterministic map \\(T\\) to points \\(x\\in\\mathbb{R}^d\\).</li> <li>It tracks how this map moves probability mass, i.e., how a distribution changes under \\(T\\).</li> </ol> <p>These are captured by two standard notions: diffeomorphisms (nice invertible maps) and push-forward maps (how a map acts on distributions).</p>"},{"location":"posts/introduction-B-flow-matching.html#diffeomorphism-a-nice-invertible-map","title":"Diffeomorphism (a \u201cnice\u201d invertible map)","text":"<p>Let \\(U,V\\subseteq\\mathbb{R}^d\\) be open sets. A map \\(T:U\\to V\\) is a \\(C^1\\)-diffeomorphism if it is bijective, continuously differentiable, and its inverse is also continuously differentiable:</p> \\[ T \\text{ is a \\(C^1\\)-diffeomorphism} \\quad\\Longleftrightarrow\\quad T \\text{ is bijective},\\; T\\in C^1(U),\\; T^{-1}\\in C^1(V). \\tag{5} \\] <p>Intuition: \\(T\\) can stretch / compress / warp space, but it does not tear it or fold distinct points onto the same point. In flow-based generative modeling, this \u201cinvertible and differentiable\u201d structure is what makes likelihood tracking possible.</p>"},{"location":"posts/introduction-B-flow-matching.html#push-forward-how-a-map-acts-on-distributions","title":"Push-forward (how a map acts on distributions)","text":"<p>Suppose \\(\\mathbf{x}\\) is a random vector on \\(\\mathbb{R}^d\\) with distribution \\(p\\), and we define a new random vector \\(\\mathbf{y}=T(\\mathbf{x})\\). The distribution of \\(\\mathbf{y}\\) is called the push-forward of \\(p\\) by \\(T\\), written \\(T_\\# p\\) (this is the \u201c\\(\\#\\)\u201d symbol you saw). Formally, for any measurable set \\(A\\subseteq\\mathbb{R}^d\\),</p> \\[ (T_\\# p)(A) \\;:=\\; p\\big(T^{-1}(A)\\big). \\tag{6} \\] <p>This definition says: \u201cthe probability that \\(\\mathbf{y}\\) lands in \\(A\\) equals the probability that \\(\\mathbf{x}\\) lands in the preimage \\(T^{-1}(A)\\).\u201d</p>"},{"location":"posts/introduction-B-flow-matching.html#if-densities-exist-change-of-variables","title":"If densities exist: change of variables","text":"<p>When \\(p\\) admits a density \\(p(x)\\) and \\(T\\) is a \\(C^1\\)-diffeomorphism, the push-forward distribution \\(q:=T_\\# p\\) also admits a density \\(q(y)\\) given by the change-of-variables formula:</p> \\[ q(y) \\;=\\; p\\big(T^{-1}(y)\\big)\\,\\left|\\det \\nabla T^{-1}(y)\\right|. \\tag{7} \\] <p>Equivalently, writing \\(y=T(x)\\),</p> \\[ q\\big(T(x)\\big)\\,\\left|\\det \\nabla T(x)\\right| \\;=\\; p(x). \\tag{8} \\] <p>This is the basic \u201cbookkeeping rule\u201d behind likelihood-based flows: a flow model specifies \\(T\\), samples via \\(\\mathbf{y}=T(\\mathbf{x})\\), and computes log-likelihoods by tracking the Jacobian determinant (or its continuous-time analogue).</p> <p>Interpretation (Of \u201c\\(\\#\\)\u201d ). The push-forward \\(T_\\# p\\) is a measure-theoretic notion: it describes how the entire probability distribution \\(p\\) changes when we transform samples by \\(T\\). In likelihood-based flow models, we typically choose a simple base distribution \\(p_0\\) and parameterize \\(T\\) (e.g., \\(T=T_\\theta\\)), so the model distribution is \\(q_\\theta := (T_\\theta)_\\# p_0\\). Training by maximum likelihood then adjusts \\(\\theta\\) so that \\(q_\\theta\\) assigns high likelihood to real data\u2014informally, it \u201cpushes\u201d the model distribution toward the data distribution.</p> <p>It is helpful to view this as two layers: push-forward is the modeling viewpoint (how a map \\(T\\) acts on distributions), while likelihood is one possible training objective for selecting parameters \\(\\theta\\) after choosing a parameterized family \\(T_\\theta\\). The push-forward construction itself does not require likelihood; the same viewpoint can be paired with other fitting criteria (e.g., adversarial objectives, moment matching, or flow/score matching).</p>"},{"location":"posts/introduction-B-flow-matching.html#b13-flows-and-velocity-fields","title":"B1.3. Flows and velocity fields","text":"<p>So far, we have discussed a single map \\(T\\). A flow generalizes this to a time-indexed family of maps \\(\\psi_t\\), generated by a time-dependent velocity field \\(u_t\\).</p> <p>A \\(C^r\\) flow \\(\\psi\\) can be defined in terms of a \\(C^r([0,1]\\times\\mathbb{R}^d,\\mathbb{R}^d)\\) velocity field \\(u:[0,1]\\times\\mathbb{R}^d\\to\\mathbb{R}^d\\), written as \\(u(t,x)=u_t(x)\\), via the following ODE:</p> \\[ \\frac{d}{dt}\\psi_t(x) = u_t\\big(\\psi_t(x)\\big). \\tag{9} \\] <p>with initial condition</p> \\[ \\psi_0(x)=x. \\tag{10} \\] <p>Intuition: at each time \\(t\\), the vector \\(u_t(x)\\) tells you which direction the point at location \\(x\\) should move next, and \\(\\psi_t(x)\\) is \u201cwhere \\(x\\) ends up\u201d after flowing for time \\(t\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#local-existence-uniqueness-and-when-psi_t-is-a-diffeomorphism","title":"Local existence, uniqueness, and when \\(\\psi_t\\) is a diffeomorphism","text":"<p>A standard result from ODE theory is: if \\(u\\) is \\(C^r\\) in \\((t,x)\\) with \\(r\\ge 1\\) (in particular, locally Lipschitz in \\(x\\)), then the ODE above has a unique local solution, and \\(\\psi_t(\\cdot)\\) is a \\(C^r\\) diffeomorphism on its domain of definition (for each fixed \\(t\\)). This guarantees local existence/uniqueness: solutions may still blow up in finite time unless we assume more (e.g., global Lipschitzness or other growth/integrability conditions). Later we will rely on conditions that guarantee the flow exists almost everywhere up to \\(t=1\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#flow-rightarrow-distribution-transport","title":"Flow \\(\\Rightarrow\\) distribution transport","text":"<p>If \\(\\mathbf{x}_0\\sim p_0\\) and \\(\\mathbf{x}_t := \\psi_t(\\mathbf{x}_0)\\), then the marginal distribution at time \\(t\\) is the push-forward</p> \\[ p_t \\;=\\; (\\psi_t)_\\# p_0. \\tag{11} \\] <p>When densities exist, this viewpoint leads directly to the continuity equation, which will serve as a backbone for both diffusion- and flow-based generative models.</p>"},{"location":"posts/introduction-B-flow-matching.html#flow-leftrightarrow-velocity-field","title":"Flow \\(\\Leftrightarrow\\) velocity field","text":"<p>Conversely, given a \\(C^1\\) flow \\(\\psi_t\\), one can recover its (unique) defining velocity field by using invertibility. Differentiating \\(\\psi_t(x')\\) and setting \\(x'=\\psi_t^{-1}(x)\\) gives</p> \\[ u_t(x) \\;=\\; \\frac{d}{dt}\\psi_t\\big(\\psi_t^{-1}(x)\\big). \\tag{12} \\] <p>In conclusion: (under suitable regularity) flows \\(\\psi_t\\) and velocity fields \\(u_t\\) are equivalent ways to represent the same deterministic transport. In ML we often parameterize \\(u_t\\) by a neural network (e.g., \\(u_t(x)\\approx v_\\theta(x,t)\\)).</p>"},{"location":"posts/introduction-B-flow-matching.html#b14-probability-paths-and-the-continuity-equation","title":"B1.4. Probability paths and the continuity equation","text":"<p>The flow viewpoint above (\\(\\mathbf{x}_t=\\psi_t(\\mathbf{x}_0)\\)) is a convenient sufficient way to generate a family of distributions \\((p_t)_{t\\in[0,1]}\\). However, it is not the most general way to think about \u201cmoving probability mass\u201d.</p>"},{"location":"posts/introduction-B-flow-matching.html#probability-path-a-time-indexed-family-of-distributions","title":"Probability path = a time-indexed family of distributions","text":"<p>A probability path is simply a family of distributions \\((p_t)_{t\\in[0,1]}\\) on \\(\\mathbb{R}^d\\) that interpolates between \\(p_0\\) and \\(p_1\\). You can view it as a \u201cmovie of densities\u201d.</p> <ul> <li>In the flow-induced case, \\(p_t=(\\psi_t)_\\# p_0\\) as in \\(\\tag{11}\\).</li> <li>More generally, one can specify \\((p_t)\\) without specifying a global deterministic map \\(\\psi_t\\) (e.g., stochastic dynamics, mixture paths, or paths defined via couplings).</li> </ul> <p>In Flow Matching, it is common to build a probability path by choosing a coupling \\(\\pi\\) between endpoints and an interpolation map \\(\\gamma_t\\):</p> <ul> <li>Sample \\((\\mathbf{x}_0,\\mathbf{x}_1)\\sim \\pi\\) where the marginals are \\(p_0\\) and \\(p_1\\).</li> <li>Define an interpolation \\(\\gamma_t:\\mathbb{R}^d\\times\\mathbb{R}^d\\to\\mathbb{R}^d\\), e.g., \\(\\gamma_t(x_0,x_1)=(1-t)x_0+t x_1\\).</li> <li>Let \\(\\mathbf{x}_t:=\\gamma_t(\\mathbf{x}_0,\\mathbf{x}_1)\\). Then \\(p_t\\) is the push-forward of \\(\\pi\\) under \\(\\gamma_t\\).</li> </ul> <p>This \u201cpath-first\u201d viewpoint is one reason Flow Matching can be presented without starting from a likelihood objective.</p>"},{"location":"posts/introduction-B-flow-matching.html#when-do-we-say-a-velocity-field-generates-a-probability-path","title":"When do we say a velocity field \u201cgenerates\u201d a probability path?","text":"<p>The guide makes a useful distinction: given an arbitrary probability path \\((p_t)\\), we say a velocity field \\(u_t\\) generates \\((p_t)\\) if, when we solve the flow ODE \\(\\frac{d}{dt}\\psi_t(x)=u_t(\\psi_t(x))\\) and set \\(\\mathbf{x}_t:=\\psi_t(\\mathbf{x}_0)\\) with \\(\\mathbf{x}_0\\sim p_0\\), the marginal law of \\(\\mathbf{x}_t\\) is exactly \\(p_t\\) for every \\(t\\in[0,1)\\).</p> <p>The interval is often written as \\([0,1)\\) (open on the right) to handle cases where the target \\(p_1\\) has compact support and the velocity field is not well-defined exactly at \\(t=1\\).</p> <p>Operationally: to check whether \\(u_t\\) generates a given \\((p_t)\\), you do not need to reason about particles \\(\\mathbf{x}_t\\) directly\u2014you can verify a PDE.</p>"},{"location":"posts/introduction-B-flow-matching.html#the-continuity-equation-conservation-of-probability","title":"The continuity equation (conservation of probability)","text":"<p>If a probability path \\((p_t)\\) is transported by a (sufficiently regular) velocity field \\(u_t\\), then \\(p_t\\) must satisfy the continuity equation</p> \\[ \\partial_t p_t(x) + \\nabla\\cdot\\big(p_t(x)\\,u_t(x)\\big)=0. \\tag{13} \\] <p>Interpretation: probability is neither created nor destroyed; it only moves with velocity \\(u_t\\).</p> <p>It is often convenient to name the probability flux</p> \\[ j_t(x) := p_t(x)\\,u_t(x), \\tag{13a} \\] <p>so \\(\\tag{13}\\) becomes \\(\\partial_t p_t + \\nabla\\cdot j_t=0\\).</p> <p>Where does \\(\\tag{13}\\) come from? It is the differential form of a conservation law. </p> \\[ \\frac{d}{dt}\\int_{\\Omega} p_t(x)\\,dx \\;=\\; -\\int_{\\partial\\Omega} p_t(x)\\,u_t(x)\\cdot n(x)\\,dS. \\tag{13b} \\] <p>(1) Notation note: \\(\\partial\\) is overloaded. The symbol \\(\\partial\\) is used in two different ways in this section:</p> <ul> <li>\\(\\partial_t p_t(x)\\) means a partial derivative with respect to time \\(t\\).</li> <li>\\(\\partial\\Omega\\) means the boundary of the region \\(\\Omega\\) (a geometric object), not a derivative.</li> </ul> <p>In \\(\\tag{13b}\\), \\(\\Omega\\subset\\mathbb{R}^d\\) is any fixed region, \\(\\partial\\Omega\\) is its boundary, \\(n(x)\\) is the outward unit normal on \\(\\partial\\Omega\\), and \\(dS\\) is the \\((d-1)\\)-dimensional surface-area element. The derivative \\(\\frac{d}{dt}\\int_{\\Omega} p_t(x)\\,dx\\) is taken with respect to time \\(t\\) (the set \\(\\Omega\\) is fixed); it measures how the total probability mass inside \\(\\Omega\\) changes over time.</p> <p>(2) The key equivalence is the divergence theorem. For a smooth vector field \\(F:\\mathbb{R}^d\\to\\mathbb{R}^d\\),</p> \\[ \\int_{\\Omega} \\nabla\\cdot F(x)\\,dx \\;=\\; \\int_{\\partial\\Omega} F(x)\\cdot n(x)\\,dS. \\tag{13c} \\] <p>This is the mathematical statement that connects \u201cwhat happens inside a volume\u201d to \u201cwhat flows through its boundary\u201d. Taking \\(F(x)=p_t(x)\\,u_t(x)\\) turns \\(\\tag{13c}\\) into \\(\\tag{13d}\\).</p> <p>Now the derivation is a sequence of standard \u201caccounting\u201d steps:</p> <p>1) Convert the boundary flux to a volume integral (divergence theorem):</p> \\[ \\int_{\\partial\\Omega} p_t(x)\\,u_t(x)\\cdot n(x)\\,dS \\;=\\; \\int_{\\Omega} \\nabla\\cdot\\big(p_t(x)\\,u_t(x)\\big)\\,dx. \\tag{13d} \\] <p>2) Move the time derivative inside the integral (for a fixed \\(\\Omega\\) and regular enough \\(p_t\\)):</p> \\[ \\frac{d}{dt}\\int_{\\Omega} p_t(x)\\,dx \\;=\\; \\int_{\\Omega}\\partial_t p_t(x)\\,dx. \\tag{13e} \\] <p>3) Combine the two to get an integral identity over \\(\\Omega\\):</p> \\[ \\int_{\\Omega}\\Big(\\partial_t p_t(x) + \\nabla\\cdot\\big(p_t(x)\\,u_t(x)\\big)\\Big)\\,dx = 0. \\tag{13f} \\] <p></p> <p>4) Localize: since \\(\\Omega\\) is arbitrary, the only way this integral can be zero for every region is that the integrand vanishes (almost everywhere), which yields \\(\\tag{13}\\).</p> <p>This is exactly the same derivation as in classical fluid mechanics, with \\(p_t\\) playing the role of density \\(\\rho\\) and \\(u_t\\) playing the role of velocity \\(v\\). The key difference is interpretational: in generative modeling, \\(u_t\\) is a learned transport field for probability mass, not a physically constrained fluid velocity (we do not impose momentum balance or an equation of state unless we explicitly do physics-informed modeling).</p> <p>Equivalently, rearranging \\(\\tag{13}\\), the continuity equation can be read as an explicit \u201cdensity update rule\u201d \\(\\partial_t p_t(x) = -\\nabla\\cdot\\big(p_t(x)\\,u_t(x)\\big)\\), which emphasizes that local density changes are fully determined by the divergence of the probability flux \\(p_t u_t\\) (not merely by \\(\\nabla\\cdot u_t\\)).</p>"},{"location":"posts/introduction-B-flow-matching.html#a-mass-conservation-equivalence-pde-leftrightarrow-generated-path","title":"A \u201cmass conservation\u201d equivalence (PDE \\(\\Leftrightarrow\\) generated path)","text":"<p>Under mild regularity assumptions (in the guide: \\(u_t\\) locally Lipschitz in \\(x\\) and an integrability condition), the following two statements are equivalent:</p> <p>1) The pair \\((p_t,u_t)\\) satisfies the continuity equation \\(\\tag{13}\\) for \\(t\\in[0,1)\\). 2) The velocity field \\(u_t\\) generates the probability path \\((p_t)\\) via the flow ODE (i.e., \\(\\mathbf{x}_t=\\psi_t(\\mathbf{x}_0)\\sim p_t\\)).</p> <p>The integrability condition can be written as a finite expected speed along the path:</p> \\[ \\int_0^1 \\int_{\\mathbb{R}^d} \\lVert u_t(x)\\rVert\\,p_t(x)\\,dx\\,dt &lt; \\infty. \\tag{13g} \\] <p>It also makes the flow ODE meaningful in integral form:</p> \\[ \\psi_t(x) = x + \\int_0^t u_s\\big(\\psi_s(x)\\big)\\,ds, \\tag{13h} \\] <p>which is often the cleanest way to see why additional assumptions beyond local Lipschitzness may be needed to guarantee existence all the way up to \\(t=1\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#weak-form-often-the-cleanest-statement","title":"Weak form (often the cleanest statement)","text":"<p>For a smooth test function \\(\\varphi:\\mathbb{R}^d\\to\\mathbb{R}\\) with sufficient decay, \\(\\tag{13}\\) is equivalent to</p> \\[ \\frac{d}{dt}\\int_{\\mathbb{R}^d}\\varphi(x)\\,p_t(x)\\,dx \\;=\\; \\int_{\\mathbb{R}^d}\\nabla\\varphi(x)\\cdot u_t(x)\\,p_t(x)\\,dx. \\tag{14} \\] <p>This is just integration by parts applied to \\(\\tag{13}\\). It is also the cleanest way to define solutions when \\(p_t\\) is not smooth.</p>"},{"location":"posts/introduction-B-flow-matching.html#characteristics-the-particle-view-recovers-the-pde","title":"Characteristics: the particle view recovers the PDE","text":"<p>If \\(\\mathbf{x}_t\\) follows the ODE \\(\\dot{\\mathbf{x}}_t=u_t(\\mathbf{x}_t)\\) and its law is \\(p_t\\), then \\(\\tag{13}\\) describes how that law evolves. Conversely, when \\(\\tag{13}\\) holds and \\(u_t\\) is regular enough, one can interpret \\(\\mathbf{x}_t\\) as \u201cparticles\u201d moving with velocity \\(u_t\\), whose density is \\(p_t\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#log-density-along-a-trajectory-connects-to-likelihood-bookkeeping","title":"Log-density along a trajectory (connects to likelihood bookkeeping)","text":"<p>Assume \\(p_t\\) is differentiable and strictly positive on the region of interest. Along a trajectory \\(t\\mapsto x(t)\\) that solves \\(\\dot x(t)=u_t(x(t))\\), the continuity equation implies</p> \\[ \\frac{d}{dt}\\log p_t(x(t)) = -\\nabla\\cdot u_t(x(t)). \\tag{15} \\] <p>This identity is the infinitesimal form of change-of-variables: it is the term that becomes the \u201c\\(-\\mathrm{div}\\)\u201d contribution in continuous normalizing flows.</p>"},{"location":"posts/introduction-B-flow-matching.html#b15-instantaneous-change-of-variables","title":"B1.5. Instantaneous change of variables","text":"<p>The change-of-variables rule \\(\\tag{7}\\)\u2013\\(\\tag{8}\\) tells us how densities transform under a single diffeomorphism \\(T\\). In continuous time, the transformation from \\(t=0\\) to \\(t=1\\) is built from infinitesimal diffeomorphisms along the flow \\(\\psi_t\\). The resulting bookkeeping identity is usually called the instantaneous change of variables (ICoV).</p>"},{"location":"posts/introduction-B-flow-matching.html#jacobian-dynamics","title":"Jacobian dynamics","text":"<p>Assume \\(\\psi_t\\) is generated by the velocity field \\(u_t\\) as in \\(\\tag{9}\\)\u2013\\(\\tag{10}\\), and \\(\\psi_t(\\cdot)\\) is differentiable in \\(x\\). Let \\(J_t(x):=\\nabla\\psi_t(x)\\in\\mathbb{R}^{d\\times d}\\) denote the Jacobian of the flow map. Differentiating \\(\\psi_t\\) with respect to \\(x\\) gives the Jacobian ODE</p> \\[ \\frac{d}{dt}J_t(x) = \\nabla u_t\\big(\\psi_t(x)\\big)\\,J_t(x), \\qquad J_0(x)=I. \\tag{16} \\] <p>Taking the log-determinant and using \\(\\frac{d}{dt}\\log\\det J_t = \\mathrm{Tr}\\big(J_t^{-1}\\frac{d}{dt}J_t\\big)\\), we obtain</p> \\[ \\frac{d}{dt}\\log\\big|\\det J_t(x)\\big| = \\mathrm{Tr}\\big(\\nabla u_t(\\psi_t(x))\\big) = \\nabla\\cdot u_t\\big(\\psi_t(x)\\big). \\tag{17} \\]"},{"location":"posts/introduction-B-flow-matching.html#density-dynamics-along-the-flow-the-icov-formula","title":"Density dynamics along the flow (the ICoV formula)","text":"<p>Let \\(\\mathbf{x}_0\\sim p_0\\) and \\(\\mathbf{x}_t=\\psi_t(\\mathbf{x}_0)\\) so that \\(p_t=(\\psi_t)_\\#p_0\\) as in \\(\\tag{11}\\). When densities exist, the discrete change-of-variables formula applied to \\(\\psi_t\\) reads</p> \\[ p_t\\big(\\psi_t(x)\\big)\\,\\big|\\det \\nabla\\psi_t(x)\\big| = p_0(x). \\tag{18} \\] <p>Differentiating \\(\\log p_t(\\psi_t(x)) + \\log|\\det\\nabla\\psi_t(x)|\\) in time and using \\(\\tag{17}\\) yields exactly the along-trajectory identity \\(\\tag{15}\\):</p> \\[ \\frac{d}{dt}\\log p_t(\\mathbf{x}_t) = -\\nabla\\cdot u_t(\\mathbf{x}_t). \\tag{19} \\] <p>Integrating \\(\\tag{19}\\) gives the practical likelihood bookkeeping rule used in continuous normalizing flows:</p> \\[ \\log p_1(\\mathbf{x}_1) = \\log p_0(\\mathbf{x}_0) - \\int_{0}^{1}\\nabla\\cdot u_t(\\mathbf{x}_t)\\,dt, \\qquad \\mathbf{x}_t=\\psi_t(\\mathbf{x}_0). \\tag{20} \\] <p>This is why \u201cdivergence of the velocity field\u201d is the continuous-time analogue of the log-Jacobian determinant in ordinary normalizing flows.</p>"},{"location":"posts/introduction-B-flow-matching.html#b2-flow-matching","title":"B2. Flow Matching","text":"<p>B-fig9. Flow Matching training pipeline (high level).</p> <p>Given a known source distribution \\(p\\) and a target (data) distribution \\(q\\), Flow Matching (FM) trains a flow model by learning a time-dependent velocity field \\(u_{\\theta,t}(x)\\). The goal is to learn a velocity field whose induced flow transports probability mass along a prescribed probability path \\((p_t)_{t\\in[0,1]}\\) from \\(p_0=p\\) to \\(p_1=q\\):</p> \\[ \\frac{d}{dt}\\psi_t(x)=u_{\\theta,t}\\big(\\psi_t(x)\\big), \\qquad p_t=(\\psi_t)_\\#p, \\qquad p_0=p,\\;p_1=q. \\tag{21} \\] <p>Revisiting the FM blueprint (B-fig9): (a) pick a known source \\(p\\) and an unknown data target \\(q\\); (b) prescribe an interpolation path \\(p_t\\) from \\(p\\) to \\(q\\); (c) learn a neural velocity field \\(u_{\\theta,t}\\) that generates that path; and (d) sample by solving an ODE using the learned \\(u_{\\theta,t}\\).</p> <p>To learn \\(u_{\\theta,t}\\), FM minimizes a regression loss that matches \\(u_{\\theta,t}\\) to a \u201cground-truth\u201d velocity field \\(u_t\\) known to generate the chosen probability path \\(p_t\\):</p> \\[ \\mathcal{L}_{\\mathrm{FM}}(\\theta) = \\mathbb{E}_{t\\sim U[0,1],\\;\\mathbf{x}_t\\sim p_t} \\Big[ D\\big(u_t(\\mathbf{x}_t),\\,u_{\\theta,t}(\\mathbf{x}_t)\\big) \\Big]. \\tag{22} \\] <p>A common choice is the squared \\(\\ell_2\\) distance</p> \\[ D(a,b)=\\lVert a-b\\rVert^2. \\tag{23} \\]"},{"location":"posts/introduction-B-flow-matching.html#data-pairs-couplings-and-why-fm-feels-supervised","title":"Data pairs, couplings, and why FM feels supervised","text":"<p>FM often looks like supervised learning because we end up with training tuples of the form \\((t,\\mathbf{x}_t,\\text{target velocity})\\), and we regress \\(u_{\\theta,t}(\\mathbf{x}_t)\\) to that target using an \\(\\ell_2\\) loss.</p> <p>Where do those \u201clabels\u201d come from? They are not human annotations. They come from a chosen coupling \\(\\pi\\) between the endpoints:</p> <ul> <li>draw a source sample \\(\\mathbf{x}_0\\sim p\\)</li> <li>draw a data sample \\(\\mathbf{x}_1\\sim q\\)</li> <li>pair them into \\((\\mathbf{x}_0,\\mathbf{x}_1)\\sim\\pi\\)</li> </ul> <p>This pairing is the key modeling choice. In most generative settings, there is no natural one-to-one correspondence between a particular \\(\\mathbf{x}_0\\) and a particular data point \\(\\mathbf{x}_1\\), so \\(\\pi\\) is synthetic (e.g., independent coupling \\(\\pi=p\\otimes q\\), or a more structured/OT-inspired coupling). The coupling determines what \u201cteacher signal\u201d FM will produce.</p>"},{"location":"posts/introduction-B-flow-matching.html#building-a-probability-path-from-a-coupling","title":"Building a probability path from a coupling","text":"<p>Given a coupling \\(\\pi\\) and an interpolation map \\(\\gamma_t:\\mathbb{R}^d\\times\\mathbb{R}^d\\to\\mathbb{R}^d\\), we define</p> <p></p> \\[ \\mathbf{x}_t := \\gamma_t(\\mathbf{x}_0,\\mathbf{x}_1), \\qquad (\\mathbf{x}_0,\\mathbf{x}_1)\\sim \\pi. \\tag{24} \\] <p>Then the probability path is simply the law of \\(\\mathbf{x}_t\\):</p> \\[ \\mathbf{x}_t\\sim p_t. \\tag{25} \\] <p>A minimal (and very common) choice is linear interpolation \\(\\gamma_t(x_0,x_1)=(1-t)x_0+t x_1\\), but other paths are possible and can change the learning dynamics.</p>"},{"location":"posts/introduction-B-flow-matching.html#from-a-path-to-a-generating-velocity-field","title":"From a path to a generating velocity field","text":"<p>Along a paired trajectory \\(t\\mapsto \\gamma_t(x_0,x_1)\\), there is an obvious \u201cpairwise\u201d velocity:</p> \\[ \\dot\\gamma_t(x_0,x_1) := \\frac{\\partial}{\\partial t}\\gamma_t(x_0,x_1). \\tag{26} \\] <p>However, a generating velocity field \\(u_t(x)\\) must be a function of \\((t,x)\\) alone (it cannot depend on the hidden pair \\((x_0,x_1)\\)). The standard construction is to take a conditional expectation with respect to the induced \\(\\mathbf{x}_t\\):</p> \\[ u_t(x) := \\mathbb{E}\\big[\\dot\\gamma_t(\\mathbf{x}_0,\\mathbf{x}_1)\\mid \\mathbf{x}_t=x\\big]. \\tag{27} \\] <p>Intuition: many different endpoint pairs can pass through the same intermediate location \\(x\\) at time \\(t\\); \\(\\tag{27}\\) says the \u201cbest\u201d single-valued velocity field at \\((t,x)\\) (in the least-squares sense) is the conditional mean of those pairwise velocities. This is exactly why we introduced conditional expectation as \u201cthe best predictor under MSE\u201d.</p> <p>With \\(\\tag{27}\\) in hand, \\(\\mathcal{L}_{\\mathrm{FM}}\\) in \\(\\tag{22}\\) becomes a standard regression objective: sample \\(t\\), sample a pair \\((\\mathbf{x}_0,\\mathbf{x}_1)\\sim\\pi\\), form \\(\\mathbf{x}_t=\\gamma_t(\\mathbf{x}_0,\\mathbf{x}_1)\\), compute (or approximate) the target \\(u_t(\\mathbf{x}_t)\\), and fit \\(u_{\\theta,t}\\) to it.</p>"},{"location":"posts/introduction-B-flow-matching.html#b21-deriving-generating-velocity-fields","title":"B2.1. Deriving generating velocity fields","text":"<ul> <li>\\(p_t(x)\\) is typically a mixture distribution whose density is not available in closed form;</li> <li>\\(p_{t\\mid 1}(x\\mid x_1)\\) is a family of simple conditional distributions (usually chosen to be analytically tractable and easy to sample from, e.g. Gaussians);</li> <li>the generating velocity field \\(u_t(x)\\) is the posterior-weighted average of a \u201cconditional velocity\u201d \\(u_t(x\\mid x_1)\\) under \\(p_{1\\mid t}(x_1\\mid x)\\).</li> </ul> <p>Continuing from the previous subsection\u2019s notation \\((\\mathbf{x}_0,\\mathbf{x}_1)\\sim\\pi\\) and \\(\\mathbf{x}_t=\\gamma_t(\\mathbf{x}_0,\\mathbf{x}_1)\\), it is often convenient to denote the \u201cintermediate distribution given the endpoint \\(x_1\\)\u201d by \\(p_{t\\mid 1}(\\cdot\\mid x_1)\\) (with the randomness of \\(\\mathbf{x}_0\\) understood to have been marginalized out).</p> <p>More concretely, let \\(\\mathbf{x}_1\\sim p_1\\) (the endpoint distribution, usually the data distribution), and for each \\(t\\in[0,1]\\) specify a conditional family \\(p_{t\\mid 1}(x\\mid x_1)\\), meaning the distribution of \\(\\mathbf{x}_t\\) given \\(\\mathbf{x}_1=x_1\\). The marginal distribution is then</p> \\[ p_t(x) \\;=\\; \\int_{\\mathbb{R}^d} p_{t\\mid 1}(x\\mid x_1)\\,p_1(x_1)\\,dx_1, \\qquad x\\in\\mathbb{R}^d. \\tag{28} \\] <p>Since \\(\\tag{28}\\) is a mixture (an integral over \\(x_1\\)), \\(p_t(x)\\) generally does not admit a closed-form expression. Suppose that for each fixed \\(x_1\\) we have a (relatively simple) conditional velocity field \\(u_t(\\cdot\\mid x_1)\\) that generates the conditional path \\((p_{t\\mid 1}(\\cdot\\mid x_1))_{t\\in[0,1]}\\) (e.g. by satisfying the corresponding continuity equation). Then the global (marginal) generating velocity field is the posterior average of these conditional velocities:</p> \\[ u_t(x) \\;=\\; \\mathbb{E}\\!\\left[u_t(x\\mid \\mathbf{x}_1)\\mid \\mathbf{x}_t=x\\right] \\;=\\; \\int_{\\mathbb{R}^d} u_t(x\\mid x_1)\\,p_{1\\mid t}(x_1\\mid x)\\,dx_1, \\tag{29} \\] <p>where the posterior weight is given by Bayes\u2019 rule:</p> \\[ p_{1\\mid t}(x_1\\mid x) \\;=\\; \\frac{p_{t\\mid 1}(x\\mid x_1)\\,p_1(x_1)}{p_t(x)}. \\tag{30} \\] <p>Insight (constraint vs. construction). The continuity equation \\(\\tag{13}\\) is simultaneously (i) a dynamical constraint\u2014a necessary condition that any pair \\((p_t,u_t)\\) must satisfy if \\(u_t\\) is to generate the path \\((p_t)\\)\u2014and (ii) the bridge that ties together \u201cdensity evolution\u201d (\\(p_t\\)) and \u201ctransport field\u201d (\\(u_t\\)). In classical PDE language one often solves \\(\\partial_t p_t + \\nabla\\cdot(p_t u_t)=0\\) for \\(p_t\\) given \\(u_t\\) and an initial condition \\(p_0\\). In Flow Matching we frequently take the opposite stance: we construct a probability path \\((p_t)\\) (e.g. via a coupling \\(\\pi\\) and an interpolation \\(\\gamma_t\\)) and then build a generating field \\(u_t\\) that satisfies the constraint. This perspective also highlights a non-uniqueness: for a fixed path \\((p_t)\\), there can be many velocity fields \\(u_t\\) that satisfy \\(\\tag{13}\\); FM\u2019s \u201cconditional expectation\u201d recipe \\(\\tag{27}\\) is one principled way to pick a single-valued \\(u_t(x)\\) from latent pairwise velocities.</p>"},{"location":"posts/introduction-B-flow-matching.html#b22-general-conditioning-and-the-marginalization-trick","title":"B2.2. General conditioning and the Marginalization Trick","text":"<p>In the previous subsection, the conditioning variable was the endpoint \\(\\mathbf{x}_1\\) (so we wrote \\(p_{t\\mid 1}(x\\mid x_1)\\)). More generally, we can condition the path on an arbitrary auxiliary random variable \\(\\mathbf{Z}\\) taking values in some space \\(\\mathcal{Z}\\). Concretely, for each \\(t\\in[0,1]\\) and \\(z\\in\\mathcal{Z}\\), suppose we specify a simple conditional distribution \\(p_{t\\mid Z}(x\\mid z)\\). The resulting marginal path is the mixture over \\(\\mathbf{Z}\\):</p> \\[ p_t(x) \\;=\\; \\int_{\\mathcal{Z}} p_{t\\mid Z}(x\\mid z)\\,p_Z(z)\\,dz, \\qquad x\\in\\mathbb{R}^d, \\tag{31} \\] <p>with the integral understood in the appropriate sense (sum / integral) depending on the law of \\(\\mathbf{Z}\\).</p> <p>Insight. This \u201cgeneral conditioning\u201d viewpoint simply enlarges the previous construction: \\(\\mathbf{Z}\\) does not have to be \\(\\mathbf{x}_1\\); it can be any variable that indexes a convenient family of conditional paths.</p>"},{"location":"posts/introduction-B-flow-matching.html#marginalization-trick-from-conditional-velocities-to-a-marginal-generating-velocity","title":"Marginalization trick: from conditional velocities to a marginal (generating) velocity","text":"<p>Assume that for each \\(z\\in\\mathcal{Z}\\), the conditional density \\(p_{t\\mid Z}(\\cdot\\mid z)\\) is transported by a conditional velocity field \\(u_t(\\cdot\\mid z)\\) in the sense of the continuity equation:</p> \\[ \\partial_t p_{t\\mid Z}(x\\mid z) + \\nabla\\cdot\\big(p_{t\\mid Z}(x\\mid z)\\,u_t(x\\mid z)\\big)=0. \\tag{32} \\] <p>Multiply \\(\\tag{32}\\) by \\(p_Z(z)\\) and integrate over \\(z\\). Under mild regularity that justifies swapping \\(\\partial_t\\) / \\(\\nabla\\cdot\\) with the \\(z\\)-integral, we obtain</p> \\[ \\partial_t p_t(x) \\, + \\, \\nabla\\cdot\\left( \\int_{\\mathcal{Z}} p_{t\\mid Z}(x\\mid z)\\,u_t(x\\mid z)\\,p_Z(z)\\,dz \\right)=0, \\tag{33} \\] <p>where we used \\(\\tag{31}\\) to identify \\(p_t(x)=\\int p_{t\\mid Z}(x\\mid z)p_Z(z)\\,dz\\). Equation \\(\\tag{33}\\) is again a continuity equation for the marginal path \\((p_t)\\), with probability flux</p> \\[ j_t(x) := \\int_{\\mathcal{Z}} p_{t\\mid Z}(x\\mid z)\\,u_t(x\\mid z)\\,p_Z(z)\\,dz. \\tag{34} \\] <p>Whenever \\(p_t(x)&gt;0\\), we can therefore define the marginal (generating) velocity field \\(u_t(x)\\) via \\(j_t(x)=p_t(x)\\,u_t(x)\\), i.e.</p> \\[ u_t(x) \\;:=\\; \\frac{1}{p_t(x)} \\int_{\\mathcal{Z}} u_t(x\\mid z)\\,p_{t\\mid Z}(x\\mid z)\\,p_Z(z)\\,dz. \\tag{35} \\] <p>Now apply Bayes\u2019 rule to form the posterior over the conditioning variable at time \\(t\\):</p> \\[ p_{Z\\mid t}(z\\mid x) \\;:=\\; p_{Z\\mid \\mathbf{X}_t}(z\\mid x) \\;=\\; \\frac{p_{t\\mid Z}(x\\mid z)\\,p_Z(z)}{p_t(x)}, \\qquad p_t(x)&gt;0. \\tag{36} \\] <p>Substituting \\(\\tag{36}\\) into \\(\\tag{35}\\) yields the advertised \u201cposterior-weighted average\u201d form:</p> \\[ u_t(x) \\;=\\; \\int_{\\mathcal{Z}} u_t(x\\mid z)\\,p_{Z\\mid t}(z\\mid x)\\,dz \\;=\\; \\mathbb{E}\\!\\left[u_t(x\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x\\right]. \\tag{37} \\] <p>This is the general version of the earlier special case \\(\\mathbf{Z}=\\mathbf{x}_1\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#why-ell_2-regression-recovers-this-conditional-expectation","title":"Why \\(\\ell_2\\) regression recovers this conditional expectation","text":"<p>Fix \\(t\\in[0,1]\\) and consider the regression viewpoint with \\(X:=\\mathbf{X}_t\\in\\mathbb{R}^d\\) as the observed input and \\(Y:=u_t(\\mathbf{X}_t\\mid \\mathbf{Z})\\in\\mathbb{R}^d\\) as the \u201clabel\u201d (a random vector because \\(\\mathbf{Z}\\) is latent given \\(X\\)). For any measurable \\(g:\\mathbb{R}^d\\to\\mathbb{R}^d\\) with \\(\\mathbb{E}\\|Y-g(X)\\|^2&lt;\\infty\\), the minimizer of</p> \\[ \\mathbb{E}\\big[\\|Y-g(X)\\|^2\\big] \\tag{38} \\] <p>is</p> \\[ g^\\star(x) = \\mathbb{E}[Y\\mid X=x]. \\tag{39} \\] <p>Therefore, the population-optimal \\(\\ell_2\\) regressor implied by the conditional-velocity construction is exactly the marginal velocity \\(\\tag{37}\\):</p> \\[ g^\\star(x)=\\mathbb{E}\\!\\left[u_t(\\mathbf{X}_t\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x\\right] = u_t(x). \\tag{40} \\] <p>Note (why not \\(\\ell_1\\)). In 1D, \\(\\ell_1\\) regression returns a (conditional) median, not a mean:</p> \\[ g^\\star \\in \\arg\\min_g \\mathbb{E}\\big[|Y-g(X)|\\big] \\quad\\Longrightarrow\\quad g^\\star(x)\\in \\mathrm{Med}(Y\\mid X=x), \\tag{40a} \\] <p>since the optimality condition is the subgradient balance \\(\\mathbb{P}(Y\\le g\\mid X=x)\\ge \\tfrac12\\) and \\(\\mathbb{P}(Y\\ge g\\mid X=x)\\ge \\tfrac12\\). For an empirical 1D sample, the minimizer is the usual median (odd \\(n\\): one observed instance; even \\(n\\): any point between the two middle instances).</p> <p>The marginalization trick above is fundamentally linear: mixing conditional solutions mixes their fluxes, which yields the posterior mean \\(u_t(x)=\\mathbb{E}[u_t(x\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x]\\). The mean is linear; the median is not. So swapping \\(\\ell_2\\) for \\(\\ell_1\\) generally selects an order-statistic-type field (a median of conditional velocities) rather than a linear mixture, and need not satisfy the continuity equation for the prescribed \\(p_t\\).</p> <p>Note (what is linear in the continuity equation). The continuity equation \\(\\partial_t p_t + \\nabla\\cdot(p_t u_t)=0\\) is linear in \\((p_t,j_t)\\) when written in flux form, where \\(j_t := p_t u_t\\):</p> \\[ \\partial_t p_t(x) + \\nabla\\cdot j_t(x) = 0. \\tag{40b} \\] <p>It is not linear in \\(u_t\\) itself, since \\(u_t=j_t/p_t\\) is nonlinear. The marginalization step in Theorem 3 uses exactly this \\((p,j)\\)-linearity plus the ability to interchange \\(\\partial_t\\) and \\(\\nabla\\cdot\\) with the \\(z\\)-integral (justified by the regularity / integrability assumptions): define \\(p_t(x)=\\int p_{t\\mid Z}(x\\mid z)\\,p_Z(z)\\,dz\\) and \\(j_t(x)=\\int j_{t\\mid Z}(x\\mid z)\\,p_Z(z)\\,dz\\) with \\(j_{t\\mid Z}:=p_{t\\mid Z}u_t(\\cdot\\mid z)\\), then integrating \\(\\partial_t p_{t\\mid Z}+\\nabla\\cdot j_{t\\mid Z}=0\\) over \\(z\\) yields \\(\\partial_t p_t+\\nabla\\cdot j_t=0\\).</p> <p>As a related aside: the (forward) Fokker\u2013Planck equation for an SDE is also linear in \\(p\\), even though it contains a second-order term. In one common notation,</p> \\[ \\partial_t p = -\\nabla\\cdot(f\\,p) + \\frac{1}{2}\\nabla^2\\!\\big(g^2\\,p\\big), \\tag{40c} \\] <p>so the key issue is not \u201cfirst-order vs. second-order\u201d, but whether the PDE is linear in the density.</p> <p>In this sense, both Flow Matching (deterministic transport; first-order generator) and Diffusion (stochastic dynamics; second-order generator) fit the same generator-based template: the induced density evolution equation is linear in \\(p\\).</p> <p>Summary (two theorems glued together, not a coincidence).</p> <ol> <li>(PDE / marginalization) If each conditional path \\((p_{t\\mid Z}(\\cdot\\mid z))\\) is generated by \\(u_t(\\cdot\\mid z)\\), then the marginal path \\((p_t)\\) is generated by the posterior average \\(u_t(x)=\\mathbb{E}[u_t(x\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x]\\).</li> <li>(Projection / \\(\\ell_2\\) optimality) The minimizer of an \\(\\ell_2\\) regression loss is the conditional expectation \\(\\mathbb{E}[Y\\mid X]\\).</li> <li>Putting them together: FM (i) identifies the marginal generating velocity as a conditional expectation, and (ii) uses \\(\\ell_2\\) regression whose population optimum is exactly that conditional expectation.</li> </ol>"},{"location":"posts/introduction-B-flow-matching.html#why-do-we-condition-turning-an-implicit-target-into-supervised-data","title":"Why do we condition? (Turning an implicit target into supervised data)","text":"<p>At the level of the generator\u2019s structure, the object we ultimately want is the marginal generating velocity \\(u_t(x)\\) in \\(\\tag{37}\\). But \\(u_t(x)\\) is typically not directly labelable: evaluating it at a given \\(x\\) requires the posterior integral \\(\\int u_t(x\\mid z)\\,p_{Z\\mid t}(z\\mid x)\\,dz\\), and \\(p_{Z\\mid t}(z\\mid x)\\) involves the intractable marginal \\(p_t(x)\\) in the denominator \\(\\tag{36}\\). So even if we can write down (and sample from) the conditional mechanism \\(p_{t\\mid Z}(\\cdot\\mid z)\\) and compute \\(u_t(\\cdot\\mid z)\\), we usually cannot form \u201cground-truth\u201d pairs \\((x, u_t(x))\\).</p> <p>Conditional Flow Matching resolves this by manufacturing supervised training pairs from the conditional world:</p> <ul> <li>sample a time \\(t\\),</li> <li>sample a latent \\(z\\sim p_Z\\),</li> <li>sample an intermediate state \\(x_t\\sim p_{t\\mid Z}(\\cdot\\mid z)\\),</li> <li>compute the tractable conditional label \\(y := u_t(x_t\\mid z)\\),</li> <li>regress a model \\(g(x,t)\\) on pairs \\((x_t,t)\\mapsto y\\) using an \\(\\ell_2\\) loss.</li> </ul> <p>The \u201csupervised learning essence\u201d is that conditioning turns an implicit marginal target into an explicit random label \\(Y=u_t(\\mathbf{X}_t\\mid \\mathbf{Z})\\) paired with an observable input \\(X=\\mathbf{X}_t\\). Then the standard \\(\\ell_2\\) projection theorem \\(\\tag{39}\\) guarantees that, at the population level,</p> \\[ g^\\star(x,t) = \\mathbb{E}\\!\\left[u_t(\\mathbf{X}_t\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x\\right] = u_t(x), \\tag{41} \\] <p>so regressing conditional velocities automatically recovers the marginal velocity without ever explicitly computing the posterior weights \\(p_{Z\\mid t}(z\\mid x)\\).</p> <p>Assumption 1. \\(p_{t\\mid Z}(x\\mid z)\\in C^1([0,1)\\times\\mathbb{R}^d)\\) as a function of \\((t,x)\\), and \\(u_t(x\\mid z)\\in C^1([0,1)\\times\\mathbb{R}^d,\\mathbb{R}^d)\\) as a function of \\((t,x)\\). Furthermore, \\(p_Z\\) has bounded support, i.e. there exists a bounded set \\(K\\subset\\mathbb{R}^m\\) such that \\(p_Z(z)=0\\) for all \\(z\\notin K\\). Finally, \\(p_t(x)&gt;0\\) for all \\(x\\in\\mathbb{R}^d\\) and \\(t\\in[0,1)\\).</p> <p>Theorem 3 (Marginalization Trick). Under Assumption 1, if \\(u_t(x\\mid z)\\) is conditionally integrable and generates the conditional probability path \\(p_t(\\cdot\\mid z)\\), then the marginal velocity field \\(u_t\\) generates the marginal probability path \\(p_t\\), for all \\(t\\in[0,1)\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#what-this-theorem-is-really-saying-and-why-it-matters","title":"What this theorem is really saying (and why it matters)","text":"<p>Theorem 3 proves a clean closure property of probability transport: if every conditional flow is valid, then the mixture flow is valid as well. Conceptually, you can think of having one \u201cprobability fluid\u201d for each \\(z\\); each one obeys a conservation law; and since the conservation law is linear in the right variables, superposing (mixing) these fluids preserves conservation.</p> <p>The key points behind the proof are:</p> <ol> <li>Linearity is in \\((p,j)\\), not in \\(u\\). The continuity equation is linear in density \\(p\\) and flux \\(j:=p u\\): \\(\\partial_t p+\\nabla\\cdot j=0\\). It is not linear in \\(u\\) itself.</li> <li>Regularity survives mixing (under the stated assumptions). With \\(p_{t\\mid Z}(\\cdot\\mid z)\\in C^1\\) in \\((t,x)\\) and mild conditions that justify interchanging differentiation and integration in \\(z\\), the marginal \\(p_t(x)=\\int p_{t\\mid Z}(x\\mid z)p_Z(z)\\,dz\\) inherits the needed differentiability.</li> <li>Integrability is controlled by convexity / Jensen. Since the marginal velocity is a conditional expectation \\(u_t(x)=\\mathbb{E}[u_t(x\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x]\\), Jensen gives    \\(\\|u_t(x)\\|\\le \\mathbb{E}[\\|u_t(x\\mid \\mathbf{Z})\\|\\mid \\mathbf{X}_t=x]\\),    which helps ensure the expected speed condition (e.g. \\(\\int_0^1\\!\\int \\|u_t(x)\\|p_t(x)\\,dx\\,dt&lt;\\infty\\)) whenever the conditional one is integrable.</li> </ol> <p>Flow Matching takeaway. This is the theoretical hinge that lets us go from conditionally supervised training signals \\(u_t(x_t\\mid z)\\) to an unconditional global ODE sampler: conditional flow matching can be marginalized into a single velocity field that transports the marginal path.</p> <p>The path of implications .</p> <ol> <li>CE is linear in \\((p,j)\\).</li> <li>Each conditional flow \\((p_{t\\mid Z}(\\cdot\\mid z), j_{t\\mid Z}(\\cdot\\mid z))\\) satisfies CE.</li> <li>Mixing over \\(z\\) preserves CE, so the marginal \\((p_t,j_t)\\) satisfies CE.</li> <li>Under the usual boundary/decay assumptions, CE implies global mass conservation \\(\\int p_t=1\\).</li> </ol>"},{"location":"posts/introduction-B-flow-matching.html#why-int_omega-nablacdotcdotdx-becomes-a-boundary-term-and-when-it-vanishes","title":"Why \\(\\int_\\Omega \\nabla\\cdot(\\cdot)\\,dx\\) becomes a boundary term (and when it vanishes)","text":"<p>Start from the continuity equation, most transparently written in flux form. Let \\(p_t:\\mathbb{R}^d\\to\\mathbb{R}_{\\ge 0}\\) be a density and \\(u_t:\\mathbb{R}^d\\to\\mathbb{R}^d\\) a velocity field, and define the probability flux \\(j_t(x):=p_t(x)\\,u_t(x)\\). The continuity equation is</p> \\[ \\partial_t p_t(x) + \\nabla\\cdot j_t(x)=0. \\tag{A1} \\] <p>Let \\(\\Omega\\subset\\mathbb{R}^d\\) be a region with piecewise smooth boundary \\(\\partial\\Omega\\), outward unit normal \\(n(x)\\), and surface-area element \\(dS\\). Integrating over \\(\\Omega\\) and (under sufficient regularity) moving \\(\\partial_t\\) inside the integral gives</p> \\[ \\frac{d}{dt}\\int_\\Omega p_t(x)\\,dx \\;+\\; \\int_\\Omega \\nabla\\cdot j_t(x)\\,dx \\;=\\;0. \\tag{A2} \\] <p>The key is the second term. The Gauss (divergence) theorem states that for any sufficiently smooth vector field \\(F:\\Omega\\to\\mathbb{R}^d\\),</p> \\[ \\int_\\Omega \\nabla\\cdot F(x)\\,dx \\;=\\; \\int_{\\partial\\Omega} F(x)\\cdot n(x)\\,dS. \\tag{A3} \\] <p>Taking \\(F=j_t\\) (i.e. \\(F=p_t u_t\\)) yields</p> \\[ \\int_\\Omega \\nabla\\cdot j_t(x)\\,dx \\;=\\; \\int_{\\partial\\Omega} j_t(x)\\cdot n(x)\\,dS \\;=\\; \\int_{\\partial\\Omega} \\big(p_t(x)\\,u_t(x)\\big)\\cdot n(x)\\,dS. \\tag{A4} \\] <p>Substituting into \\(\\tag{A2}\\) gives the \u201cmass balance / net flux\u201d identity:</p> \\[ \\frac{d}{dt}\\int_\\Omega p_t(x)\\,dx \\;=\\; -\\int_{\\partial\\Omega} j_t(x)\\cdot n(x)\\,dS. \\tag{A5} \\] <p>Interpretation: \\(\\int_\\Omega p_t\\) is the total probability mass inside \\(\\Omega\\). The right-hand side is the net outward flux through \\(\\partial\\Omega\\). Hence the mass changes exactly by \u201cminus net outflow\u201d.</p>"},{"location":"posts/introduction-B-flow-matching.html#what-does-the-boundary-term-is-zero-mean","title":"What does \u201cthe boundary term is zero\u201d mean?","text":"<p>Common ways to make \\(\\int_{\\partial\\Omega} j_t\\cdot n\\,dS=0\\) (think: different domain choices / boundary conditions) include:</p> <ol> <li>\\(\\Omega=\\mathbb{R}^d\\) with sufficient decay at infinity. Consider \\(\\Omega_R=\\{x:\\|x\\|\\le R\\}\\) and send \\(R\\to\\infty\\). If \\(j_t(x)\\) decays fast enough that \\(\\int_{\\partial\\Omega_R} j_t\\cdot n\\,dS\\to 0\\), the boundary contribution vanishes. Intuition: no probability mass flows in/out \u201cfrom infinity\u201d.</li> <li>Periodic boundary conditions (a torus / periodic box). Contributions from opposite faces cancel, so the net flux is zero.</li> <li>No-flux (reflecting / Neumann-type) boundary conditions. Impose</li> </ol> \\[    j_t(x)\\cdot n(x) = 0,\\qquad x\\in\\partial\\Omega,    \\tag{A6} \\] <p>meaning probability mass cannot cross the boundary.</p> <p>When the boundary term is zero, \\(\\tag{A5}\\) reduces to \\(\\frac{d}{dt}\\int_\\Omega p_t(x)\\,dx=0\\), so the total mass \\(\\int_\\Omega p_t(x)\\,dx\\) is conserved in time. In particular, if \\(\\int_\\Omega p_0(x)\\,dx=1\\), then \\(\\int_\\Omega p_t(x)\\,dx=1\\) for all \\(t\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#b23-flow-matching-loss","title":"B2.3. Flow Matching loss","text":"<p>B-fig10. Flow matching loss as a path-matching objective.</p> <p>The key modeling stance is: Flow Matching matches a path, not just the final density. Instead of directly minimizing a discrepancy between \\(p_1\\) and some model density \\(q_\\theta\\), FM matches the generator (a velocity field) along the prescribed intermediate marginals \\((p_t)\\). If \\(u_{\\theta,t}\\) matches the true generating field \\(u_t\\) for \\(t\\in[0,1)\\), then the ODE it defines transports mass along the intended path and reaches the desired endpoint.</p> <p>At the loss level, this is written as an expected discrepancy between vectors \\(u_{\\theta,t}(x)\\) and \\(u_t(x)\\), averaged over \\(t\\) and \\(x\\sim p_t\\). A central class of losses is Bregman divergences: given a strictly convex, differentiable potential \\(\\Phi:\\mathbb{R}^d\\to\\mathbb{R}\\), define</p> \\[ D_\\Phi(a,b) := \\Phi(a)-\\Phi(b)-\\langle\\nabla\\Phi(b),a-b\\rangle. \\tag{42a} \\] <p>Then the (population) flow matching loss is</p> \\[ \\mathcal{L}_{\\mathrm{FM}}(\\theta) := \\mathbb{E}_{t\\sim U[0,1],\\,\\mathbf{X}_t\\sim p_t} \\Big[ D_\\Phi\\big(u_t(\\mathbf{X}_t),\\,u_{\\theta,t}(\\mathbf{X}_t)\\big) \\Big]. \\tag{42} \\] <p>The squared \\(\\ell_2\\) loss is the special case \\(\\Phi(v)=\\frac12\\|v\\|^2\\), for which \\(D_\\Phi(a,b)=\\frac12\\|a-b\\|^2\\).</p> <p>The only remaining question is: where do the labels \\(u_t(\\mathbf{X}_t)\\) come from? In general, the marginal target \\(u_t(x)\\) is not directly computable because it is defined via a latent-variable marginalization (Theorem 3): it contains a posterior average over \\(\\mathbf{Z}\\) given \\(\\mathbf{X}_t=x\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#conditional-flow-matching-cfm-supervised-labels-from-a-latent-variable","title":"Conditional Flow Matching (CFM): supervised labels from a latent variable","text":"<p>Assume we have a latent variable \\(\\mathbf{Z}\\sim p_Z\\), a conditional family \\(p_{t\\mid Z}(\\cdot\\mid z)\\), and a tractable conditional velocity field \\(u_t(\\cdot\\mid z)\\) that generates \\(p_{t\\mid Z}(\\cdot\\mid z)\\). Then we can construct supervised samples by:</p> <ul> <li>sample \\(t\\sim U[0,1]\\),</li> <li>sample \\(z\\sim p_Z\\),</li> <li>sample \\(\\mathbf{X}_t\\sim p_{t\\mid Z}(\\cdot\\mid z)\\),</li> <li>set the label \\(Y:=u_t(\\mathbf{X}_t\\mid z)\\),</li> <li>regress \\(u_{\\theta,t}(\\mathbf{X}_t)\\) onto \\(Y\\).</li> </ul> <p>This yields the conditional flow matching objective:</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) := \\mathbb{E}_{t\\sim U[0,1],\\,\\mathbf{Z}\\sim p_Z,\\,\\mathbf{X}_t\\sim p_{t\\mid Z}(\\cdot\\mid \\mathbf{Z})} \\Big[ D_\\Phi\\big(u_t(\\mathbf{X}_t\\mid \\mathbf{Z}),\\,u_{\\theta,t}(\\mathbf{X}_t)\\big) \\Big]. \\tag{43} \\] <p>Even though \\(\\mathcal{L}_{\\mathrm{FM}}\\) in \\(\\tag{42}\\) is generally not directly computable (because it depends on the intractable marginal velocity \\(u_t\\)), CFM is designed so that it has the same gradient signal under a Bregman loss.</p> <p>Theorem 4 (Gradient equivalence). Under suitable regularity, for Bregman divergences \\(D_\\Phi\\) one has $$ \\nabla_\\theta \\mathcal{L}{\\mathrm{FM}}(\\theta) \\;=\\; \\nabla\\theta \\mathcal{L}_{\\mathrm{CFM}}(\\theta). \\tag{44} $$</p> <p>Proof sketch (the \u201cBregman magic\u201d). For fixed \\(t\\) and \\(x\\), write the marginal target as a conditional expectation \\(u_t(x)=\\mathbb{E}[u_t(x\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x]\\). The key identity is that the gradient of a Bregman divergence is affine in its first argument:</p> \\[ \\nabla_b D_\\Phi(a,b) \\;=\\; \\nabla^2\\Phi(b)\\,(b-a), \\tag{45} \\] <p>so for any \\(\\alpha,\\beta\\in\\mathbb{R}\\) with \\(\\alpha+\\beta=1\\) and any \\(u_1,u_2,v\\in\\mathbb{R}^d\\),</p> \\[ \\nabla_v D_\\Phi(\\alpha u_1 + \\beta u_2, v) \\;=\\; \\alpha\\,\\nabla_v D_\\Phi(u_1,v) \\;+\\; \\beta\\,\\nabla_v D_\\Phi(u_2,v), \\tag{45a} \\] <p>and, more generally, for any integrable random vector \\(Y\\in\\mathbb{R}^d\\),</p> \\[ \\nabla_v D_\\Phi\\big(\\mathbb{E}[Y],v\\big) \\;=\\; \\mathbb{E}\\big[\\nabla_v D_\\Phi(Y,v)\\big]. \\tag{45b} \\] <p>so \\(\\nabla_b D_\\Phi(\\mathbb{E}[A],b)=\\mathbb{E}[\\nabla_b D_\\Phi(A,b)]\\). Plug this into the chain rule expression for \\(\\nabla_\\theta \\mathcal{L}_{\\mathrm{FM}}\\), and the conditional expectation over \\(\\mathbf{Z}\\) moves \u201cthrough the gradient\u201d, turning the marginal label into the conditional label and yielding \\(\\nabla_\\theta \\mathcal{L}_{\\mathrm{CFM}}\\).</p> <p>Proposition 1 (Bregman regression learns conditional expectations). Let \\(X\\) and \\(Y\\) be random variables with \\(X\\in\\mathbb{R}^d\\) and \\(Y\\in\\mathrm{dom}(\\Phi)\\). The population minimizer of $$ \\mathbb{E}\\big[D_\\Phi(Y, g(X))\\big] $$ over measurable functions \\(g\\) is $$ g^\\star(x) \\;=\\; (\\nabla\\Phi)^{-1}!\\Big(\\mathbb{E}\\big[\\nabla\\Phi(Y)\\mid X=x\\big]\\Big). \\tag{46a} $$ In particular, for \\(\\Phi(v)=\\frac12\\|v\\|^2\\), this reduces to \\(g^\\star(x)=\\mathbb{E}[Y\\mid X=x]\\).</p> <p>Fix \\(t\\) and define \\(X:=\\mathbf{X}_t\\) and \\(Y:=u_t(\\mathbf{X}_t\\mid \\mathbf{Z})\\). By the \\(\\ell_2\\) projection theorem (already used in \\(\\tag{39}\\)), the population minimizer of \\(\\mathbb{E}[\\|Y-g(X)\\|^2]\\) is \\(g^\\star(x)=\\mathbb{E}[Y\\mid X=x]\\). Therefore, if we had infinite data and enough model capacity, minimizing \\(\\mathcal{L}_{\\mathrm{CFM}}\\) would recover</p> \\[ u_{\\theta,t}(x) \\;\\approx\\; \\mathbb{E}\\!\\left[u_t(x\\mid \\mathbf{Z})\\mid \\mathbf{X}_t=x\\right] \\;=\\; u_t(x), \\tag{46} \\] <p>which is exactly the marginal generating velocity identified by the marginalization trick.</p> <p>More generally, Bregman divergences give an analogous \u201cconditional expectation\u201d principle: minimizing \\(\\mathbb{E}[D_\\Phi(Y, g(X))]\\) recovers a conditional expectation in the geometry induced by \\(\\Phi\\) (with squared \\(\\ell_2\\) as the familiar Euclidean case).</p>"},{"location":"posts/introduction-B-flow-matching.html#general-time-sampling-engineering-note","title":"General time sampling (engineering note)","text":"<p>The uniform choice \\(t\\sim U[0,1]\\) can be replaced by any density \\(\\omega(t)\\) on \\([0,1]\\): it simply reweights the contribution of different times in \\(\\mathcal{L}_{\\mathrm{FM}}\\) / \\(\\mathcal{L}_{\\mathrm{CFM}}\\). In practice, changing the sampling distribution for \\(t\\) is often a convenient variance-control knob.</p>"},{"location":"posts/introduction-B-flow-matching.html#b24-solving-unconditional-generation-with-conditional-flows","title":"B2.4. Solving unconditional generation with conditional flows","text":"<p>At this point, training a flow model \\(u_{\\theta,t}\\) can be reduced to three concrete steps:</p> <ol> <li>Find a family of conditional probability paths \\(p_{t\\mid Z}(x\\mid z)\\) whose mixture \\(p_t(x)=\\int p_{t\\mid Z}(x\\mid z)p_Z(z)\\,dz\\) defines the desired marginal path (and satisfies the usual boundary / mass-conservation requirements).</li> <li>Find conditional velocity fields \\(u_t(x\\mid z)\\) that generate each conditional path \\(p_{t\\mid Z}(\\cdot\\mid z)\\).</li> <li>Train \\(u_{\\theta,t}\\) using the Conditional Flow Matching loss (B2.3), which only requires sampling \\(z\\) and evaluating \\(u_t(\\cdot\\mid z)\\), not the intractable marginal velocity \\(u_t(\\cdot)\\).</li> </ol> <p>What remains is a practical question: how do we design such conditional paths and conditional velocity fields?</p>"},{"location":"posts/introduction-B-flow-matching.html#a-flexible-construction-via-conditional-flows","title":"A flexible construction via conditional flows","text":"<p>One general approach is to build a conditional flow map and obtain both \\(p_{t\\mid 1}(x\\mid x_1)\\) and \\(u_t(x\\mid x_1)\\) from it. Here the conditioning variable is the endpoint \\(\\mathbf{X}_1=x_1\\).</p> <p>Define a conditional flow \\(\\psi:[0,1)\\times\\mathbb{R}^d\\times\\mathbb{R}^d\\to\\mathbb{R}^d\\), written \\(\\psi_t(x\\mid x_1)\\), such that</p> \\[ \\psi_0(x\\mid x_1)=x, \\qquad \\lim_{t\\uparrow 1}\\psi_t(x\\mid x_1)=x_1, \\tag{47} \\] <p>and assume \\(\\psi\\) is smooth in \\((t,x)\\) and a diffeomorphism in \\(x\\) for each \\(t\\in[0,1)\\) (conditions can be relaxed, but smoothness keeps the discussion simple).</p> <p>Now define the conditional flow model</p> \\[ \\mathbf{X}_{t\\mid 1} := \\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1), \\qquad \\mathbf{X}_{0\\mid 1}\\sim \\pi_{0\\mid 1}(\\cdot\\mid \\mathbf{X}_1). \\tag{48} \\] <p>The conditional density \\(p_{t\\mid 1}(\\cdot\\mid x_1)\\) is the push-forward of \\(\\pi_{0\\mid 1}(\\cdot\\mid x_1)\\) under \\(\\psi_t(\\cdot\\mid x_1)\\):</p> \\[ p_{t\\mid 1}(x\\mid x_1) := \\big(\\psi_t(\\cdot\\mid x_1)\\big)_\\#\\pi_{0\\mid 1}(\\cdot\\mid x_1)\\,(x). \\tag{49} \\] <p>Finally, by the standard equivalence between flows and velocity fields, the corresponding conditional velocity field is uniquely determined by \\(\\psi\\) via differentiation:</p> \\[ u_t(x\\mid x_1) \\;=\\; \\frac{\\partial}{\\partial t}\\psi_t\\!\\big(\\psi_t^{-1}(x\\mid x_1)\\mid x_1\\big), \\qquad t\\in[0,1). \\tag{50} \\] <p>Summary. This further reduces \u201cdesign \\(p_{t\\mid 1}\\) and \\(u_t(\\cdot\\mid x_1)\\)\u201d to a single task: build a conditional flow map \\(\\psi_t(\\cdot\\mid x_1)\\) satisfying the endpoint constraints \\(\\tag{47}\\). Different choices of \\(\\psi\\) (e.g. OT-inspired conditional flows, affine conditional flows, etc.) induce different conditional paths and learning dynamics.</p> <p></p>"},{"location":"posts/introduction-B-flow-matching.html#derivation-rewriting-the-cfm-loss-using-a-conditional-flow-psi_tcdotmid-x_1","title":"Derivation: rewriting the CFM loss using a conditional flow \\(\\psi_t(\\cdot\\mid x_1)\\)","text":"<p>Revisit the CFM objective \\(\\tag{43}\\) in the special case \\(\\mathbf{Z}=\\mathbf{X}_1\\). Using the conditional path induced by the conditional flow \\(\\psi_t(\\cdot\\mid x_1)\\), we can write</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) \\;=\\; \\mathbb{E}_{t,\\mathbf{X}_1,\\mathbf{X}_t\\sim p_{t\\mid 1}(\\cdot\\mid \\mathbf{X}_1)} \\Big[ D_\\Phi\\!\\big(u_t(\\mathbf{X}_t\\mid \\mathbf{X}_1),\\,u_{\\theta,t}(\\mathbf{X}_t)\\big) \\Big]. \\tag{51} \\] <p>Now use the sampling representation \\(\\tag{48}\\): for a given \\(\\mathbf{X}_1\\), sample \\(\\mathbf{X}_{0\\mid 1}\\sim \\pi_{0\\mid 1}(\\cdot\\mid \\mathbf{X}_1)\\) and set \\(\\mathbf{X}_t=\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1)\\). By the Law of the Unconscious Statistician (LOTUS), \\(\\mathbf{X}_t\\sim p_{t\\mid 1}(\\cdot\\mid \\mathbf{X}_1)\\) can therefore be replaced by \\((\\mathbf{X}_{0\\mid 1},\\mathbf{X}_1)\\) sampling:</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) \\;=\\; \\mathbb{E}_{t,\\;(\\mathbf{X}_{0\\mid 1},\\mathbf{X}_1)\\sim \\pi_{0,1}} \\Big[ D_\\Phi\\!\\big(u_t(\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1)\\mid \\mathbf{X}_1),\\,u_{\\theta,t}(\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1))\\big) \\Big]. \\tag{52} \\] <p>Here \\(\\pi_{0,1}\\) denotes the joint law of \\((\\mathbf{X}_{0\\mid 1},\\mathbf{X}_1)\\), i.e. sample \\(\\mathbf{X}_1\\sim p_1\\) and then \\(\\mathbf{X}_{0\\mid 1}\\sim \\pi_{0\\mid 1}(\\cdot\\mid \\mathbf{X}_1)\\).</p> <p>Finally, the conditional velocity field induced by \\(\\psi\\) satisfies (by definition \\(\\tag{50}\\)) the identity</p> \\[ u_t(\\mathbf{X}_t\\mid \\mathbf{X}_1) \\;=\\; \\frac{\\partial}{\\partial t}\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1) \\;=:\\; \\dot\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1), \\qquad \\mathbf{X}_t=\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1). \\tag{53} \\] <p>Substituting \\(\\tag{53}\\) into \\(\\tag{52}\\) yields the practical \u201csupervised\u201d form: the label is simply \\(\\dot\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1)\\) evaluated along the sampled conditional flow trajectory.</p> <p>In the squared-\\(\\ell_2\\) case (i.e. \\(D_\\Phi(a,b)=\\frac12\\|a-b\\|^2\\)), Proposition 1 reduces to the usual conditional mean optimality. The population minimizer of \\(\\mathcal{L}_{\\mathrm{CFM}}\\) therefore satisfies</p> \\[ u_t(x) \\;=\\; \\mathbb{E}\\!\\left[\\dot\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1)\\;\\middle|\\;\\mathbf{X}_t=x\\right], \\tag{54} \\] <p>which matches the earlier \u201cmarginal velocity = conditional expectation\u201d principle, now expressed directly in terms of the conditional flow map \\(\\psi_t(\\cdot\\mid x_1)\\).</p> <p>Corollary 1 (meaning; conditional-flow version of marginalization). If we build the conditional probability path \\(p_{t\\mid 1}(\\cdot\\mid x_1)\\) by pushing forward a \\(C^1\\) base conditional \\(\\pi_{0\\mid 1}(\\cdot\\mid x_1)\\) through a sufficiently smooth conditional flow map \\(\\psi_t(\\cdot\\mid x_1)\\) (with the endpoint constraints \\(\\psi_0(x\\mid x_1)=x\\) and \\(\\lim_{t\\uparrow 1}\\psi_t(x\\mid x_1)=x_1\\)), and if the induced conditional velocity \\(u_t(\\cdot\\mid x_1)\\) is conditionally integrable (e.g. \\(\\mathbb{E}\\|\\dot\\psi_t(\\mathbf{X}_{0\\mid 1}\\mid \\mathbf{X}_1)\\|&lt;\\infty\\)), then Theorem 3 applies with \\(\\mathbf{Z}=\\mathbf{X}_1\\): the posterior-averaged marginal velocity field \\(u_t(x)\\) generates the mixed marginal path \\(p_t(x)=\\int p_{t\\mid 1}(x\\mid x_1)\\,p_1(x_1)\\,dx_1\\). In short: valid conditional flows \\(\\Rightarrow\\) a valid marginal (unconditional) probability path and generator, so conditional-flow constructions are a principled way to design \\(p_t\\) and \\(u_t\\) for Flow Matching.</p> <p>Note (pair-conditioned vs. endpoint-conditioned flows, and a cautionary counterexample). In the guide, one can define an intermediate state either via an endpoint-conditioned flow \\(X_t=\\psi_t(X_0\\mid X_1)\\) or more symmetrically via a pair-conditioned interpolant \\(X_t=\\psi_t(X_0,X_1)\\). Under additional invertibility assumptions (e.g. \\(\\psi_t(\\cdot,x_1)\\) is a diffeomorphism in \\(x_0\\) for each fixed \\(x_1\\), and \\(\\psi_t(x_0,\\cdot)\\) is a diffeomorphism in \\(x_1\\) for each fixed \\(x_0\\)), these viewpoints lead to the same marginal probability path \\((p_t)\\) and the same marginal velocity field \\(u_t\\) (the \u201cconditioning choice\u201d is then largely an equivalent parametrization).</p> <p>However, not every smooth endpoint interpolant is valid for defining a marginal generating velocity. A standard counterexample is</p> \\[ \\psi_t(x_0,x_1) := \\big((1-2t)_+\\big)^\\tau\\,x_0 + \\big((2t-1)_+\\big)^\\tau\\,x_1, \\qquad (s)_+ := \\max\\{s,0\\}, \\qquad \\tau&gt;2, \\tag*{} \\] <p>for which \\(\\psi_0(x_0,x_1)=x_0\\), \\(\\psi_1(x_0,x_1)=x_1\\), but \\(\\psi_{1/2}(x_0,x_1)=0\\) for all \\((x_0,x_1)\\). Hence, if \\(X_t:=\\psi_t(X_0,X_1)\\), then \\(X_{1/2}=0\\) almost surely and the marginal \\(p_{1/2}\\) collapses to a delta mass. If a well-posed deterministic Markov velocity field \\(u_t(x)\\) were to generate this marginal path (in the sense of the continuity equation and the flow ODE), that delta collapse would force \\(p_t\\) to remain a delta for all \\(t&gt;1/2\\), contradicting a non-degenerate endpoint distribution at \\(t=1\\). The takeaway is: when constructing \\(\\psi_t\\) we need conditions (non-collapse / invertibility and integrability) that guarantee the existence of a sensible marginal generator \\(u_t\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#b25-optimal-transport-and-linear-conditional-flow","title":"B2.5 Optimal Transport and linear conditional flow","text":"<p>This subsection is a \u201cborrow-the-conclusion\u201d stop: we will not dive into OT theory, but we will use one clean variational fact\u2014a linear conditional flow arises from a kinetic-energy minimization principle (or, more precisely, from a tight upper bound thereof).</p>"},{"location":"posts/introduction-B-flow-matching.html#dynamic-ot-with-quadratic-cost-kinetic-energy","title":"Dynamic OT with quadratic cost (kinetic energy)","text":"<p>A canonical \u201cchoose a nice path\u201d principle is the Benamou\u2013Brenier (dynamic OT) formulation with quadratic cost: find a probability path \\((p_t)_{t\\in[0,1]}\\) and a velocity field \\((u_t)\\) that minimize kinetic energy subject to mass conservation and endpoint constraints:</p> \\[ (p_t^\\star,u_t^\\star) \\in \\arg\\min_{(p_t,u_t)} \\int_{0}^{1}\\int_{\\mathbb{R}^d}\\|u_t(x)\\|^2\\,p_t(x)\\,dx\\,dt \\tag{55a} \\] <p>subject to</p> \\[ p_0=p,\\qquad p_1=q, \\tag{55b} \\] <p>and the continuity equation</p> \\[ \\partial_t p_t(x) + \\nabla\\cdot\\big(p_t(x)\\,u_t(x)\\big)=0. \\tag{55c} \\] <p>When an optimal transport map \\(\\varphi:\\mathbb{R}^d\\to\\mathbb{R}^d\\) exists, the resulting marginal path is the OT displacement interpolant (McCann):</p> \\[ \\psi_t^\\star(x) = (1-t)\\,x + t\\,\\varphi(x), \\qquad X_t=\\psi_t^\\star(X_0),\\ \\ X_0\\sim p. \\tag{56} \\] <p>It yields straight sample trajectories \\(X_t = X_0 + t(\\varphi(X_0)-X_0)\\) with constant velocity \\(\\varphi(X_0)-X_0\\), which is numerically friendly.</p>"},{"location":"posts/introduction-B-flow-matching.html#why-ot-is-a-reasonable-but-not-mandatory-choice","title":"Why OT is a reasonable (but not mandatory) choice","text":"<p>The OT viewpoint is often used here for geometric intuition rather than as a claim of universal optimality.</p> <ul> <li>Geometric meaning. The dynamic OT objective \\(\\tag{55a}\\)\u2013\\(\\tag{55c}\\) picks, among all mass-preserving transports from \\(p\\) to \\(q\\), the one with minimal kinetic energy in the ambient Euclidean geometry. Equivalently (informally), it chooses a \u201cleast-effort\u201d probability flow.</li> <li>Straight trajectories. The displacement interpolant \\(\\tag{56}\\) moves individual samples along straight lines with constant velocity, which tends to be easier for ODE solvers (less curvature, less stiffness).</li> <li>A principled baseline. Even if we do not solve OT exactly, it provides a clean reference path that is well-motivated by an explicit variational principle.</li> <li>Not necessarily best for learning. The quadratic cost uses the Euclidean metric in \\(\\mathbb{R}^d\\), which may not align with semantic similarity (e.g. in pixel space). Different couplings and different paths can yield better training dynamics or sample quality, and in practice FM often uses simpler couplings / interpolants for efficiency.</li> </ul> <p>Geometric insight (why \u201cminimum kinetic energy\u201d is a straight line in distribution space). If we equip the space of probability measures with the quadratic Wasserstein distance</p> \\[ W_2^2(p,q) := \\min_{\\pi\\in\\Pi(p,q)} \\mathbb{E}_{(X_0,X_1)\\sim\\pi}\\big[\\|X_1-X_0\\|^2\\big], \\tag{56a} \\] <p>then the Benamou\u2013Brenier formulation says that \\(W_2\\)-geodesics are exactly the paths that minimize the kinetic energy \\(\\int_0^1\\!\\int \\|u_t(x)\\|^2 p_t(x)\\,dx\\,dt\\) subject to the continuity equation and endpoint constraints. In words: minimum kinetic energy corresponds to \u201cstraight-line motion\u201d in \\(W_2\\) geometry\u2014this is a geometric statement about the metric structure of distribution space, not a physical claim about images as fluids.</p> <p>Why squared speed (\\(\\ell_2\\) kinetic energy) is a natural regularizer. Many alternative \u201ceffort\u201d functionals are possible (e.g. \\(\\ell_1\\)-type speed, minimum-time criteria, or adding stochasticity), but the \\(\\ell_2\\) kinetic energy is special: it is smooth, convex in the flux variables, and in Euclidean space it often yields well-behaved (and sometimes analytic) interpolants. For Flow Matching, OT therefore serves as a canonical, geometry-consistent choice of \\(\\psi_t\\): not a universal truth, but a particularly natural regularization principle that produces elegant mathematics and stable numerics.</p>"},{"location":"posts/introduction-B-flow-matching.html#from-marginal-kinetic-energy-to-a-conditional-flow-objective-jensen-bound","title":"From marginal kinetic energy to a conditional-flow objective (Jensen bound)","text":"<p>In our conditional-flow construction, the marginal velocity can be written (squared-\\(\\ell_2\\) case) as a conditional expectation, e.g. \\(u_t(x)=\\mathbb{E}[\\dot\\psi_t(X_{0\\mid 1}\\mid X_1)\\mid X_t=x]\\) from \\(\\tag{54}\\). Plugging this into the kinetic energy integrand and applying Jensen\u2019s inequality gives a bound:</p> \\[ \\int_0^1 \\mathbb{E}\\big[\\|u_t(X_t)\\|^2\\big]\\,dt \\;=\\; \\int_0^1 \\mathbb{E}\\Big[\\big\\|\\mathbb{E}[\\dot\\psi_t(X_{0\\mid 1}\\mid X_1)\\mid X_t]\\big\\|^2\\Big]\\,dt \\;\\le\\; \\int_0^1 \\mathbb{E}\\Big[\\mathbb{E}\\big[\\|\\dot\\psi_t(X_{0\\mid 1}\\mid X_1)\\|^2\\mid X_t\\big]\\Big]\\,dt. \\tag{57} \\] <p>Using the tower property, the right-hand side simplifies to an expectation over paired endpoints:</p> \\[ \\int_0^1 \\mathbb{E}\\big[\\|u_t(X_t)\\|^2\\big]\\,dt \\;\\le\\; \\mathbb{E}_{(X_{0\\mid 1},X_1)\\sim\\pi_{0,1}} \\left[ \\int_0^1 \\|\\dot\\psi_t(X_{0\\mid 1}\\mid X_1)\\|^2\\,dt \\right]. \\tag{58} \\] <p>Crucially, the bound in \\(\\tag{58}\\) decouples over pairs: for each fixed \\((x,x_1)\\), minimizing the inner integral becomes a classical variational problem.</p>"},{"location":"posts/introduction-B-flow-matching.html#the-per-pair-variational-problem-rightarrow-linear-conditional-flow","title":"The per-pair variational problem \\(\\Rightarrow\\) linear conditional flow","text":"<p>For a fixed pair \\((x,x_1)\\), consider a trajectory \\(\\gamma:[0,1]\\to\\mathbb{R}^d\\) with \\(\\gamma(0)=x\\), \\(\\gamma(1)=x_1\\). The variational problem is</p> \\[ \\min_{\\gamma}\\ \\int_0^1 \\|\\dot\\gamma(t)\\|^2\\,dt \\quad\\text{s.t.}\\quad \\gamma(0)=x,\\ \\gamma(1)=x_1. \\tag{59} \\] <p>The Euler\u2013Lagrange equation for the Lagrangian \\(L(\\gamma,\\dot\\gamma)=\\|\\dot\\gamma\\|^2\\) gives \\(\\ddot\\gamma(t)=0\\), hence \\(\\gamma(t)\\) must be a straight line. Enforcing the boundary conditions yields</p> \\[ \\psi_t(x\\mid x_1) = (1-t)\\,x + t\\,x_1. \\tag{60} \\] <p>This is the linear conditional flow. It minimizes the Jensen upper bound \\(\\tag{58}\\) among conditional flows (and in a degenerate target case \\(q=\\delta_{x_1}\\), it coincides with the exact OT solution).</p> <p>One additional useful consequence is an explicit kinetic-energy bound:</p> \\[ \\int_0^1 \\mathbb{E}\\big[\\|u_t(X_t)\\|^2\\big]\\,dt \\;\\le\\; \\mathbb{E}\\big[\\|X_1-X_{0\\mid 1}\\|^2\\big], \\tag{61} \\] <p>where \\((X_{0\\mid 1},X_1)\\sim\\pi_{0,1}\\). This explains why linear / affine conditional flows are often a good default: they encourage straight trajectories and keep the implied marginal kinetic energy controlled.</p>"},{"location":"posts/introduction-B-flow-matching.html#b26-affine-conditional-flows","title":"B2.6 Affine conditional flows","text":"<p>In B2.5, the linear conditional flow emerged as the minimizer of a (tight) upper bound on the marginal kinetic energy. A natural generalization is the family of affine conditional flows, which keep the conditional dynamics simple while retaining enough flexibility to shape the probability path.</p>"},{"location":"posts/introduction-B-flow-matching.html#setup-an-affine-conditional-flow-with-a-scheduler","title":"Setup: an affine conditional flow with a scheduler","text":"<p>Define a conditional flow of the form</p> \\[ \\psi_t(x\\mid x_1) := \\alpha_t\\,x_1 + \\sigma_t\\,x, \\tag{62} \\] <p>where \\(\\alpha_t,\\sigma_t:[0,1]\\to[0,1]\\) are smooth \u201cschedulers\u201d satisfying the endpoint constraints</p> \\[ \\alpha_0=0,\\quad \\alpha_1=1,\\qquad \\sigma_0=1,\\quad \\sigma_1=0, \\tag{63} \\] <p>and strict monotonicity on \\((0,1)\\),</p> \\[ \\dot\\alpha_t&gt;0,\\qquad \\dot\\sigma_t&lt;0,\\qquad t\\in(0,1). \\tag{64} \\] <p>For each fixed \\(t\\in[0,1)\\), \\(\\psi_t(\\cdot\\mid x_1)\\) is an affine (hence smooth) map in \\(x\\), and it satisfies the same \u201cendpoint-conditioning\u201d spirit as \\(\\tag{47}\\): it is the identity at \\(t=0\\) and collapses to \\(x_1\\) as \\(t\\uparrow 1\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#labels-marginal-velocity-and-the-cfm-loss","title":"Labels, marginal velocity, and the CFM loss","text":"<p>Under the independent coupling \\(\\pi_{0,1}(x_0,x_1)=p(x_0)\\,q(x_1)\\), we can sample \\(X_0\\sim p\\), \\(X_1\\sim q\\), and define</p> \\[ X_t := \\psi_t(X_0\\mid X_1) = \\alpha_t X_1 + \\sigma_t X_0. \\tag{65} \\] <p>Differentiating \\(\\psi_t\\) in time gives a tractable conditional-velocity label along the sampled pair:</p> \\[ \\dot\\psi_t(X_0\\mid X_1) = \\dot\\alpha_t\\,X_1 + \\dot\\sigma_t\\,X_0. \\tag{66} \\] <p>The corresponding marginal generating velocity is the posterior average (cf. \\(\\tag{54}\\)):</p> \\[ u_t(x) = \\mathbb{E}\\!\\left[\\dot\\alpha_t\\,X_1 + \\dot\\sigma_t\\,X_0 \\;\\middle|\\; X_t=x\\right]. \\tag{67} \\] <p>In this affine case, the conditional flow matching objective \\(\\tag{52}\\) becomes simply</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) = \\mathbb{E}_{t,\\,(X_0,X_1)\\sim\\pi_{0,1}} \\Big[ D_\\Phi\\big(\\dot\\alpha_t X_1 + \\dot\\sigma_t X_0,\\ u_{\\theta,t}(X_t)\\big) \\Big], \\qquad X_t=\\alpha_t X_1 + \\sigma_t X_0. \\tag{68} \\] <p>Theorem 6 (Affine conditional flows generate a valid marginal path). Assume that \\(q\\) has bounded support. Assume that \\(p\\in C^1(\\mathbb{R}^d)\\) is strictly positive and has finite second moments. Let the coupling be independent, \\(\\pi_{0,1}(x_0,x_1)=p(x_0)\\,q(x_1)\\). Let \\(p_{t\\mid 1}(x\\mid x_1)\\) be defined by the conditional-flow push-forward \\(\\tag{49}\\) with \\(\\psi_t\\) given by \\(\\tag{62}\\), and define the marginal path by mixing over \\(x_1\\) as in \\(\\tag{69}\\). Then the marginal velocity field \\(u_t\\) defined by \\(\\tag{67}\\) generates the marginal probability path \\((p_t)_{t\\in[0,1)}\\), which interpolates \\(p\\) and \\(q\\).</p> \\[ p_t(x) := \\int_{\\mathbb{R}^d} p_{t\\mid 1}(x\\mid x_1)\\,q(x_1)\\,dx_1. \\tag{69} \\]"},{"location":"posts/introduction-B-flow-matching.html#what-theorem-6-is-saying-in-practice","title":"What Theorem 6 is saying (in practice)","text":"<p>Using Corollary 1, one can show (under mild regularity/integrability assumptions, e.g. \\(q\\) bounded support and \\(p\\in C^1(\\mathbb{R}^d)\\) strictly positive with finite second moments) that the marginal velocity \\(u_t\\) in \\(\\tag{67}\\) indeed generates the marginal path \\(p_t\\) interpolating \\(p\\) and \\(q\\). Informally: affine conditional flows give a broad, still-checkable family of conditional constructions that produce a legitimate unconditional probability path and a trainable CFM objective.</p>"},{"location":"posts/introduction-B-flow-matching.html#b261-velocity-parameterizations","title":"B2.6.1 Velocity parameterizations","text":"<p>Different parameterizations can be mathematically equivalent (representing the same underlying velocity field or path), yet lead to different optimization dynamics in practice; this subsection treats parameterization choice as an engineering problem of finding what trains best.</p> <p>As a simple example, for the affine conditional flow in \\(\\tag{65}\\), for any \\(t\\in(0,1)\\) such that \\(\\alpha_t&gt;0\\) and \\(\\sigma_t&gt;0\\),</p> \\[ \\begin{aligned} X_t &amp;= \\alpha_t X_1 + \\sigma_t X_0 \\\\ &amp;\\Longleftrightarrow\\quad X_1 = \\frac{X_t-\\sigma_t X_0}{\\alpha_t} \\\\ &amp;\\Longleftrightarrow\\quad X_0 = \\frac{X_t-\\alpha_t X_1}{\\sigma_t}. \\end{aligned} \\tag{70} \\] <p>These identities are simple algebra, but they will be used repeatedly: they are exactly \\(\\tag{70}\\) substituted into the conditional-expectation formula \\(\\tag{67}\\).</p> <p>First, by linearity of conditional expectation, \\(\\tag{67}\\) can be expanded as</p> \\[ u_t(x) = \\dot\\alpha_t\\,\\mathbb{E}[X_1\\mid X_t=x] \\;+\\; \\dot\\sigma_t\\,\\mathbb{E}[X_0\\mid X_t=x]. \\tag{71} \\] <p>Next, taking conditional expectation of \\(X_t=\\alpha_t X_1+\\sigma_t X_0\\) given \\(X_t=x\\) yields</p> \\[ x = \\alpha_t\\,\\mathbb{E}[X_1\\mid X_t=x] \\;+\\; \\sigma_t\\,\\mathbb{E}[X_0\\mid X_t=x], \\tag{72} \\] <p>and therefore the two equivalent rearrangements</p> \\[ \\mathbb{E}[X_1\\mid X_t=x] = \\frac{x-\\sigma_t\\,\\mathbb{E}[X_0\\mid X_t=x]}{\\alpha_t}, \\tag{73} \\] \\[ \\mathbb{E}[X_0\\mid X_t=x] = \\frac{x-\\alpha_t\\,\\mathbb{E}[X_1\\mid X_t=x]}{\\sigma_t}. \\tag{74} \\] <p>Plugging \\(\\tag{73}\\) or \\(\\tag{74}\\) into \\(\\tag{71}\\) gives two equivalent parameterizations of the same marginal velocity:</p> \\[ u_t(x) = \\frac{\\dot\\sigma_t}{\\sigma_t}\\,x \\;+\\; \\left(\\dot\\alpha_t - \\alpha_t\\,\\frac{\\dot\\sigma_t}{\\sigma_t}\\right)\\mathbb{E}[X_1\\mid X_t=x], \\tag{75} \\] \\[ u_t(x) = \\frac{\\dot\\alpha_t}{\\alpha_t}\\,x \\;+\\; \\left(\\dot\\sigma_t - \\sigma_t\\,\\frac{\\dot\\alpha_t}{\\alpha_t}\\right)\\mathbb{E}[X_0\\mid X_t=x]. \\tag{76} \\] <p>where we have used the basic identity \\(\\mathbb{E}[Z\\mid Z=z]=z\\). Next, denote the deterministic conditional-mean predictors</p> \\[ x_{1\\mid t}(x) := \\mathbb{E}[X_1\\mid X_t=x] \\qquad\\text{(the \\(x_1\\)-prediction / target)}, \\tag{77} \\] \\[ x_{0\\mid t}(x) := \\mathbb{E}[X_0\\mid X_t=x] \\qquad\\text{(the \\(x_0\\)-prediction / source)}. \\tag{78} \\] <p>These provide two additional ways to parameterize \\(u_t\\): via the target prediction \\(x_{1\\mid t}\\) and via the source prediction \\(x_{0\\mid t}\\), by plugging \\(\\tag{77}\\)\u2013\\(\\tag{78}\\) into \\(\\tag{75}\\)\u2013\\(\\tag{76}\\).</p> <p>Sanity check (your interpretation). Your statement is essentially correct with one important qualifier: given paired endpoints \\((X_0,X_1)\\) and a known construction of \\(X_t\\) from the pair, conditional-matching losses let us learn many useful conditional expectations of the form \\(\\mathbb{E}[f_t(X_0,X_1)\\mid X_t=x]\\), which include \\(x_{1\\mid t}\\), \\(x_{0\\mid t}\\), and (through identities like \\(\\tag{75}\\)\u2013\\(\\tag{76}\\)) the marginal velocity \\(u_t\\). For a score \\(\\nabla_x\\log p_t(x)\\), this is only true when the score can be expressed (or closely approximated) as such a conditional expectation for a tractable choice of \\(f_t\\) (as happens in diffusion/denoising constructions). In general, \u201chaving pairs\u201d alone does not automatically make the score a conditional expectation of a known \\(f_t(X_0,X_1)\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#matching-vs-conditional-matching-a-general-recipe","title":"Matching vs. conditional matching (a general recipe)","text":"<p>Let \\(f_t(X_0,X_1)\\in\\mathbb{R}^m\\) be any time-dependent random vector that we can evaluate on paired samples, and define the corresponding conditional expectation function</p> \\[ g_t(x) := \\mathbb{E}\\big[f_t(X_0,X_1)\\mid X_t=x\\big]. \\tag{79} \\] <p>If we could evaluate \\(g_t(X_t)\\), we could fit a model \\(g_{\\theta,t}\\) via the \u201cmatching\u201d objective</p> \\[ \\mathcal{L}_{\\mathrm{M}}(\\theta) := \\mathbb{E}_{t\\sim U[0,1],\\,X_t\\sim p_t} \\Big[ D_\\Phi\\big(g_t(X_t),\\,g_{\\theta,t}(X_t)\\big) \\Big]. \\tag{80} \\] <p>But \\(g_t\\) is typically intractable. Conditional matching replaces the intractable label \\(g_t(X_t)\\) by the tractable paired label \\(f_t(X_0,X_1)\\):</p> \\[ \\mathcal{L}_{\\mathrm{CM}}(\\theta) := \\mathbb{E}_{t\\sim U[0,1],\\,(X_0,X_1)\\sim\\pi_{0,1}} \\Big[ D_\\Phi\\big(f_t(X_0,X_1),\\,g_{\\theta,t}(X_t)\\big) \\Big], \\qquad X_t=\\psi_t(X_0\\mid X_1). \\tag{81} \\] <p>Theorem 7 (Gradient equivalence for conditional matching). For Bregman divergences \\(D_\\Phi\\) and under suitable regularity, the losses \\(\\mathcal{L}_{\\mathrm{M}}\\) and \\(\\mathcal{L}_{\\mathrm{CM}}\\) have the same gradients: \\(\\nabla_\\theta \\mathcal{L}_{\\mathrm{M}}(\\theta)=\\nabla_\\theta \\mathcal{L}_{\\mathrm{CM}}(\\theta)\\). In particular, the population minimizer satisfies \\(g_{\\theta,t}(x)=g_t(x)=\\mathbb{E}[f_t(X_0,X_1)\\mid X_t=x]\\).</p> <p>This is exactly the mechanism we have already used for velocities: choosing \\(f_t(X_0,X_1)=\\dot\\psi_t(X_0\\mid X_1)\\) yields \\(g_t(x)=u_t(x)\\); choosing \\(f_t(X_0,X_1)=X_1\\) yields \\(g_t(x)=x_{1\\mid t}(x)\\); and choosing \\(f_t(X_0,X_1)=X_0\\) yields \\(g_t(x)=x_{0\\mid t}(x)\\).</p> <p></p>"},{"location":"posts/introduction-B-flow-matching.html#b262-post-training-velocity-scheduler-change","title":"B2.6.2 Post-training velocity scheduler change","text":"<p>Affine conditional flows admit a useful \u201cscheduler transfer\u201d trick: after training a velocity model under one scheduler \\((\\alpha_t,\\sigma_t)\\), we can reuse the same trained field to sample under a different scheduler \\((\\bar\\alpha_r,\\bar\\sigma_r)\\). In other words, the scheduler used for training and the scheduler used for inference need not coincide.</p>"},{"location":"posts/introduction-B-flow-matching.html#scaletime-st-transformation-between-two-affine-conditional-flows","title":"Scale\u2013time (ST) transformation between two affine conditional flows","text":"<p>Let the \u201cold\u201d affine conditional flow be</p> \\[ \\psi_t(x_0\\mid x_1) := \\alpha_t\\,x_1 + \\sigma_t\\,x_0, \\tag{82} \\] <p>and the \u201cnew\u201d one be</p> \\[ \\bar\\psi_r(x_0\\mid x_1) := \\bar\\alpha_r\\,x_1 + \\bar\\sigma_r\\,x_0. \\tag{83} \\] <p>We relate them by a scale\u2013time transform: choose functions \\(t_r\\in[0,1]\\) and \\(s_r\\ge 0\\) such that</p> \\[ \\bar\\psi_r(x_0\\mid x_1) = s_r\\,\\psi_{t_r}(x_0\\mid x_1). \\tag{84} \\] <p>Matching the coefficients of \\(x_1\\) and \\(x_0\\) in \\(\\tag{84}\\) yields \\(\\bar\\alpha_r = s_r\\alpha_{t_r}\\) and \\(\\bar\\sigma_r = s_r\\sigma_{t_r}\\). Dividing these equations suggests introducing the (affine) signal-to-noise ratio</p> \\[ \\rho(t) := \\frac{\\alpha_t}{\\sigma_t}, \\qquad \\bar\\rho(r) := \\frac{\\bar\\alpha_r}{\\bar\\sigma_r}, \\tag{85} \\] <p>and assuming \\(\\rho\\) is invertible on \\([0,1)\\) (which typically holds for strictly increasing \\(\\alpha_t\\) and strictly decreasing \\(\\sigma_t\\) on \\((0,1)\\)). Then</p> \\[ t_r = \\rho^{-1}\\!\\big(\\bar\\rho(r)\\big), \\qquad s_r = \\frac{\\bar\\sigma_r}{\\sigma_{t_r}}. \\tag{86} \\]"},{"location":"posts/introduction-B-flow-matching.html#transforming-the-marginal-velocity-field","title":"Transforming the marginal velocity field","text":"<p>Let \\(X_t:=\\psi_t(X_0\\mid X_1)\\) be the old conditional flow and \\(\\bar X_r:=\\bar\\psi_r(X_0\\mid X_1)\\) the new one, with the same endpoint coupling \\((X_0,X_1)\\sim\\pi_{0,1}\\). By \\(\\tag{84}\\), we have \\(\\bar X_r = s_r X_{t_r}\\). Differentiating in \\(r\\) gives</p> \\[ \\frac{d}{dr}\\bar X_r = \\dot s_r\\,X_{t_r} + s_r\\,\\dot t_r\\,\\frac{d}{dt}X_t\\big|_{t=t_r}. \\tag{87} \\] <p>Define the old marginal velocity \\(u_t(x):=\\mathbb{E}[\\frac{d}{dt}X_t\\mid X_t=x]\\) and the new one \\(\\bar u_r(x):=\\mathbb{E}[\\frac{d}{dr}\\bar X_r\\mid \\bar X_r=x]\\). Conditioning \\(\\bar X_r=x\\) implies \\(X_{t_r}=x/s_r\\), so taking conditional expectations in \\(\\tag{87}\\) yields the closed-form transformation</p> \\[ \\bar u_r(x) = \\frac{\\dot s_r}{s_r}\\,x \\;+\\; s_r\\,\\dot t_r\\,u_{t_r}\\!\\left(\\frac{x}{s_r}\\right). \\tag{88} \\] <p>Operationally: if you trained a neural model \\(u_{\\theta,t}(x)\\approx u_t(x)\\) under the old scheduler, you can sample under the new scheduler by evaluating \\(u_{\\theta,t_r}(x/s_r)\\) and applying the rescaling in \\(\\tag{88}\\). This is one concrete sense in which \u201cthe scheduler can be changed post-training\u201d.</p>"},{"location":"posts/introduction-B-flow-matching.html#equivalence-at-the-endpoint-why-scheduler-changes-can-preserve-t1-samples","title":"Equivalence at the endpoint (why scheduler changes can preserve \\(t=1\\) samples)","text":"<p>Under mild conditions (and to avoid an infinite \\(\\rho(1)\\), often by taking \\(\\sigma_1=\\bar\\sigma_1=\\varepsilon&gt;0\\) and letting \\(\\varepsilon\\downarrow 0\\) in the end), one can show that the transformed flow reaches the same endpoint map at \\(t=1\\) (informally, different schedulers are reparameterizations of the same transport). Practically, this motivates trying different inference schedulers even when the training scheduler is fixed: the change mainly affects the numerics / stiffness / step allocation of the ODE, not the intended endpoint distribution.</p>"},{"location":"posts/introduction-B-flow-matching.html#b263-gaussian-paths-and-the-score","title":"B2.6.3 Gaussian paths and the score","text":"<p>At the time of writing, the most commonly used affine probability paths in diffusion/flow practice are built from:</p> <ul> <li>the independent coupling \\(\\pi_{0,1}(x_0,x_1)=p(x_0)\\,q(x_1)\\),</li> <li>a Gaussian source \\(p\\) (so \\(X_0\\) is Gaussian), and</li> <li>an affine conditional flow \\(X_t=\\alpha_t X_1+\\sigma_t X_0\\).</li> </ul> <p>Because Gaussians are closed under affine transformations, the resulting conditional probability path is Gaussian:</p> \\[ p_{t\\mid 1}(x\\mid x_1) = \\mathcal{N}\\!\\big(x\\mid \\alpha_t x_1,\\ \\sigma_t^2 I\\big). \\tag{89} \\] <p>The marginal \\(p_t\\) is then a Gaussian convolution / mixture:</p> \\[ p_t(x) = \\int_{\\mathbb{R}^d}\\mathcal{N}\\!\\big(x\\mid \\alpha_t x_1,\\ \\sigma_t^2 I\\big)\\,q(x_1)\\,dx_1. \\tag{90} \\] <p>This family subsumes the marginal probability paths used by standard diffusion models: in diffusion, generation is stochastic (an SDE), but the prescribed forward noising process defines the same marginal densities \\(p_t\\). In \u201cflow language\u201d, one can equivalently generate the same marginals using the probability flow ODE, whose velocity depends on the score \\(\\nabla_x\\log p_t(x)\\).</p> <p>Concretely, a diffusion model specifies a forward SDE</p> \\[ dX_t = f(t,X_t)\\,dt + g(t)\\,dW_t, \\tag{91} \\] <p>whose marginals \\(p_t\\) satisfy the Fokker\u2013Planck equation. The same marginals are generated by the deterministic probability flow ODE</p> \\[ \\frac{d}{dt}X_t = f(t,X_t) -\\frac12 g(t)^2\\,\\nabla_x\\log p_t(X_t). \\tag{92} \\] <p>In the Gaussian-mixture path \\(\\tag{90}\\), the score can be written in terms of the conditional-mean predictors \\(x_{1\\mid t}(x)=\\mathbb{E}[X_1\\mid X_t=x]\\) and \\(x_{0\\mid t}(x)=\\mathbb{E}[X_0\\mid X_t=x]\\):</p> \\[ \\nabla_x \\log p_t(x) = -\\frac{1}{\\sigma_t^2}\\Big(x-\\alpha_t\\,\\mathbb{E}[X_1\\mid X_t=x]\\Big) = \\frac{\\alpha_t}{\\sigma_t^2}\\,x_{1\\mid t}(x) - \\frac{1}{\\sigma_t^2}\\,x, \\tag{93} \\] <p>One useful quantity admitting a simple form in this Gaussian case is also the conditional score. From \\(\\tag{89}\\),</p> \\[ \\nabla_x\\log p_{t\\mid 1}(x\\mid x_1) = -\\frac{1}{\\sigma_t^2}\\big(x-\\alpha_t x_1\\big). \\tag{94} \\] <p>The marginal score \\(\\nabla_x\\log p_t(x)\\) can be derived from \\(\\tag{90}\\) by straightforward calculus:</p> \\[ \\nabla_x\\log p_t(x) = \\frac{1}{p_t(x)} \\int_{\\mathbb{R}^d}\\nabla_x p_{t\\mid 1}(x\\mid x_1)\\,q(x_1)\\,dx_1, \\tag{95} \\] \\[ \\nabla_x\\log p_t(x) = \\int_{\\mathbb{R}^d}\\nabla_x\\log p_{t\\mid 1}(x\\mid x_1)\\; \\frac{p_{t\\mid 1}(x\\mid x_1)\\,q(x_1)}{p_t(x)}\\,dx_1 = \\mathbb{E}\\big[\\nabla_x\\log p_{t\\mid 1}(X_t\\mid X_1)\\mid X_t=x\\big], \\tag{96} \\] <p>and therefore, using \\(\\tag{94}\\),</p> \\[ \\nabla_x\\log p_t(x) = \\mathbb{E}\\!\\left[-\\frac{1}{\\sigma_t^2}\\big(X_t-\\alpha_t X_1\\big)\\;\\middle|\\;X_t=x\\right]. \\tag{97} \\] <p>If we instantiate the affine Gaussian path as \\(X_t=\\alpha_t X_1+\\sigma_t X_0\\) with \\(X_0\\sim\\mathcal{N}(0,I)\\) independent of \\(X_1\\), then \\(X_t-\\alpha_t X_1=\\sigma_t X_0\\), so \\(\\tag{97}\\) simplifies to</p> \\[ \\nabla_x\\log p_t(x) = \\mathbb{E}\\!\\left[-\\frac{1}{\\sigma_t}X_0\\;\\middle|\\;X_t=x\\right] = -\\frac{1}{\\sigma_t}\\,x_{0\\mid t}(x). \\tag{98} \\] <p>In diffusion terminology, \\(x_{0\\mid t}(x)\\) is the noise prediction (often called \\(\\varepsilon\\)-prediction). Equation \\(\\tag{98}\\) gives an explicit conversion between the score and the noise-prediction parameterization for Gaussian affine paths (cf. Table 1).</p> <p>Two widely used diffusion-style choices of schedulers (Song et al., 2021) can be expressed in this affine-path language (up to the time direction / endpoint conventions):</p> <ul> <li>VP-style (noise-to-data, heuristic at \\(t=0\\)): \\(\\alpha_t\\equiv 1\\), with \\(\\sigma_1=0\\) and \\(\\sigma_0\\gg 1\\) so that \\(p_0(x)=\\int \\mathcal{N}(x\\mid x_1,\\sigma_0^2 I)\\,q(x_1)\\,dx_1\\) is close to a known Gaussian.</li> <li>VE-style: choose a decreasing \\(\\beta_t\\) with \\(\\beta_0\\gg 1\\) and \\(\\beta_1=0\\), and set</li> </ul> \\[   \\alpha_t = e^{-\\beta_t/2},   \\qquad   \\sigma_t = \\sqrt{1-e^{-\\beta_t}}.   \\tag{101} \\] <p>Kinetic optimality of the marginal velocity (Gaussian paths). For Gaussian affine paths, the marginal velocity can be written directly in terms of the score. Starting from \\(\\tag{76}\\), \\(u_t(x)=\\frac{\\dot\\alpha_t}{\\alpha_t}x+\\left(\\dot\\sigma_t-\\sigma_t\\frac{\\dot\\alpha_t}{\\alpha_t}\\right)x_{0\\mid t}(x)\\), and using \\(x_{0\\mid t}(x)=-\\sigma_t\\nabla_x\\log p_t(x)\\) from \\(\\tag{98}\\), we obtain</p> \\[ u_t(x) = \\frac{\\dot\\alpha_t}{\\alpha_t}\\,x \\;+\\; \\left(\\frac{\\dot\\alpha_t}{\\alpha_t}\\sigma_t^2-\\sigma_t\\dot\\sigma_t\\right)\\nabla_x\\log p_t(x). \\tag{99} \\] <p>Equivalently, \\(u_t\\) is a gradient field:</p> \\[ u_t(x) = \\nabla_x\\left( \\frac{\\dot\\alpha_t}{2\\alpha_t}\\,\\|x\\|^2 \\;+\\; \\left(\\frac{\\dot\\alpha_t}{\\alpha_t}\\sigma_t^2-\\sigma_t\\dot\\sigma_t\\right)\\log p_t(x) \\right). \\tag{100} \\] <p>This \u201cgradient form\u201d is exactly what one expects from kinetic-energy minimization with a fixed density path: among all velocity fields that generate the same \\((p_t)\\), the kinetic-energy minimizer can be taken to be (a version of) a gradient field (see, e.g., discussions of dynamic OT / Benamou\u2013Brenier and the role of potentials).</p> <p>Takeaway. Gaussian affine paths make the \u201cdiffusion \u2194 flow\u201d connection explicit: the same marginal path \\((p_t)\\) can be generated stochastically (SDE) or deterministically (probability flow ODE), and the score \\(\\nabla_x\\log p_t\\) is directly tied to learnable predictors \\(x_{1\\mid t}\\) or \\(x_{0\\mid t}\\) via \\(\\tag{93}\\) and \\(\\tag{98}\\), with the marginal velocity admitting the explicit score-based form \\(\\tag{99}\\).</p> <p>To summarize the most common parameterizations used in practice (in this Gaussian affine setting), define the scalar coefficient \\(c_t := \\frac{\\dot\\alpha_t}{\\alpha_t}\\sigma_t^2 - \\sigma_t\\dot\\sigma_t\\) as in \\(\\tag{99}\\). Then we have the following \u201cnetwork output \\(\\leftrightarrow\\) math target \\(\\leftrightarrow\\) conversions\u201d:</p> Parameterization Network output Mathematical target Relation to score \\(s_t(x):=\\nabla_x\\log p_t(x)\\) Relation to velocity \\(u_t(x)\\) \\(\\varepsilon\\)-prediction \\(\\hat\\varepsilon_\\theta(x_t,t)\\) \\(\\mathbb{E}[X_0\\mid X_t=x_t]\\) (here \\(X_0\\equiv \\varepsilon\\)) \\(\\hat s_\\theta(x_t,t)= -\\hat\\varepsilon_\\theta(x_t,t)/\\sigma_t\\) (from \\(\\tag{98}\\)) \\(\\hat u_\\theta(x_t,t)=\\frac{\\dot\\alpha_t}{\\alpha_t}x_t + c_t\\,\\hat s_\\theta(x_t,t)\\) (from \\(\\tag{99}\\)) \\(x_0\\)-prediction \\(\\hat x_{0,\\theta}(x_t,t)\\) \\(x_{0\\mid t}(x_t)=\\mathbb{E}[X_0\\mid X_t=x_t]\\) (\\(\\tag{78}\\)) \\(\\hat s_\\theta(x_t,t)= -\\hat x_{0,\\theta}(x_t,t)/\\sigma_t\\) (\\(\\tag{98}\\)) same as above via \\(\\hat s_\\theta\\) \\(x_1\\)-prediction \\(\\hat x_{1,\\theta}(x_t,t)\\) \\(x_{1\\mid t}(x_t)=\\mathbb{E}[X_1\\mid X_t=x_t]\\) (\\(\\tag{77}\\)) \\(\\hat s_\\theta(x_t,t)=\\frac{\\alpha_t}{\\sigma_t^2}\\hat x_{1,\\theta}(x_t,t)-\\frac{1}{\\sigma_t^2}x_t\\) (\\(\\tag{93}\\)) \\(\\hat u_\\theta(x_t,t)=\\frac{\\dot\\alpha_t}{\\alpha_t}x_t + c_t\\,\\hat s_\\theta(x_t,t)\\) score-prediction \\(\\hat s_\\theta(x_t,t)\\) \\(s_t(x_t)=\\nabla_x\\log p_t(x_t)\\) direct \\(\\hat u_\\theta(x_t,t)=\\frac{\\dot\\alpha_t}{\\alpha_t}x_t + c_t\\,\\hat s_\\theta(x_t,t)\\) (\\(\\tag{99}\\)) velocity-prediction \\(\\hat u_\\theta(x_t,t)\\) \\(u_t(x_t)\\) (FM target) \\(\\hat s_\\theta(x_t,t)=\\big(\\hat u_\\theta(x_t,t)-\\frac{\\dot\\alpha_t}{\\alpha_t}x_t\\big)/c_t\\) (when \\(c_t\\ne 0\\)) direct <p>All entries above are mathematically equivalent ways to represent the same underlying objects for the Gaussian affine path; they are not guaranteed to be equivalent outside this setting.</p> <pre><code>                Gaussian Affine Path\n            X_t = \u03b1_t X\u2081 + \u03c3_t X\u2080\n                        \u2502\n                        \u25bc\n                Conditional Expectations\n                        \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u25bc                \u25bc                \u25bc\n   x1-pred          x0-pred           score\n  E[X1|X_t=x]     E[X0|X_t=x]     \u2207 log p_t(x)\n       \u2502                \u2502                \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 linear transforms \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n                           velocity u_t(x)\n                                \u2502\n                                \u25bc\n                            ODE sampling\n</code></pre>"},{"location":"posts/introduction-B-flow-matching.html#b27-data-couplings","title":"B2.7 Data couplings","text":"<p>Flow Matching requires a way to sample paired endpoints \\((X_0,X_1)\\) whose marginals match the chosen source and target distributions. Throughout this note, we typically denote the source by \\(p\\) and the target/data by \\(q\\). A data coupling is any joint distribution \\(\\pi_{0,1}\\) on \\(\\mathbb{R}^d\\times\\mathbb{R}^d\\) such that</p> \\[ (X_0,X_1)\\sim\\pi_{0,1}, \\qquad X_0\\sim p,\\ \\ X_1\\sim q. \\tag{102} \\] <p>The coupling \\(\\pi_{0,1}\\) is not \u201cjust a detail\u201d: once you fix a conditional flow construction \\(X_t=\\psi_t(X_0\\mid X_1)\\) (or more generally \\(X_t=\\psi_t(X_0,X_1)\\)), the resulting training labels (e.g. \\(\\dot\\psi_t(X_0\\mid X_1)\\)) and the induced marginal target \\(u_t(x)=\\mathbb{E}[\\dot\\psi_t(X_0\\mid X_1)\\mid X_t=x]\\) are both taken with respect to \\((X_0,X_1)\\sim\\pi_{0,1}\\). Changing \\(\\pi_{0,1}\\) changes the teacher signal, even if \\(p\\) and \\(q\\) are unchanged.</p>"},{"location":"posts/introduction-B-flow-matching.html#common-choices","title":"Common choices","text":"<ul> <li>Independent coupling: \\(\\pi_{0,1}=p\\otimes q\\). Sample \\(X_0\\sim p\\) and \\(X_1\\sim q\\) independently. This is the simplest and most common default, and it pairs naturally with affine/Gaussian paths. A drawback is that \\(\\|X_1-X_0\\|\\) can be large, which can make conditional labels higher-variance / harder to regress.</li> <li>Heuristic mini-batch pairing: in practice, one often samples mini-batches from \\(p\\) and \\(q\\) and pairs them by a simple rule (same index, random permutation, nearest neighbor within the batch, etc.). This implicitly defines an empirical coupling and can affect variance and stability.</li> <li>Structured / OT-inspired coupling: choose \\(\\pi_{0,1}\\) to reduce a transport cost such as \\(\\mathbb{E}_{\\pi_{0,1}}\\|X_1-X_0\\|^2\\). This often leads to \u201cshorter\u201d pairings, which can produce straighter / lower-energy sample trajectories and easier regression targets, at the cost of computing (or approximating) the coupling.</li> </ul>"},{"location":"posts/introduction-B-flow-matching.html#what-changes-when-you-change-pi_01","title":"What changes when you change \\(\\pi_{0,1}\\)?","text":"<p>Even when the endpoint marginals \\(p,q\\) are fixed, changing \\(\\pi_{0,1}\\) changes the training pairs and therefore the induced conditional/marginal objects. Concretely, for a fixed conditional flow map \\(\\psi_t\\), the conditional label \\(\\dot\\psi_t(X_0\\mid X_1)\\) is evaluated on \\((X_0,X_1)\\sim\\pi_{0,1}\\), and the marginal target is a conditional expectation under the induced random variable \\(X_t\\). So \\(\\pi_{0,1}\\) is a modeling choice that trades off:</p> <ul> <li>computational cost (easy sampling vs. coupling computation),</li> <li>target variance / regression difficulty,</li> <li>and the geometric character of the induced trajectories.</li> </ul> <p>In short: FM becomes a supervised regression problem only after you choose a coupling. Different couplings give different teacher signals, even when they share the same endpoint marginals.</p>"},{"location":"posts/introduction-B-flow-matching.html#b28-conditional-generation-and-guidance","title":"B2.8 Conditional generation and guidance","text":"<p>We now consider conditional generation under a guidance variable. Assume target samples are labeled \\((x_1,y)\\), where \\(x_1\\in\\mathbb{R}^d\\), \\(y\\in\\mathcal{Y}\\subseteq\\mathbb{R}^k\\), and \\(t\\in[0,1)\\).</p>"},{"location":"posts/introduction-B-flow-matching.html#conditional-models-learn-qx_1mid-y-directly","title":"Conditional models (learn \\(q(x_1\\mid y)\\) directly)","text":"<p>A natural conditional objective is to learn to sample from the conditional data distribution \\(q(x_1\\mid y)\\). Following the same \u201cpath + velocity\u201d blueprint as the unconditional case, we prescribe (for each fixed \\(y\\)) a conditional probability path \\((p_{t\\mid Y}(\\cdot\\mid y))_{t\\in[0,1)}\\) interpolating \\(p_{0\\mid Y}(\\cdot\\mid y)=p(\\cdot)\\) and \\(p_{1\\mid Y}(\\cdot\\mid y)=q(\\cdot\\mid y)\\).</p> <p>One convenient construction is to reuse an \\(x_1\\)-conditioned path \\(p_{t\\mid 1}(x\\mid x_1)\\) that does not depend on \\(y\\), and define the guided path by marginalizing over \\(q(x_1\\mid y)\\):</p> \\[ p_{t\\mid Y}(x\\mid y) := \\int_{\\mathbb{R}^d} p_{t\\mid 1}(x\\mid x_1)\\,q(x_1\\mid y)\\,dx_1. \\tag{103} \\] <p>Under the same regularity assumptions as in the unconditional marginalization trick, the corresponding guided marginal velocity field is the posterior-weighted conditional velocity:</p> \\[ u_t(x\\mid y) = \\int_{\\mathbb{R}^d} u_t(x\\mid x_1)\\,p_{1\\mid t,Y}(x_1\\mid x,y)\\,dx_1, \\tag{104} \\] <p>where Bayes\u2019 rule gives the posterior</p> \\[ p_{1\\mid t,Y}(x_1\\mid x,y) = \\frac{p_{t\\mid 1}(x\\mid x_1)\\,q(x_1\\mid y)}{p_{t\\mid Y}(x\\mid y)}. \\tag{105} \\] <p>In practice, we train a single network \\(u_{\\theta,t}:\\mathbb{R}^d\\times\\mathbb{R}^k\\to\\mathbb{R}^d\\) to approximate \\(u_t(x\\mid y)\\) for all \\(y\\). If we build \\(p_{t\\mid 1}\\) via a conditional flow \\(X_t=\\psi_t(X_0\\mid X_1)\\), then the guided CFM objective has the same supervised form as before, just with \\(y\\) as an extra input:</p> \\[ \\mathcal{L}_{\\mathrm{CFM}}(\\theta) = \\mathbb{E}_{t,\\,(X_0,X_1,Y)\\sim\\pi_{0,1,Y}} D\\!\\Big(\\dot\\psi_t(X_0\\mid X_1),\\ u_{\\theta,t}(X_t\\mid Y)\\Big). \\tag{106} \\] <p>Here \\(\\pi_{0,1,Y}\\) is a joint coupling consistent with \\(Y\\sim p_Y\\) and \\(X_1\\sim q(\\cdot\\mid Y)\\) (and \\(X_0\\sim p\\)).</p>"},{"location":"posts/introduction-B-flow-matching.html#classifier-guidance-and-classifier-free-guidance-score-based-view","title":"Classifier guidance and classifier-free guidance (score-based view)","text":"<p>For Gaussian affine paths, we have a linear relation between velocity and score (cf. Table 1): there exist scalar schedules \\(a_t,b_t\\) such that</p> \\[ u_t(x) = a_t x + b_t\\,\\nabla_x\\log p_t(x). \\tag{107} \\] <p>The same form holds conditionally:</p> \\[ u_t(x\\mid y) = a_t x + b_t\\,\\nabla_x\\log p_{t\\mid Y}(x\\mid y). \\tag{108} \\] <p>Using Bayes\u2019 rule, \\(p_{t\\mid Y}(x\\mid y)\\propto p_{Y\\mid t}(y\\mid x)\\,p_t(x)\\), so taking \\(\\nabla_x\\log\\) yields the key score identity</p> \\[ \\nabla_x\\log p_{t\\mid Y}(x\\mid y) = \\nabla_x\\log p_{Y\\mid t}(y\\mid x) \\;+\\; \\nabla_x\\log p_t(x). \\tag{109} \\] <p>This suggests classifier guidance: train an unconditional model for \\(p_t\\) (hence \\(u_t\\) or \\(\\nabla_x\\log p_t\\)), train a time-dependent classifier \\(p_{Y\\mid t}(y\\mid x)\\), then guide sampling by adding the classifier term:</p> \\[ \\tilde u_t(x\\mid y) = u_t(x) \\;+\\; w\\,b_t\\,\\nabla_x\\log p_{Y\\mid t}(y\\mid x), \\qquad w&gt;0. \\tag{110} \\] <p>Classifier-free guidance (CFG) avoids an explicit classifier by learning conditional and unconditional models together (e.g. by randomly dropping the condition during training). In the velocity parameterization, the standard CFG heuristic takes the convex-combination form</p> \\[ \\tilde u_t(x\\mid y) = (1-w)\\,u_t(x\\mid \\varnothing) + w\\,u_t(x\\mid y), \\tag{111} \\] <p>where \\(\\varnothing\\) denotes a null condition and \\(w\\) is the guidance scale.</p> <p>We will keep this section intentionally lightweight: conditional generation and guidance quickly become an \u201cengineering-meets-theory\u201d topic on its own, and it is worth treating separately once the unconditional FM/CFM story is fully digested.</p>"},{"location":"posts/introduction-C-compare-and-code.html","title":"Section C \u2014 Comparison table + code playbook","text":"<p>This section is a compact algorithm \u2194 code playbook for three mainstream dynamics-based generative model families:</p> <ul> <li>Score-based diffusion (SDE): learn a time-dependent score \\(s_\\theta(x,t)\\) and sample with a reverse-time SDE (often with a predictor\u2013corrector scheme), or deterministically via the probability-flow ODE.</li> <li>Discrete diffusion (DDPM): learn a denoiser parameterization (commonly \\(\\varepsilon_\\theta\\)) and sample a reverse Markov chain.</li> <li>Flow matching (ODE): learn a velocity field \\(v_\\theta(x,t)\\) by regression and sample by ODE integration.</li> </ul> <p>To avoid duplication, we keep derivations elsewhere:</p> <ul> <li>Numerical ODE/SDE solvers: mathematics-foundation.md</li> <li>Continuity / Fokker\u2013Planck and reverse-time constructions: mathematics-foundation.md and diffusion-models-intro.md</li> <li>Flow matching theory (CFM, Theorems 1\u20133, Gaussian paths): diffusion-models-intro.md and introduction-B-flow-matching.md</li> </ul>"},{"location":"posts/introduction-C-compare-and-code.html#c0-notation-shared","title":"C0. Notation (shared)","text":"<p>We work in \\(\\mathbb{R}^D\\).</p> <ul> <li>Data distribution: \\(x_\\text{data}\\sim q(x)\\) (we only have sample access).</li> <li>Simple prior: \\(x_\\text{prior}\\sim p(x)\\) (often \\(p=\\mathcal{N}(0,I)\\)).</li> <li>Discrete time (DDPM): \\(t\\in\\{1,\\dots,T\\}\\).</li> <li>Continuous time (SDE/ODE): \\(t\\in[0,1]\\).</li> <li>Model outputs:</li> <li>score: \\(s_\\theta(x,t)\\approx \\nabla_x\\log p_t(x)\\),</li> <li>noise: \\(\\varepsilon_\\theta(x_t,t)\\approx \\varepsilon\\) in the forward noising formula,</li> <li>velocity: \\(v_\\theta(x,t)\\approx \\dot\\gamma_t\\) along a chosen path \\(\\gamma_t\\).</li> </ul>"},{"location":"posts/introduction-C-compare-and-code.html#c1-comparison-table-what-is-modeled-learned-sampled","title":"C1. Comparison table (what is modeled / learned / sampled)","text":"Aspect Score-based diffusion (SDE) Discrete diffusion (DDPM) Flow matching (ODE) Dynamics type It\u00f4 SDE \\(dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t\\) (forward), sample via reverse-time SDE (or PF-ODE) Forward Markov chain \\(q(x_t\\mid x_{t-1})\\) with designed \\(\\beta_t\\), sample via reverse chain Deterministic ODE \\(\\frac{d}{dt}X_t=v_\\theta(X_t,t)\\) What is designed SDE coefficients \\((f,g)\\) / schedule (e.g., VP/VE) discrete schedule \\(\\beta_t\\) (equiv. \\(\\alpha_t,\\bar\\alpha_t\\)) a probability path (bridge) \\(\\gamma_t\\) and a time grid What is learned \\(s_\\theta(x,t)\\) (score), or equivalent parameterization typically \\(\\varepsilon_\\theta(x_t,t)\\) (noise), sometimes \\(x_{0,\\theta}\\) or \\(v_\\theta\\) \\(v_\\theta(x,t)\\) (velocity) Training inputs sample \\((x_0,t)\\), sample noise \\(\\varepsilon\\), construct \\(x_t\\sim p_t(\\cdot\\mid x_0)\\) in closed form sample \\((x_0,t)\\), sample noise \\(\\varepsilon\\), construct \\(x_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\,\\varepsilon\\) sample endpoints (noise/data) and time \\(t\\), construct \\(x_t=\\gamma_t(x_0,x_1)\\) Supervision target closed-form conditional score \\(\\nabla_{x_t}\\log p(x_t\\mid x_0)\\) (DSM) regression target \\(\\varepsilon\\) in the forward corruption target velocity \\(\\dot\\gamma_t(x_0,x_1)\\) Sampling randomness stochastic (reverse SDE), or deterministic (PF-ODE) stochastic reverse chain (Gaussian transitions) deterministic ODE (any ODE solver) Typical solver Euler\u2013Maruyama + Langevin corrector (PC), or ODE solver for PF-ODE ancestral time stepping Euler / Heun / RK methods (see mathematics-foundation.md)"},{"location":"posts/introduction-C-compare-and-code.html#c2-training-pseudocode-comparison-side-by-side","title":"C2. Training pseudocode comparison (side-by-side)","text":""},{"location":"posts/introduction-C-compare-and-code.html#c21-score-based-diffusion-denoising-score-matching","title":"C2.1 Score-based diffusion (denoising score matching)","text":"<p>Assume a forward SDE is chosen so that the conditional \\(p(x_t\\mid x_0)\\) is tractable (often Gaussian). Then the DSM objective regresses the model score to the closed-form conditional score:</p> \\[ \\mathbb{E}_{t,x_0,x_t}\\Big[\\lambda(t)\\,\\big\\|s_\\theta(x_t,t)-\\nabla_{x_t}\\log p(x_t\\mid x_0)\\big\\|^2\\Big]. \\] <p>Pseudocode:</p> <pre><code>repeat:\n  sample x0 ~ p_data\n  sample t  ~ Uniform(0, 1)\n  sample \u03b5  ~ N(0, I)\n  construct xt ~ p(xt | x0)   # e.g. VE: x0 + \u03c3(t) \u03b5 ; VP: \u221a\u03b1\u0305(t) x0 + \u221a(1-\u03b1\u0305(t)) \u03b5\n  set target score s*(xt,t) = \u2207_{xt} log p(xt | x0)  # closed form\n  loss = \u03bb(t) \u00b7 || s\u03b8(xt,t) - s*(xt,t) ||^2\n  take optimizer step on loss w.r.t. \u03b8\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c22-ddpm-noise-prediction-loss","title":"C2.2 DDPM (noise-prediction loss)","text":"<p>DDPM training commonly regresses \\(\\varepsilon_\\theta\\) to the injected noise in the forward corruption:</p> <pre><code>repeat:\n  sample x0 ~ p_data\n  sample t  ~ Uniform({1, \u2026, T})\n  sample \u03b5  ~ N(0, I)\n  set xt = \u221a\u03b1\u0305_t \u00b7 x0 + \u221a(1-\u03b1\u0305_t) \u00b7 \u03b5\n  loss = || \u03b5 - \u03b5\u03b8(xt, t) ||^2\n  take optimizer step on loss w.r.t. \u03b8\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c23-flow-matching-velocity-regression-on-a-designed-path","title":"C2.3 Flow matching (velocity regression on a designed path)","text":"<p>Choose a bridge \\(\\gamma_t(x_0,x_1)\\) connecting a prior endpoint and a data endpoint, and regress a velocity field to the path derivative \\(\\dot\\gamma_t\\):</p> \\[ \\mathbb{E}_{t,(x_0,x_1)}\\Big[\\|v_\\theta(\\gamma_t(x_0,x_1),t)-\\dot\\gamma_t(x_0,x_1)\\|^2\\Big]. \\] <p>For the linear bridge with \\(x_0\\sim p\\), \\(x_1\\sim q\\),</p> \\[ \\gamma_t(x_0,x_1)=(1-t)x_0+t x_1,\\qquad \\dot\\gamma_t(x_0,x_1)=x_1-x_0. \\] <p>Pseudocode:</p> <pre><code>repeat:\n  sample x1 ~ p_data\n  sample x0 ~ N(0, I)\n  sample t ~ Uniform(0, 1)\n  xt = (1 - t) \u00b7 x0 + t \u00b7 x1\n  target = x1 - x0\n  loss = || v\u03b8(xt, t) - target ||^2\n  take optimizer step on loss w.r.t. \u03b8\n</code></pre> <p>Markov vs continuous path sampling (practical point). In DDPM, training pairs \\((x_t,t)\\) are generated from a discrete Markov chain and indexed by integer \\(t\\). In score-based diffusion and flow matching, \\((x_t,t)\\) is sampled from a continuous-time path in one shot (via a tractable conditional perturbation or an explicit interpolation), without a Markov constraint between adjacent times.</p>"},{"location":"posts/introduction-C-compare-and-code.html#c3-sampling-pseudocode-comparison-side-by-side","title":"C3. Sampling pseudocode comparison (side-by-side)","text":""},{"location":"posts/introduction-C-compare-and-code.html#c31-score-based-diffusion-predictorcorrector-reverse-sde-sampler","title":"C3.1 Score-based diffusion: predictor\u2013corrector reverse-SDE sampler","text":"<pre><code>initialize x ~ N(0, I)  # terminal noise\nfor t = 1 \u2192 \u03b5 (descending):\n  # Predictor: one reverse-SDE step (Euler\u2013Maruyama)\n  sample z ~ N(0, I)\n  x \u2190 x + [f(x,t) - g(t)^2 s\u03b8(x,t)] \u0394t + g(t) \u221a(|\u0394t|) \u00b7 z\n\n  # Corrector: K steps of Langevin at the same t (optional)\n  repeat K times:\n    sample z ~ N(0, I)\n    x \u2190 x + \u03b7_step \u00b7 s\u03b8(x,t) + \u221a(2 \u03b7_step) \u00b7 z\nreturn x\n</code></pre> <p>The reverse-time formulas and the probability-flow ODE are summarized in diffusion-models-intro.md (Chapter 5.5) and in mathematics-foundation.md (Chapter 2).</p>"},{"location":"posts/introduction-C-compare-and-code.html#c32-ddpm-ancestral-reverse-diffusion","title":"C3.2 DDPM: ancestral reverse diffusion","text":"<pre><code>initialize x_T ~ N(0, I)\nfor t = T, \u2026, 1:\n  sample z ~ N(0, I) if t &gt; 1 else 0\n  mean = 1/\u221a\u03b1_t \u00b7 (x_t - (1-\u03b1_t)/\u221a(1-\u03b1\u0305_t) \u00b7 \u03b5\u03b8(x_t, t))\n  x_{t-1} = mean + \u03c3_t \u00b7 z\nreturn x_0\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c33-flow-matching-ode-sampling-by-heun-improved-euler","title":"C3.3 Flow matching: ODE sampling by Heun (improved Euler)","text":"<pre><code>set \u03c4_0 = 0 &lt; \u03c4_1 &lt; \u2026 &lt; \u03c4_S = 1\ninitialize x ~ N(0, I) at t = 0\nfor s = 0, \u2026, S-1:\n  t = \u03c4_s,  t_next = \u03c4_{s+1},  h = t_next - t\n  k1 = v\u03b8(x, t)\n  x_pred = x + h \u00b7 k1\n  k2 = v\u03b8(x_pred, t_next)\n  x = x + (h/2) \u00b7 (k1 + k2)\nreturn x \u2248 sample from p_data\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c4-minimal-pytorch-code-snippets-training-sampling","title":"C4. Minimal PyTorch code snippets (training + sampling)","text":"<p>These snippets are intentionally small and meant to make the variable \u2194 formula correspondence explicit. For generic ODE/SDE solvers, see mathematics-foundation.md.</p>"},{"location":"posts/introduction-C-compare-and-code.html#c41-score-based-diffusion-vevp-schedules-dsm-loss-pc-sampler","title":"C4.1 Score-based diffusion (VE/VP schedules + DSM loss + PC sampler)","text":"<pre><code>import torch\n\n\ndef ve_marginal_std(t, *, sigma_min=0.01, sigma_max=50.0):\n    \"\"\"\n    VE schedule: choose a marginal std \u03c3(t) (not the diffusion coefficient g(t)).\n    t: shape (B,) in [0,1].\n    \"\"\"\n    return sigma_min * (sigma_max / sigma_min) ** t\n\n\ndef vp_beta(t, *, beta_min=0.1, beta_max=20.0):\n    \"\"\"VP noise rate \u03b2(t), t in [0,1].\"\"\"\n    return beta_min + t * (beta_max - beta_min)\n\n\ndef vp_alpha_bar(t, *, beta_min=0.1, beta_max=20.0):\n    \"\"\"\n    \u03b1\u0305(t) = exp(-\u222b_0^t \u03b2(s) ds) for linear \u03b2(s).\n    \"\"\"\n    integral = beta_min * t + 0.5 * (beta_max - beta_min) * t * t\n    return torch.exp(-integral)\n\n\ndef dsm_loss_ve(score_model, x0, t, *, sigma_min=0.01, sigma_max=50.0, weight=None):\n    \"\"\"\n    VE denoising score matching:\n      x_t = x0 + \u03c3(t) \u03b5\n      \u2207_{x_t} log p(x_t|x0) = -(x_t-x0)/\u03c3(t)^2 = -\u03b5/\u03c3(t)\n    \"\"\"\n    eps = torch.randn_like(x0)\n    sigma = ve_marginal_std(t, sigma_min=sigma_min, sigma_max=sigma_max)\n    while sigma.ndim &lt; x0.ndim:\n        sigma = sigma[..., None]\n    xt = x0 + sigma * eps\n    target = -eps / sigma\n    pred = score_model(xt, t)\n    loss = (pred - target).pow(2)\n    if weight is not None:\n        w = weight(t)\n        while w.ndim &lt; loss.ndim:\n            w = w[..., None]\n        loss = w * loss\n    return loss.mean()\n\n\n@torch.no_grad()\ndef langevin_corrector(score_model, x, t, *, snr=0.16, n_steps=1):\n    \"\"\"\n    K steps of overdamped Langevin dynamics at fixed t.\n    Heuristic step size chosen to keep a target SNR.\n    \"\"\"\n    for _ in range(n_steps):\n        grad = score_model(x, t)\n        noise = torch.randn_like(x)\n\n        grad_norm = torch.norm(grad.reshape(grad.shape[0], -1), dim=-1).mean()\n        noise_norm = torch.norm(noise.reshape(noise.shape[0], -1), dim=-1).mean()\n        step_size = (snr * noise_norm / (grad_norm + 1e-12)) ** 2 * 2.0\n\n        x = x + step_size * grad + torch.sqrt(2.0 * step_size) * noise\n    return x\n\n\n@torch.no_grad()\ndef pc_sampler(score_model, shape, *, n_steps=1000, sde=\"ve\", device=\"cpu\", corrector_steps=1, snr=0.16):\n    \"\"\"\n    Predictor\u2013corrector sampling.\n    - VE predictor uses the identity g(t)^2 dt = d(\u03c3(t)^2) for the chosen marginal \u03c3(t).\n    - VP predictor uses Euler\u2013Maruyama with f(x,t)=-0.5\u03b2(t)x, g(t)=sqrt(\u03b2(t)).\n    \"\"\"\n    x = torch.randn(shape, device=device)\n    ts = torch.linspace(1.0, 1e-3, n_steps, device=device)  # reverse-time grid\n\n    for i in range(len(ts) - 1):\n        t = ts[i].expand(shape[0])\n        t_next = ts[i + 1].expand(shape[0])\n        dt = t_next - t  # negative\n\n        z = torch.randn_like(x)\n\n        if sde == \"ve\":\n            sigma = ve_marginal_std(t)\n            sigma_next = ve_marginal_std(t_next)\n            while sigma.ndim &lt; x.ndim:\n                sigma = sigma[..., None]\n                sigma_next = sigma_next[..., None]\n            d_sigma2 = sigma_next**2 - sigma**2  # negative\n            x = x - d_sigma2 * score_model(x, t) + torch.sqrt(torch.clamp(-d_sigma2, min=0.0)) * z\n\n        elif sde == \"vp\":\n            beta = vp_beta(t)\n            while beta.ndim &lt; x.ndim:\n                beta = beta[..., None]\n            f = -0.5 * beta * x\n            g = torch.sqrt(beta)\n            dt_b = dt\n            while dt_b.ndim &lt; x.ndim:\n                dt_b = dt_b[..., None]\n            x = x + (f - (g**2) * score_model(x, t)) * dt_b + g * torch.sqrt(-dt_b) * z\n\n        else:\n            raise ValueError(\"sde must be 've' or 'vp'\")\n\n        x = langevin_corrector(score_model, x, t_next, snr=snr, n_steps=corrector_steps)\n\n    return x\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c42-ddpm-noise-prediction-training-ancestral-sampler","title":"C4.2 DDPM (noise-prediction training + ancestral sampler)","text":"<pre><code>import torch\n\n\ndef ddpm_forward_sample(x0, t, alpha_bar):\n    \"\"\"\n    x_t = sqrt(alpha_bar[t]) x0 + sqrt(1-alpha_bar[t]) eps\n    alpha_bar: shape (T+1,) with alpha_bar[0]=1.\n    t: int64 tensor of shape (B,) with values in {1,...,T}.\n    \"\"\"\n    eps = torch.randn_like(x0)\n    a_bar = alpha_bar[t]\n    while a_bar.ndim &lt; x0.ndim:\n        a_bar = a_bar[..., None]\n    xt = torch.sqrt(a_bar) * x0 + torch.sqrt(1.0 - a_bar) * eps\n    return xt, eps\n\n\ndef ddpm_loss_eps(eps_model, x0, t, alpha_bar):\n    xt, eps = ddpm_forward_sample(x0, t, alpha_bar)\n    pred_eps = eps_model(xt, t)\n    return (pred_eps - eps).pow(2).mean()\n\n\n@torch.no_grad()\ndef ddpm_sample(eps_model, shape, *, alpha, alpha_bar, sigma):\n    \"\"\"\n    Ancestral sampling for a fixed-variance DDPM parameterization.\n    Arrays alpha/alpha_bar/sigma are shape (T+1,) with index 0 unused for sampling.\n    \"\"\"\n    device = alpha.device\n    T = alpha.shape[0] - 1\n    x = torch.randn(shape, device=device)\n\n    for t in range(T, 0, -1):\n        t_vec = torch.full((shape[0],), t, device=device, dtype=torch.long)\n        eps = eps_model(x, t_vec)\n\n        mean = (1.0 / torch.sqrt(alpha[t])) * (x - ((1.0 - alpha[t]) / torch.sqrt(1.0 - alpha_bar[t])) * eps)\n\n        if t &gt; 1:\n            x = mean + sigma[t] * torch.randn_like(x)\n        else:\n            x = mean\n\n    return x\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c43-flow-matching-linear-bridge-ode-sampling","title":"C4.3 Flow matching (linear bridge + ODE sampling)","text":"<pre><code>import torch\n\n\ndef flow_matching_loss(v_model, x1, t):\n    \"\"\"\n    Linear bridge between x0 ~ N(0,I) and x1 ~ data:\n      x_t = (1-t) x0 + t x1\n      target = d/dt x_t = x1 - x0\n    \"\"\"\n    x0 = torch.randn_like(x1)\n    t_for_path = t\n    while t_for_path.ndim &lt; x1.ndim:\n        t_for_path = t_for_path[..., None]\n    xt = (1.0 - t_for_path) * x0 + t_for_path * x1\n    target = x1 - x0\n    pred = v_model(xt, t)  # convention: model expects t with shape (B,)\n    return (pred - target).pow(2).mean()\n\n\n@torch.no_grad()\ndef flow_sample(v_model, shape, *, n_steps=50, method=\"heun\", device=\"cpu\"):\n    \"\"\"Sample by integrating dx/dt = v_model(x,t) from t=0 to t=1.\"\"\"\n    x = torch.randn(shape, device=device)\n    ts = torch.linspace(0.0, 1.0, n_steps + 1, device=device)\n\n    for i in range(n_steps):\n        t = float(ts[i].item())\n        t_next = float(ts[i + 1].item())\n        h = t_next - t\n\n        t_vec = torch.full((shape[0],), t, device=device)\n        if method == \"euler\":\n            x = x + h * v_model(x, t_vec)\n\n        elif method == \"heun\":\n            k1 = v_model(x, t_vec)\n            x_pred = x + h * k1\n            t_next_vec = torch.full((shape[0],), t_next, device=device)\n            k2 = v_model(x_pred, t_next_vec)\n            x = x + 0.5 * h * (k1 + k2)\n\n        else:\n            raise ValueError(\"method must be 'euler' or 'heun'\")\n\n    return x\n</code></pre>"},{"location":"posts/introduction-C-compare-and-code.html#c5-elbo-policy-keep-it-light","title":"C5. ELBO policy (keep it light)","text":"<p>DDPM was originally introduced via a variational bound (an ELBO over a latent diffusion chain), but most practical training uses a simplified regression loss (e.g., noise prediction MSE) that can be derived as a special case of that ELBO under common parameterizations and fixed variances.</p> <p>For details, see introduction-beta-CFM-and-ELBO.md and diffusion-models-intro.md (Chapter 4).</p>"},{"location":"posts/introduction-C-compare-and-code.html#c6-section-close-template","title":"C6. Section close template","text":"<ol> <li>We model: pick a view (score / noise / velocity).</li> <li>We learn: the corresponding network output (\\(s_\\theta\\) / \\(\\varepsilon_\\theta\\) / \\(v_\\theta\\)).</li> <li>We sample: the matching dynamics + numerical method (reverse SDE / reverse chain / ODE solver).</li> </ol>"},{"location":"posts/introduction-beta-CFM-and-ELBO.html","title":"Introduction \\(\\beta\\) \u2014 CFM and ELBO","text":""},{"location":"posts/introduction-beta-CFM-and-ELBO.html#clarification-what-this-note-isand-is-notclaiming","title":"Clarification (what this note is\u2014and is not\u2014claiming)","text":"<p>This note puts Conditional Flow Matching (CFM) and variational objectives (ELBO) side by side for a very specific reason: when designing a computable loss, both frameworks face a similar-looking obstacle\u2014some marginal object is intractable, and we introduce conditional structure (auxiliary variables, conditional distributions, conditional expectations) to turn the optimization into an expectation we can sample or estimate.</p> <p>However, this is a methodological similarity, not a semantic or \u201cphysical\u201d equivalence. The objectives live on different mathematical objects:</p> <ul> <li>ELBO is a variational lower bound on a log-marginal likelihood \\(\\log p_\\theta(x)=\\log\\int p_\\theta(x,z)\\,dz\\). Its construction is inseparable from Jensen\u2019s inequality and an explicit inference distribution \\(q_\\phi(z\\mid x)\\).</li> <li>Flow Matching / CFM is a path-matching / generator-regression viewpoint: we prescribe a probability path \\((p_t)\\) and learn a velocity field along that path. The intractable marginal target (e.g., a marginal velocity defined via posterior averaging) is replaced by a tractable conditional supervision signal, and the correctness of this replacement is justified by precise statements such as marginalization identities and gradient equivalence under Bregman losses.</li> </ul> <p>So the purpose of this note is not to \u201cderive Flow Matching from ELBO\u201d (or vice versa), but to clarify:</p> <ol> <li>where the analogy does hold (turning intractable marginals into computable conditional objectives), and</li> <li>where it breaks (what is being optimized, what assumptions are required, and what guarantees we get).</li> </ol> <p>With that scope fixed, we now recap the two optimization stories.</p>"},{"location":"posts/mathematics-foundation.html","title":"Mathematics Foundation","text":"<p>All discussions are in the Euclidean setting unless stated otherwise: \\(x\\in\\mathbb{R}^D\\), \\(t\\in[0,1]\\). The goal is to pin down the minimum deterministic/stochastic differential-equation facts needed for flow models and diffusion models.</p>"},{"location":"posts/mathematics-foundation.html#chapter-1-differential-equations-de-first-order-ode-sde","title":"Chapter 1 \u2014 Differential Equations (DE): first-order ODE / SDE","text":""},{"location":"posts/mathematics-foundation.html#11-foundation-of-ordinary-differential-equations","title":"1.1 Foundation of Ordinary Differential Equations","text":"<p>Let \\(u:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}^D\\) be a time-dependent vector field. Consider the initial value problem (IVP)</p> \\[ \\frac{d}{dt}x(t)=u(t,x(t)),\\qquad x(0)=x_0\\in\\mathbb{R}^D. \\] <p>A standard sufficient condition for (global) existence and uniqueness on \\([0,1]\\) is:</p> <ul> <li>for each \\(t\\), \\(u(t,\\cdot)\\) is globally Lipschitz on \\(\\mathbb{R}^D\\), and</li> <li>\\(u\\) has at most linear growth in \\(x\\) (e.g., \\(\\|u(t,x)\\|\\le a(t)+b\\|x\\|\\) with \\(a\\in L^1([0,1])\\)).</li> </ul> <p>We write the solution as \\(x(t;x_0)\\) and define the flow map</p> \\[ \\psi_t(x_0):=x(t;x_0),\\qquad \\psi_0(x_0)=x_0. \\] <p>One immediate consequence of uniqueness (hence of the Lipschitz-type assumptions above) is non-intersection of solution trajectories: if two solutions \\(x_1(\\cdot),x_2(\\cdot)\\) satisfy \\(x_1(t_\\ast)=x_2(t_\\ast)\\) at some time \\(t_\\ast\\), then they must coincide for all \\(t\\) in their common interval of existence. (Proof sketch: treat \\((t_\\ast,x_1(t_\\ast))\\) as a new initial condition and apply uniqueness.)</p>"},{"location":"posts/mathematics-foundation.html#111-exponential-integration-factors-integration-factor-method","title":"1.1.1 Exponential integration factors (integration factor method)","text":"<p>This subsection is mainly about how to solve first-order ODEs in the cases where closed forms exist, and how to rewrite them into a form that is more structured (and numerically stable) when they do not.</p> <p>Baseline. For a general nonlinear ODE \\(\\dot x=u(t,x)\\), a closed form is usually unavailable; the \u201csolution operator\u201d is the flow map \\(\\psi_t\\). In special cases, \\(\\psi_t\\) can be written explicitly.</p> <p>(A) Linear scalar ODE (homogeneous). Consider</p> \\[ \\frac{d}{dt}x(t)=L(t)\\,x(t), \\] <p>where \\(L:[0,1]\\to\\mathbb{R}\\) is continuous. Then for any \\(0\\le s\\le t\\le 1\\),</p> \\[ x(t)=x(s)\\,\\exp\\!\\Big(\\int_s^t L(\\tau)\\,d\\tau\\Big). \\] <p>This motivates the exponential (integration) factor</p> \\[ E(s\\to t):=\\exp\\!\\Big(\\int_s^t L(\\tau)\\,d\\tau\\Big), \\] <p>which accumulates the time-dependent linear effect.</p> <p>(B) Linear scalar ODE (inhomogeneous): integrating factor. For</p> \\[ \\frac{d}{dt}x(t)=L(t)\\,x(t)+r(t), \\] <p>define \\(E(s\\to t)\\) as above. Then the closed-form solution is</p> \\[ x(t)=E(s\\to t)\\,x(s)+\\int_s^t E(\\tau\\to t)\\,r(\\tau)\\,d\\tau. \\] <p>This is the standard integrating-factor method.</p> <p>(C) Semilinear ODE: variation of constants / Duhamel formula. More generally, consider a semilinear ODE</p> \\[ \\frac{d}{dt}x(t)=L(t)\\,x(t)+N(x(t),t), \\] <p>where \\(x(t)\\in\\mathbb{R}^D\\), \\(L(t)\\in\\mathbb{R}\\) (equivalently \\(L(t)I\\) acting on \\(\\mathbb{R}^D\\)), and \\(N:\\mathbb{R}^D\\times[0,1]\\to\\mathbb{R}^D\\). Multiplying by \\(E(s\\to t)^{-1}\\) and applying the product rule yields</p> \\[ \\frac{d}{dt}\\Big[E(s\\to t)^{-1}x(t)\\Big]=E(s\\to t)^{-1}N(x(t),t). \\] <p>Integrating from \\(s\\) to \\(t\\) gives the integral form (Duhamel / variation-of-constants formula)</p> \\[ x(t)=E(s\\to t)\\,x(s)\\;+\\;\\int_s^t E(\\tau\\to t)\\,N(x(\\tau),\\tau)\\,d\\tau. \\] <p>This separates the evolution into a closed-form linear propagation and a nonlinear residual. Exponential integrators discretize only the integral term while handling the linear propagation exactly, often improving stability when the linear part is stiff.</p> <p>Remark (matrix-valued linear part). If the linear part is \\(L(t)\\in\\mathbb{R}^{D\\times D}\\), the same integral formula holds with \\(E(s\\to t)\\) defined as the fundamental matrix solving \\(\\frac{d}{dt}E(s\\to t)=L(t)E(s\\to t)\\), \\(E(s\\to s)=I\\). In general \\(E(s\\to t)\\neq \\exp\\!\\big(\\int_s^t L(\\tau)\\,d\\tau\\big)\\) unless \\(L(t)\\) commutes with itself at different times (or \\(L\\) is constant).</p> <p>What is \u201cclosed form\u201d here (and when do we still need numerics)? For a generic nonlinear first-order ODE, a closed-form solution is not available. Case (A) is fully explicit. Case (B) is explicit up to quadrature: if the integral \\(\\int_s^t E(\\tau\\to t)r(\\tau)\\,d\\tau\\) can be evaluated analytically then we obtain a closed form; otherwise we still compute that integral numerically. Case (C) provides an exact integral representation, but since \\(N\\) depends on the unknown trajectory \\(x(\\tau)\\), it is generally an implicit integral equation and still requires numerical approximation (e.g., time stepping, Picard iteration, or exponential integrators).</p> <p>Diffeomorphism is about regularity/invertibility, not linearity. In flow models, we often care that the time-\\(t\\) map \\(\\psi_t\\) is a (local) \\(C^1\\) diffeomorphism so that the transformation is invertible and change-of-variables identities make sense. This property does not require the dynamics to be linear. Rather, it follows from ODE well-posedness plus smoothness: if \\(u(t,\\cdot)\\) is (locally) Lipschitz (uniqueness) and \\(C^1\\) in \\(x\\) on a domain where solutions exist up to time \\(t\\), then \\(\\psi_t\\) is (locally) invertible and differentiable, with inverse given by running the same ODE backward in time. Nonlinearity is typical and compatible with diffeomorphism; linearity is only a special case where we may also get closed-form expressions.</p>"},{"location":"posts/mathematics-foundation.html#112-numerical-solvers-for-odes-time-discretization","title":"1.1.2 Numerical solvers for ODEs (time discretization)","text":"<p>Closed-form solutions are rare for nonlinear, time-dependent ODEs, so we typically approximate trajectories numerically. A useful starting point is the integral form of the ODE</p> \\[ \\dot x(t)=v(x(t),t),\\qquad x(0)=x_0, \\] <p>namely</p> \\[ x(t)=x_0+\\int_0^t v(x(\\tau),\\tau)\\,d\\tau. \\] <p>Numerical solvers discretize time and approximate this integral by evaluating the vector field \\(v\\) at selected points.</p> <p>Discretization. Choose grid points \\(0=t_0&lt;t_1&lt;\\dots&lt;t_N=T\\) with step sizes \\(h_n:=t_{n+1}-t_n\\), and maintain states \\(x_n\\approx x(t_n)\\).</p> <p>Order of accuracy (one line). A method is called order-\\(p\\) if, for a sufficiently smooth solution and a uniform step size \\(h\\), its global error at \\(T\\) scales as \\(O(h^p)\\) as \\(h\\to 0\\) (equivalently, local truncation error \\(O(h^{p+1})\\)).</p> <p>Euler (explicit). The simplest one-step method uses the current slope:</p> \\[ x_{n+1}=x_n+h_n\\,v(x_n,t_n). \\] <p>It is first-order accurate: local truncation error \\(O(h_n^2)\\) and global error \\(O(\\max_n h_n)\\) under standard regularity assumptions.</p> <p>Heun (improved Euler / explicit trapezoid). A second-order predictor\u2013corrector:</p> \\[ \\tilde x_{n+1}=x_n+h_n\\,v(x_n,t_n),\\qquad x_{n+1}=x_n+\\frac{h_n}{2}\\Big(v(x_n,t_n)+v(\\tilde x_{n+1},t_{n+1})\\Big). \\] <p>It has local error \\(O(h_n^3)\\) and global error \\(O((\\max_n h_n)^2)\\).</p> <p>Runge\u2013Kutta (RK4). A standard fourth-order method based on four slopes:</p> \\[ k_1=v(x_n,t_n),\\quad k_2=v\\Big(x_n+\\frac{h_n}{2}k_1,t_n+\\frac{h_n}{2}\\Big),\\quad k_3=v\\Big(x_n+\\frac{h_n}{2}k_2,t_n+\\frac{h_n}{2}\\Big),\\quad k_4=v(x_n+h_n k_3,t_n+h_n), \\] \\[ x_{n+1}=x_n+\\frac{h_n}{6}\\big(k_1+2k_2+2k_3+k_4\\big). \\] <p>RK4 is a common accuracy\u2013cost tradeoff when vector-field evaluations are not too expensive.</p> <p>Semilinear structure and exponential integrators. If \\(v(x,t)=L(t)x+N(x,t)\\) (Section 1.1.1), then</p> \\[ x(t)=E(0\\to t)x_0+\\int_0^t E(\\tau\\to t)\\,N(x(\\tau),\\tau)\\,d\\tau, \\] <p>and exponential integrators approximate only the integral term while handling the linear propagation \\(E(\\cdot\\to\\cdot)\\) analytically. This can substantially improve stability when the linear part is stiff.</p> <p>Reverse-time integration (ODE). Solving backward from a terminal condition \\(x(T)=x_T\\) is straightforward: integrate on a decreasing grid \\(t_0=T&gt;t_1&gt;\\dots&gt;t_N=0\\). With Euler and constant step \\(h&gt;0\\),</p> \\[ t_{n+1}=t_n-h,\\qquad x_{n+1}=x_n-h\\,v(x_n,t_n). \\] <p>For ODEs, this is just a reparameterization of time; in diffusion models, reverse-time ODE integration is used for sampling (e.g., probability flow ODEs).</p> <p>Remark (stability and stiffness). For stiff dynamics, explicit methods may require very small step sizes for stability; implicit methods or structure-exploiting solvers (e.g., exponential integrators, diffusion-specific solvers) can be preferable.</p> <p>Minimal code (Euler / Heun / RK4). Below is a tiny reference implementation for the scalar ODE \\( \\dot x=v(x,t) \\). The same structure applies to \\(x\\in\\mathbb{R}^D\\) by letting <code>x</code> be a NumPy/PyTorch array/tensor and having <code>v(x,t)</code> return the same shape.</p> <pre><code>from typing import Callable, Literal, Tuple, List\n\nMethod = Literal[\"euler\", \"heun\", \"rk4\"]\n\n\ndef solve_ode(\n    v: Callable[[float, float], float],\n    x0: float,\n    t0: float,\n    t1: float,\n    n_steps: int,\n    method: Method = \"euler\",\n) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"\n    Solve dx/dt = v(x,t) on [t0,t1] with a chosen explicit solver.\n    - method: \"euler\" | \"heun\" | \"rk4\"\n    \"\"\"\n    if n_steps &lt;= 0:\n        raise ValueError(\"n_steps must be positive\")\n\n    h = (t1 - t0) / n_steps\n    t = t0\n    x = x0\n    ts = [t]\n    xs = [x]\n\n    for _ in range(n_steps):\n        if method == \"euler\":\n            x = x + h * v(x, t)\n\n        elif method == \"heun\":\n            k1 = v(x, t)\n            x_pred = x + h * k1\n            k2 = v(x_pred, t + h)\n            x = x + (h / 2.0) * (k1 + k2)\n\n        elif method == \"rk4\":\n            k1 = v(x, t)\n            k2 = v(x + 0.5 * h * k1, t + 0.5 * h)\n            k3 = v(x + 0.5 * h * k2, t + 0.5 * h)\n            k4 = v(x + h * k3, t + h)\n            x = x + (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\n        else:\n            raise ValueError(f\"unknown method: {method}\")\n\n        t = t + h\n        ts.append(t)\n        xs.append(x)\n\n    return ts, xs\n</code></pre>"},{"location":"posts/mathematics-foundation.html#12-random-initial-condition-random-ivp","title":"1.2 Random initial condition (random IVP)","text":"<p>Fix a probability space \\((\\Omega,\\mathcal{F},\\mathbb{P})\\). Let \\(\\mathbf{X}_0:\\Omega\\to\\mathbb{R}^D\\) be an \\(\\mathcal{F}\\)-measurable random variable with law \\(\\mu_0:=\\mathcal{L}(\\mathbf{X}_0)\\). Define</p> \\[ \\mathbf{X}_t:=\\psi_t(\\mathbf{X}_0),\\qquad t\\in[0,1], \\] <p>and denote \\(\\mu_t:=\\mathcal{L}(\\mathbf{X}_t)\\). This is still a deterministic ODE; randomness enters only through \\(\\mathbf{X}_0\\).</p>"},{"location":"posts/mathematics-foundation.html#13-push-forward-of-measures-and-test-function-identity","title":"1.3 Push-forward of measures and test-function identity","text":"<p>For each \\(t\\), the law evolves by push-forward:</p> \\[ \\mu_t = (\\psi_t)_\\#\\mu_0. \\] <p>Equivalently, for any bounded measurable \\(\\varphi:\\mathbb{R}^D\\to\\mathbb{R}\\),</p> \\[ \\mathbb{E}\\big[\\varphi(\\mathbf{X}_t)\\big] = \\int_{\\mathbb{R}^D}\\varphi(\\psi_t(x))\\,\\mu_0(dx). \\]"},{"location":"posts/mathematics-foundation.html#14-foundation-of-stochastic-differential-equations","title":"1.4 Foundation of Stochastic Differential Equations","text":"<p>This section provides an intuition-first bridge from ODEs to SDEs. Chapter 2 then states the It\u00f4 SDE and the associated density evolution (Fokker\u2013Planck).</p>"},{"location":"posts/mathematics-foundation.html#141-from-odes-to-sdes-discretization-intuition","title":"1.4.1 From ODEs to SDEs (discretization intuition)","text":"<p>Start from a deterministic ODE in \\(\\mathbb{R}^D\\):</p> \\[ \\frac{d}{dt}x(t)=f(x(t),t),\\qquad x(0)=x_0,\\qquad t\\in[0,T]. \\] <p>Euler time stepping with step size \\(\\Delta t\\) gives</p> \\[ x_{t+\\Delta t}\\approx x_t+f(x_t,t)\\,\\Delta t. \\] <p>To model uncertainty or unmodeled interactions, add a random perturbation at each time step:</p> \\[ x_{t+\\Delta t}\\approx x_t+f(x_t,t)\\,\\Delta t+g(t)\\,\\sqrt{\\Delta t}\\,\\varepsilon_t, \\qquad \\varepsilon_t\\sim\\mathcal{N}(0,I_D)\\ \\text{i.i.d.} \\] <p>The \\(\\sqrt{\\Delta t}\\) scaling is crucial: it is the scaling (up to constants) for which the cumulative randomness remains \\(O(1)\\) over \\(O(1)\\) time, rather than vanishing (\\(\\Delta t\\)) or exploding (\\(1\\)).</p> <p>In the continuous-time limit, this leads to an It\u00f4 SDE</p> \\[ dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t, \\] <p>where \\(W_t\\in\\mathbb{R}^D\\) is a standard Brownian motion (Wiener process) characterized by:</p> <ul> <li>\\(W_0=0\\) a.s.;</li> <li>independent increments: \\(W_t-W_s\\) is independent of \\(\\sigma(W_u:u\\le s)\\) for \\(0\\le s&lt;t\\);</li> <li>Gaussian increments: \\(W_t-W_s\\sim \\mathcal{N}(0,(t-s)I_D)\\);</li> <li>sample paths are a.s. continuous but nowhere classically differentiable.</li> </ul> <p>The notation \\(dW_t:=W_{t+dt}-W_t\\) is a convenient shorthand for these increments and should not be interpreted as a classical differential. Informally, one writes</p> \\[ dW_t\\sim \\mathcal{N}(0,dt\\,I_D), \\] <p>meaning that over a short interval of length \\(dt\\), the increment behaves like a zero-mean Gaussian with covariance \\(dt\\,I_D\\).</p>"},{"location":"posts/mathematics-foundation.html#142-how-to-read-an-ito-sde-integral-form-and-ito-integration-intuition","title":"1.4.2 How to read an It\u00f4 SDE: integral form and It\u00f4 integration intuition","text":"<p>An SDE should be understood through its integral formulation. For example, the It\u00f4 SDE</p> \\[ dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t,\\qquad X_0=x_0, \\] <p>means that for each \\(t\\in[0,T]\\),</p> \\[ X_t = X_0 +\\int_0^t f(X_s,s)\\,ds +\\int_0^t g(s)\\,dW_s, \\] <p>where the first integral is a classical (Lebesgue/Riemann) integral and the second is an It\u00f4 stochastic integral.</p> <p>We do not build the It\u00f4 integral rigorously here; instead, keep the following intuition in mind. For a partition \\(0=t_0&lt;t_1&lt;\\dots&lt;t_N=t\\), the It\u00f4 integral can be viewed (informally) as a limit of left-point Riemann sums:</p> \\[ \\int_0^t g(s)\\,dW_s \\approx \\sum_{i=0}^{N-1} g(t_i)\\,\\big(W_{t_{i+1}}-W_{t_i}\\big), \\] <p>with convergence in probability (under suitable conditions). The left-endpoint evaluation \\(g(t_i)\\) is what distinguishes the It\u00f4 convention from other conventions (e.g., Stratonovich often corresponds to midpoint-type evaluations).</p> <p>Because Brownian sample paths are a.s. continuous but nowhere classically differentiable, expressions like \\(dW_t/dt\\) do not exist in the usual sense, and classical \u201cintegrate both sides\u201d reasoning does not apply directly. The differential notation \\(dX_t\\), \\(dt\\), \\(dW_t\\) is therefore shorthand for increments and must be interpreted through the integral equation above.</p> <p>Comparison with ODEs. For an ODE \\(\\dot x(t)=f(x(t),t)\\), the integral form</p> \\[ x(t)=x(0)+\\int_0^t f(x(\\tau),\\tau)\\,d\\tau \\] <p>is justified by the fundamental theorem of calculus (differentiability recovers the function from its derivative). For SDEs, there is no direct analog because \\(W_t\\) is not differentiable and stochastic integrals do not obey the classical chain rule. Instead, the correct replacement is It\u00f4\u2019s formula (It\u00f4\u2019s lemma), which we will use later when connecting SDEs to density evolution and reverse-time constructions in diffusion models.</p> <p>Minimal code (Euler\u2013Maruyama / Milstein). The most common time stepping for It\u00f4 SDEs is Euler\u2013Maruyama. Below is a small reference implementation for</p> \\[ dX_t=f(X_t,t)\\,dt+G(X_t,t)\\,dW_t, \\] <p>where \\(W_t\\in\\mathbb{R}^m\\) and \\(G(x,t)\\in\\mathbb{R}^{D\\times m}\\). Milstein is included only for the scalar case \\(D=m=1\\).</p> <pre><code>from typing import Callable, Literal, Tuple, Optional\n\nimport numpy as np\n\nSdeMethod = Literal[\"euler_maruyama\", \"milstein_scalar\"]\n\n\ndef solve_sde(\n    f: Callable[[np.ndarray, float], np.ndarray],\n    G: Callable[[np.ndarray, float], np.ndarray],\n    x0,\n    t0: float,\n    t1: float,\n    n_steps: int,\n    *,\n    method: SdeMethod = \"euler_maruyama\",\n    rng: Optional[np.random.Generator] = None,\n    dgdx_scalar: Optional[Callable[[float, float], float]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Solve the It\u00f4 SDE: dX = f(X,t) dt + G(X,t) dW, with W in R^m.\n\n    - f(x,t): (D,) -&gt; (D,)\n    - G(x,t): (D,) -&gt; (D,m)\n    - x0: float or array-like of shape (D,)\n    - method:\n        - \"euler_maruyama\": works for any (D,m)\n        - \"milstein_scalar\": only for D=m=1; requires dgdx_scalar(x,t)=d/dx g(x,t)\n          where G(x,t) = [[g(x,t)]].\n    \"\"\"\n    if n_steps &lt;= 0:\n        raise ValueError(\"n_steps must be positive\")\n    if t1 &lt;= t0:\n        raise ValueError(\"require t1 &gt; t0 for this forward-time solver\")\n\n    rng = np.random.default_rng() if rng is None else rng\n\n    x = np.asarray(x0, dtype=float)\n    if x.ndim == 0:\n        x = x.reshape((1,))\n\n    t = float(t0)\n    h = (t1 - t0) / n_steps\n\n    ts = np.empty(n_steps + 1, dtype=float)\n    xs = np.empty((n_steps + 1,) + x.shape, dtype=float)\n    ts[0] = t\n    xs[0] = x\n\n    for n in range(n_steps):\n        drift = np.asarray(f(x, t), dtype=float).reshape(x.shape)\n        diffusion = np.asarray(G(x, t), dtype=float)\n        if diffusion.ndim != 2:\n            raise ValueError(\"G(x,t) must return a 2D array of shape (D,m)\")\n        D, m = diffusion.shape\n        if D != x.shape[0]:\n            raise ValueError(\"G(x,t) first dimension must match x dimension D\")\n\n        dW = rng.standard_normal(size=(m,)) * np.sqrt(h)  # N(0, h I_m)\n\n        if method == \"euler_maruyama\":\n            x = x + h * drift + diffusion @ dW\n\n        elif method == \"milstein_scalar\":\n            if not (D == 1 and m == 1 and x.shape == (1,)):\n                raise ValueError(\"milstein_scalar requires D=m=1 and scalar state\")\n            if dgdx_scalar is None:\n                raise ValueError(\"milstein_scalar requires dgdx_scalar\")\n            g = float(diffusion[0, 0])\n            gp = float(dgdx_scalar(float(x[0]), t))\n            x = x + h * drift + diffusion @ dW + 0.5 * g * gp * (dW[0] ** 2 - h)\n\n        else:\n            raise ValueError(f\"unknown method: {method}\")\n\n        t = t + h\n        ts[n + 1] = t\n        xs[n + 1] = x\n\n    return ts, xs\n</code></pre>"},{"location":"posts/mathematics-foundation.html#chapter-2-density-evolution-from-change-of-variables-to-fokkerplanck","title":"Chapter 2 \u2014 Density Evolution: From change of variables to Fokker\u2013Planck","text":"<p>This chapter summarizes the two canonical density-evolution PDEs:</p> <ul> <li>deterministic transport (ODE) \\(\\Rightarrow\\) continuity equation;</li> <li>stochastic diffusion (It\u00f4 SDE) \\(\\Rightarrow\\) Fokker\u2013Planck equation.</li> </ul>"},{"location":"posts/mathematics-foundation.html#21-change-of-variable-formula-from-deterministic-maps-to-stochastic-flows","title":"2.1 Change-of-Variable Formula: From Deterministic Maps to Stochastic Flows","text":"<p>This section starts from a single deterministic update \\(x_1=\\Psi(x_0)\\) and tracks how densities transform under smooth bijections. Composing many such updates leads to the Jacobian-determinant bookkeeping used in normalizing flows. Taking a continuous-time limit recovers the continuity equation; adding Brownian noise upgrades it to the Fokker\u2013Planck equation (Section 2.2).</p>"},{"location":"posts/mathematics-foundation.html#211-single-deterministic-map","title":"2.1.1 Single deterministic map","text":"<p>Let \\(\\Psi:\\mathbb{R}^D\\to\\mathbb{R}^D\\) be a \\(C^1\\) bijection with \\(C^1\\) inverse (a diffeomorphism). If \\(X_0\\sim p_0\\) and \\(X_1:=\\Psi(X_0)\\), then \\(X_1\\sim p_1\\) where the density is given by the change-of-variable formula</p> \\[ p_1(x_1)=p_0\\big(\\Psi^{-1}(x_1)\\big)\\,\\left|\\det \\nabla \\Psi^{-1}(x_1)\\right|. \\] <p>Equivalently, writing \\(x_1=\\Psi(x_0)\\),</p> \\[ p_0(x_0)=p_1(\\Psi(x_0))\\,\\left|\\det \\nabla\\Psi(x_0)\\right|. \\] <p>Interpretation: \\(\\left|\\det\\nabla\\Psi\\right|\\) is the local volume change, and the density compensates to conserve probability mass.</p> <p>At the measure level, this is exactly a push-forward:</p> \\[ \\mu_1 = \\Psi_\\#\\mu_0, \\] <p>meaning \\(\\mu_1(A)=\\mu_0(\\Psi^{-1}(A))\\) for any Borel set \\(A\\subseteq\\mathbb{R}^D\\). The density formula above is the Lebesgue-density version of \\(\\mu_1=\\Psi_\\#\\mu_0\\).</p> <p>As a special case, if \\(\\Psi(x)=Ax\\) with \\(A\\in\\mathbb{R}^{D\\times D}\\) invertible, then</p> \\[ p_1(x_1)=p_0(A^{-1}x_1)\\,|\\det A^{-1}|. \\]"},{"location":"posts/mathematics-foundation.html#212-composing-multiple-bijections-discrete-normalizing-flows","title":"2.1.2 Composing multiple bijections (discrete normalizing flows)","text":"<p>Consider a sequence of diffeomorphisms \\(\\Psi_1,\\dots,\\Psi_L\\) and states \\(x_k=\\Psi_k(x_{k-1})\\). If \\(X_0\\sim p_0\\), define \\(X_k:=\\Psi_k(X_{k-1})\\) and let \\(p_k\\) be the density of \\(X_k\\). Mass conservation at each step implies</p> \\[ p_k(x_k)=p_{k-1}(x_{k-1})\\left|\\det \\nabla\\Psi_k(x_{k-1})\\right|^{-1}, \\qquad x_{k-1}=\\Psi_k^{-1}(x_k). \\] <p>Recursing yields the overall Jacobian product</p> \\[ p_L(x_L)=p_0(x_0)\\prod_{k=1}^L \\left|\\det \\nabla\\Psi_k(x_{k-1})\\right|^{-1}, \\] <p>and, in log form,</p> \\[ \\log p_L(x_L)=\\log p_0(x_0)-\\sum_{k=1}^L \\log\\left|\\det \\nabla\\Psi_k(x_{k-1})\\right|. \\] <p>This is the core likelihood bookkeeping identity for (discrete) normalizing flows.</p>"},{"location":"posts/mathematics-foundation.html#213-continuous-time-limit-rightarrow-continuity-equation","title":"2.1.3 Continuous-time limit \\(\\Rightarrow\\) continuity equation","text":"<p>Let \\(u(t,x)\\) be a time-dependent velocity field and consider the ODE \\(\\dot x(t)=u(t,x(t))\\). A standard way to connect maps to flows is to take small steps</p> \\[ \\Psi_{t\\to t+\\Delta t}(x)\\approx x+u(t,x)\\,\\Delta t, \\] <p>so the Jacobian factor becomes \\(\\det(I+\\Delta t\\,\\nabla_x u(t,x))\\). In the limit \\(\\Delta t\\to 0\\), the density \\(p_t\\) (when it exists and is smooth enough) evolves according to the continuity equation</p> \\[ \\partial_t p_t(x)+\\nabla\\!\\cdot\\big(p_t(x)\\,u(t,x)\\big)=0.\\qquad\\text{(CE)} \\] <p>Along trajectories \\(X_t\\) solving the ODE, an equivalent form is</p> \\[ \\frac{d}{dt}\\log p_t(X_t)=-\\nabla\\!\\cdot u(t,X_t). \\] <p>Regularity of \\(u\\) \\(\\Rightarrow\\) an invertible flow map. Under standard ODE well-posedness assumptions (e.g., \\(u(t,\\cdot)\\) locally Lipschitz in \\(x\\) and sufficiently regular in \\(t\\)), for each initial condition \\(x_0\\) there is a unique trajectory \\(t\\mapsto x(t;x_0)\\). This defines the time-\\(t\\) flow map</p> \\[ \\psi_t(x_0):=x(t;x_0). \\] <p>Uniqueness implies non-intersection of trajectories, and in particular makes \\(\\psi_t\\) (locally) invertible on its domain of existence: the inverse is given by running the same ODE backward in time, i.e., \\(\\psi_t^{-1}=\\psi_{t\\to 0}\\) whenever both flows are well-defined. If \\(u\\) is \\(C^1\\) in \\(x\\), then \\(\\psi_t\\) is (locally) a \\(C^1\\) diffeomorphism.</p> <p>Derivation sketch (via change of variables). View the ODE as the continuous-time limit of small bijective updates (forward Euler):</p> \\[ x_{t+\\Delta t}=\\Psi(x_t):=x_t+\\Delta t\\,u(t,x_t). \\] <p>Then</p> \\[ \\nabla_{x_t}\\Psi(x_t)=I+\\Delta t\\,\\nabla_x u(t,x_t)+O(\\Delta t^2), \\] <p>and hence</p> \\[ \\det(\\nabla_{x_t}\\Psi)=1+\\Delta t\\,\\nabla\\!\\cdot u(t,x_t)+O(\\Delta t^2), \\] <p>using \\(\\det(I+\\Delta t A)=1+\\Delta t\\,\\mathrm{tr}(A)+O(\\Delta t^2)\\) and \\(\\nabla\\!\\cdot u=\\mathrm{tr}(\\nabla_x u)\\). Applying the change-of-variable formula to the update gives</p> \\[ \\log p_{t+\\Delta t}(x_{t+\\Delta t})-\\log p_t(x_t) = -\\Delta t\\,\\nabla\\!\\cdot u(t,x_t)+O(\\Delta t^2). \\] <p>On the other hand, a Taylor expansion yields</p> \\[ \\log p_{t+\\Delta t}(x_{t+\\Delta t})-\\log p_t(x_t) = \\Delta t\\,\\partial_t\\log p_t(x_t) +\\Delta t\\,u(t,x_t)^\\top\\nabla_x\\log p_t(x_t) +O(\\Delta t^2). \\] <p>Matching \\(O(\\Delta t)\\) terms and rewriting via the product rule recovers (CE) (and the trajectory form above).</p> <p>At the measure level, the ODE flow map \\(\\psi_t\\) (when well-defined) pushes the initial law forward:</p> \\[ \\mu_t = (\\psi_t)_\\#\\mu_0. \\] <p>When \\(\\mu_t(dx)=p_t(x)\\,dx\\) exists, the continuity equation (CE) is the density-level expression of \\(\\mu_t=(\\psi_t)_\\#\\mu_0\\).</p>"},{"location":"posts/mathematics-foundation.html#214-ode-vs-sde-push-forward-map-vs-stochastic-evolution","title":"2.1.4 ODE vs SDE: push-forward map vs stochastic evolution","text":"<p>For an It\u00f4 SDE, sample paths satisfy</p> \\[ dX_t=b(t,X_t)\\,dt+\\sigma(t,X_t)\\,dW_t, \\] <p>and \\(X_t\\) is no longer a deterministic function of \\(X_0\\). Consequently, in general there is no single deterministic map \\(\\psi_t\\) such that \\(\\mu_t=(\\psi_t)_\\#\\mu_0\\).</p> <p>Instead, the law evolves via a transition kernel (Markov semigroup) \\(P_t\\). In a notation that mirrors the push-forward \\(\\#\\), it is common to view \\(P_t\\) as inducing a push-forward operator on measures (the adjoint of \\(P_t\\) acting on test functions).</p> <p>Kernel \\(\\Rightarrow\\) measure push-forward. Let \\(P_t(x,\\cdot)\\) be a probability measure on \\(\\mathbb{R}^D\\) for each \\(x\\), and write \\(P_t(x,A)\\) for its mass on a Borel set \\(A\\). Define the induced operator \\(P_t^\\ast\\) on measures by</p> \\[ (P_t^\\ast \\mu_0)(A) := \\int_{\\mathbb{R}^D} P_t(x,A)\\,\\mu_0(dx), \\qquad A\\ \\text{Borel}. \\] <p>Then the law evolution is simply</p> \\[ \\mu_t = P_t^\\ast \\mu_0. \\] <p>Many notes also write this as \\(\\mu_t=\\mu_0 P_t\\) (right action) or, informally, \\(\\mu_t=(P_t)_\\#\\mu_0\\) to emphasize \u201cpush-forward by a stochastic mechanism\u201d. The safest (unambiguous) notation is \\(P_t^\\ast \\mu_0\\).</p> <p>Dual (test-function) form. The same evolution can be written as</p> \\[ \\int_{\\mathbb{R}^D}\\varphi(x)\\,\\mu_t(dx) = \\int_{\\mathbb{R}^D} (P_t\\varphi)(x)\\,\\mu_0(dx), \\qquad (P_t\\varphi)(x):=\\int_{\\mathbb{R}^D}\\varphi(y)\\,P_t(x,dy), \\] <p>for bounded measurable \\(\\varphi\\). This is exactly the \u201ckernel vs measure\u201d adjoint relationship: \\(P_t\\) acts on functions, \\(P_t^\\ast\\) acts on measures.</p> <p>Deterministic maps as a special case. If \\(P_t\\) comes from a deterministic map \\(\\psi_t\\), then</p> \\[ P_t(x,dy)=\\delta_{\\psi_t(x)}(dy) \\quad\\Longrightarrow\\quad P_t^\\ast \\mu_0 = (\\psi_t)_\\#\\mu_0. \\] <p>So the usual push-forward \\((\\psi_t)_\\#\\) is recovered by taking a Dirac transition kernel.</p> <p>When a density \\(p_t\\) exists, this kernel-level evolution is described by the Fokker\u2013Planck equation (Section 2.2), which differs from the continuity equation by a second-order diffusion term.</p> <p>Velocity-first vs density-first (Eulerian vs Lagrangian). There is an important asymmetry:</p> <ul> <li>Velocity-first: specifying \\(u(t,\\cdot)\\) (under well-posedness assumptions) determines the flow map \\(\\psi_t\\), hence determines the pushed-forward laws \\(\\mu_t=(\\psi_t)_\\#\\mu_0\\) and (when densities exist) a unique density evolution via (CE).</li> <li>Density-first: specifying only a density path \\(t\\mapsto p_t\\) generally does not determine a unique velocity field. Indeed, if a vector field \\(w_t(x)\\) satisfies</li> </ul> \\[ \\nabla\\!\\cdot\\big(p_t(x)\\,w_t(x)\\big)=0, \\] <p>then both \\(u_t\\) and \\(u_t+w_t\\) produce the same right-hand side in (CE), hence the same density evolution. A single density path may correspond to many different particle flows.</p> <p>Realizability (consistency check). Not every arbitrary path \\(p_t\\) can arise as the marginal law of particles moving under some deterministic velocity field. The continuity equation provides a consistency condition: we say \\(p_t\\) is realizable (generated by a flow) if there exists \\(u(t,x)\\) such that \\(p_t\\) and \\(u\\) satisfy (CE) (with suitable boundary/decay conditions).</p> <p>(Optional) Conditioning. If we introduce an auxiliary variable \\(Z\\sim\\pi\\) and define a conditional velocity field \\(u(t,x\\mid z)\\), then for each fixed \\(z\\) we have a conditional push-forward and continuity equation:</p> \\[ p_t(\\cdot\\mid z)=(\\psi_t(\\cdot;z))_\\# p_0,\\qquad \\partial_t p_t(x\\mid z)+\\nabla\\!\\cdot\\big(p_t(x\\mid z)\\,u(t,x\\mid z)\\big)=0. \\] <p>The unconditional marginal is the mixture</p> \\[ p_t(x)=\\int p_t(x\\mid z)\\,\\pi(z)\\,dz. \\]"},{"location":"posts/mathematics-foundation.html#215-path-first-density-first-vs-velocity-first-where-diffusion-and-flow-matching-fit","title":"2.1.5 Path-first (density-first) vs velocity-first: where diffusion and flow matching fit","text":"<p>In modern generative modeling, it is useful to separate two design patterns:</p> <ul> <li>Path-first / density-first: first specify (explicitly or implicitly) a probability path \\((\\mu_t)_{t\\in[0,1]}\\) or a forward corruption mechanism that induces \\(\\mu_t\\), and then learn dynamics that are consistent with that path.</li> <li>Velocity-first: first specify a parameterized dynamics family (e.g., a flow map or vector field \\(u_\\theta\\)), and then fit it to data using an objective; the induced path \\(\\mu_t\\) is whatever that dynamics produces.</li> </ul> <p>Flow-based generative modeling can be understood as a Lagrangian particle system whose Eulerian density evolution satisfies the continuity equation (in a suitable weak sense, and as a pointwise PDE under additional regularity), expressing pure transport and conservation of probability mass. This is a useful intuition for why, in a velocity-first viewpoint, we do not \u201cimpose (CE) as a constraint\u201d: once we specify the particle dynamics \\(\\dot X_t=u(t,X_t)\\) and define \\(\\mu_t=(\\psi_t)_\\#\\mu_0\\), (CE) follows as the density-level statement of mass conservation. By contrast, in a path-first/density-first viewpoint, (CE) acts as a compatibility condition between a prescribed \\(p_t\\) and a velocity field \\(u\\).</p> <p>Here \u201cfirst\u201d refers to what is treated as the design input in modeling/derivation/training (what you specify up front), not what is \u201cknown during sampling\u201d. In both paradigms, once dynamics are learned, sampling proceeds by integrating an ODE/SDE.</p> <p>\u201cDesign input\u201d means something you choose to specify that defines the modeling problem; \u201cknown\u201d means something that is already given at a particular stage of an algorithm/derivation (often as an output of a previous stage).</p> <p>Diffusion models and flow matching are typically path-first:</p> <ul> <li>Diffusion models: choose a forward noising SDE (equivalently a noise schedule such as \\(\\beta(t)\\) or \\(\\alpha(t),\\sigma(t)\\)), which defines a tractable forward path that \u201cthickens\u201d the data distribution. Training then learns a reverse-time object (often the score) that makes sampling possible.</li> <li>Flow matching / CFM: choose a probability path via a coupling + interpolation (e.g., endpoint pairing and \\(\\gamma_t(x_0,x_1)\\)), then learn a velocity field that generates (or matches) that path.</li> </ul> <p>In this path-first viewpoint, the continuity equation (CE) plays the role of a consistency condition: a velocity field \\(u\\) generates a density path \\(p_t\\) only if \\(p_t\\) and \\(u\\) satisfy (CE). In practice we rarely \u201csolve (CE) for \\(u\\)\u201d directly because \\(p_t\\) is not available in closed form; instead, training objectives are designed as computable surrogates that guarantee (or approximate) the same consistency.</p> <p>Finally, note that sampling is always velocity-first in execution: once a model provides a drift/velocity (ODE or SDE), we generate samples by numerically integrating the learned dynamics.</p>"},{"location":"posts/mathematics-foundation.html#22-stochastic-dynamics-ito-sde","title":"2.2 Stochastic dynamics: It\u00f4 SDE","text":"<p>Let \\(\\mathbf{W}_t\\) be a standard \\(m\\)-dimensional Brownian motion. Consider the It\u00f4 SDE</p> \\[ d\\mathbf{X}_t = b(t,\\mathbf{X}_t)\\,dt + \\sigma(t,\\mathbf{X}_t)\\,d\\mathbf{W}_t, \\] <p>where \\(b:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}^D\\) is the drift and \\(\\sigma:[0,1]\\times\\mathbb{R}^D\\to\\mathbb{R}^{D\\times m}\\) is the diffusion coefficient. Define the diffusion matrix</p> \\[ a(t,x):=\\sigma(t,x)\\sigma(t,x)^\\top\\in\\mathbb{R}^{D\\times D}. \\] <p>Assume \\(\\mu_t(dx)=p_t(x)\\,dx\\) exists and \\(b,\\sigma\\) are regular enough. Then \\(p_t\\) satisfies the Fokker\u2013Planck (forward Kolmogorov) equation</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\big(b(t,x)\\,p_t(x)\\big) \\;+\\;\\frac{1}{2}\\sum_{i=1}^D\\sum_{j=1}^D \\partial_{x_i}\\partial_{x_j}\\!\\big(a_{ij}(t,x)\\,p_t(x)\\big). \\] <p>Special cases:</p> <ul> <li>Pure transport (\\(\\sigma\\equiv 0\\)): the second-order term vanishes and we recover the continuity equation.</li> <li>Isotropic diffusion (\\(a(t,x)=\\beta(t)I\\)): the second-order term becomes \\(\\frac{1}{2}\\beta(t)\\Delta p_t\\).</li> </ul> <p>In the diffusion-model setting, a common special case is</p> \\[ dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t,\\qquad W_t\\in\\mathbb{R}^D, \\] <p>i.e., \\(\\sigma(t,x)=g(t)I\\). Then</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\big(f(x,t)\\,p_t(x)\\big) \\;+\\;\\frac{1}{2}g(t)^2\\,\\Delta p_t(x). \\] <p>Using \\(\\nabla p_t=p_t\\nabla\\log p_t\\), this can be rewritten in a divergence (mass conservation) form:</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\Big(\\Big(f(x,t)-\\frac{1}{2}g(t)^2\\,\\nabla_x\\log p_t(x)\\Big)\\,p_t(x)\\Big). \\] <p>Here the first term transports probability mass by the drift, while the Laplacian term models spreading (diffusion) due to stochastic noise. A full derivation uses It\u00f4 calculus and is omitted here.</p>"},{"location":"posts/mathematics-foundation.html#23-intuition-of-the-continuity-equation","title":"2.3 Intuition of the Continuity Equation","text":"<p>The continuity equation is a conservation law for a density. In our context, it describes conservation of probability mass under deterministic transport.</p>"},{"location":"posts/mathematics-foundation.html#231-physical-interpretation-control-volume-and-flux","title":"2.3.1 Physical interpretation (control volume and flux)","text":"<p>Think of a small fixed box (control volume) centered at \\(x\\in\\mathbb{R}^3\\) with side lengths \\(\\Delta x,\\Delta y,\\Delta z\\). Let \\(p(x,t)\\) be the density of a conserved quantity (mass or probability). The total amount inside the box is approximately</p> \\[ p(x,t)\\,\\Delta x\\,\\Delta y\\,\\Delta z. \\] <p>Changes can only happen via flux across the boundary. Let \\(j(x,t)\\in\\mathbb{R}^3\\) be the flux vector (amount crossing unit area per unit time). The net outflux in the \\(x\\)-direction is approximately</p> \\[ \\big(j_x(x,y,z,t)-j_x(x+\\Delta x,y,z,t)\\big)\\,\\Delta y\\,\\Delta z, \\] <p>and similarly for the other directions. Summing the three directions, the total net outflux is</p> \\[ -\\,(\\nabla\\!\\cdot j)(x,t)\\,\\Delta x\\,\\Delta y\\,\\Delta z. \\] <p>Conservation says \u201crate of change inside = minus net outflux\u201d, hence</p> \\[ \\partial_t p(x,t)\\,\\Delta x\\,\\Delta y\\,\\Delta z = -\\,(\\nabla\\!\\cdot j)(x,t)\\,\\Delta x\\,\\Delta y\\,\\Delta z. \\] <p>Canceling the volume factor (valid for any sufficiently small box) yields the local form</p> \\[ \\partial_t p(x,t)+\\nabla\\!\\cdot j(x,t)=0. \\] <p>For deterministic particle transport with velocity field \\(u(x,t)\\), the natural flux is \\(j=p\\,u\\). Plugging this into the conservation law gives the continuity equation</p> \\[ \\partial_t p+\\nabla\\!\\cdot(p\\,u)=0, \\] <p>which is exactly (CE) in Section 2.1.3.</p>"},{"location":"posts/mathematics-foundation.html#232-derivation-from-a-global-conservation-law-divergence-theorem","title":"2.3.2 Derivation from a global conservation law (divergence theorem)","text":"<p>Let \\(p(x,t)\\) be a density on \\(\\mathbb{R}^D\\), \\(u(x,t)\\) a velocity field, and \\(V\\subset\\mathbb{R}^D\\) an arbitrary control volume with boundary \\(\\partial V\\) and outward unit normal \\(n\\). The total mass in \\(V\\) is</p> \\[ \\int_V p(x,t)\\,dx, \\] <p>so its time derivative is the accumulation rate \\(\\frac{d}{dt}\\int_V p\\,dx\\). The outward flux through the boundary is</p> \\[ \\int_{\\partial V} p(x,t)\\,u(x,t)\\cdot n(x)\\,dS. \\] <p>Conservation requires</p> \\[ \\frac{d}{dt}\\int_V p\\,dx+\\int_{\\partial V} p\\,u\\cdot n\\,dS=0. \\] <p>Using the divergence theorem,</p> \\[ \\int_{\\partial V} p\\,u\\cdot n\\,dS=\\int_V \\nabla\\!\\cdot(p\\,u)\\,dx, \\] <p>so</p> \\[ \\int_V \\big(\\partial_t p+\\nabla\\!\\cdot(p\\,u)\\big)\\,dx=0. \\] <p>Since \\(V\\) is arbitrary, the integrand must vanish (in the weak sense), yielding</p> \\[ \\partial_t p+\\nabla\\!\\cdot(p\\,u)=0. \\]"},{"location":"posts/mathematics-foundation.html#appendix-a-integrating-factor-derivation-scalar-linear-ode","title":"Appendix A \u2014 Integrating factor derivation (scalar linear ODE)","text":"<p>This appendix spells out the algebra behind the integrating-factor identity used in Section 1.1.1.</p>"},{"location":"posts/mathematics-foundation.html#a1-problem","title":"A.1 Problem","text":"<p>Let \\(L:[0,1]\\to\\mathbb{R}\\) and \\(r:[0,1]\\to\\mathbb{R}\\) be continuous. Consider the inhomogeneous linear ODE</p> \\[ \\dot x(t)=L(t)x(t)+r(t),\\qquad t\\in[0,1]. \\] <p>Fix \\(0\\le s\\le t\\le 1\\) and assume \\(x(\\cdot)\\) is differentiable.</p>"},{"location":"posts/mathematics-foundation.html#a2-step-1-define-the-integration-factor-and-its-derivative","title":"A.2 Step 1: define the integration factor and its derivative","text":"<p>Define</p> \\[ E(s\\to t):=\\exp\\!\\Big(\\int_s^t L(\\tau)\\,d\\tau\\Big), \\qquad E^{-1}(s\\to t):=\\exp\\!\\Big(-\\int_s^t L(\\tau)\\,d\\tau\\Big). \\] <p>By the chain rule and the fundamental theorem of calculus,</p> \\[ \\frac{d}{dt}E^{-1}(s\\to t) = E^{-1}(s\\to t)\\cdot\\frac{d}{dt}\\Big(-\\int_s^t L(\\tau)\\,d\\tau\\Big) = -L(t)\\,E^{-1}(s\\to t). \\]"},{"location":"posts/mathematics-foundation.html#a3-step-2-product-rule-the-key-identity","title":"A.3 Step 2: product rule (the key identity)","text":"<p>Using the product rule,</p> \\[ \\frac{d}{dt}\\Big(E^{-1}(s\\to t)x(t)\\Big) = \\Big(\\frac{d}{dt}E^{-1}(s\\to t)\\Big)x(t)+E^{-1}(s\\to t)\\dot x(t). \\] <p>Substituting \\(\\frac{d}{dt}E^{-1}(s\\to t)=-L(t)E^{-1}(s\\to t)\\) gives</p> \\[ \\frac{d}{dt}\\Big(E^{-1}(s\\to t)x(t)\\Big) = E^{-1}(s\\to t)\\big(\\dot x(t)-L(t)x(t)\\big). \\] <p>If \\(\\dot x(t)=L(t)x(t)+r(t)\\), then \\(\\dot x(t)-L(t)x(t)=r(t)\\), hence</p> \\[ \\frac{d}{dt}\\Big(E^{-1}(s\\to t)x(t)\\Big)=E^{-1}(s\\to t)\\,r(t). \\]"},{"location":"posts/mathematics-foundation.html#a4-step-3-integrate-from-s-to-t","title":"A.4 Step 3: integrate from \\(s\\) to \\(t\\)","text":"<p>Integrate both sides from \\(s\\) to \\(t\\) (use \\(\\tau\\) as the integration variable):</p> \\[ \\int_s^t \\frac{d}{d\\tau}\\Big(E^{-1}(s\\to \\tau)x(\\tau)\\Big)\\,d\\tau = \\int_s^t E^{-1}(s\\to \\tau)\\,r(\\tau)\\,d\\tau. \\] <p>By the fundamental theorem of calculus, the left-hand side is</p> \\[ E^{-1}(s\\to t)x(t)-E^{-1}(s\\to s)x(s). \\] <p>Since \\(E^{-1}(s\\to s)=\\exp(0)=1\\), we obtain</p> \\[ E^{-1}(s\\to t)x(t) = x(s)+\\int_s^t E^{-1}(s\\to \\tau)\\,r(\\tau)\\,d\\tau. \\]"},{"location":"posts/mathematics-foundation.html#a5-step-4-solve-for-xt-the-closed-form-formula","title":"A.5 Step 4: solve for \\(x(t)\\) (the closed-form formula)","text":"<p>Multiply both sides by \\(E(s\\to t)\\):</p> \\[ x(t)=E(s\\to t)x(s)+\\int_s^t E(s\\to t)\\,E^{-1}(s\\to \\tau)\\,r(\\tau)\\,d\\tau. \\] <p>Finally, note that</p> \\[ E(s\\to t)\\,E^{-1}(s\\to \\tau) = \\exp\\!\\Big(\\int_s^t L(\\xi)\\,d\\xi-\\int_s^\\tau L(\\xi)\\,d\\xi\\Big) = \\exp\\!\\Big(\\int_\\tau^t L(\\xi)\\,d\\xi\\Big) = E(\\tau\\to t), \\] <p>so the solution can be written as</p> \\[ x(t)=E(s\\to t)\\,x(s)+\\int_s^t E(\\tau\\to t)\\,r(\\tau)\\,d\\tau. \\]"},{"location":"posts/mathematics-foundation.html#appendix-b-derivation-of-the-fokkerplanck-equation-isotropic-diffusion","title":"Appendix B \u2014 Derivation of the Fokker\u2013Planck equation (isotropic diffusion)","text":"<p>This appendix derives the Fokker\u2013Planck equation for the diffusion-model-style SDE</p> \\[ dX_t = f(X_t,t)\\,dt + g(t)\\,dW_t,\\qquad X_0\\sim p_0, \\] <p>where \\(X_t\\in\\mathbb{R}^D\\), \\(W_t\\) is a standard \\(D\\)-dimensional Brownian motion, \\(f:\\mathbb{R}^D\\times[0,T]\\to\\mathbb{R}^D\\), and \\(g:[0,T]\\to[0,\\infty)\\). We assume enough regularity (existence of a smooth density \\(p_t\\) and sufficient decay at infinity) to justify exchanging derivatives/integrals and integrating by parts.</p>"},{"location":"posts/mathematics-foundation.html#b0-notation-and-assumptions-what-we-use-implicitly","title":"B.0 Notation and assumptions (what we use implicitly)","text":"<ul> <li>Write \\(X_t=(X_t^{(1)},\\dots,X_t^{(D)})\\) and \\(W_t=(W_t^{(1)},\\dots,W_t^{(D)})\\).</li> <li>\\(\\nabla\\varphi=(\\partial_{x_1}\\varphi,\\dots,\\partial_{x_D}\\varphi)\\), \\(\\Delta\\varphi=\\sum_{i=1}^D \\partial_{x_i x_i}\\varphi\\), and \\(\\nabla\\!\\cdot F=\\sum_{i=1}^D \\partial_{x_i}F_i\\).</li> <li>The quadratic covariation of Brownian motion satisfies</li> </ul> \\[ d\\langle W^{(i)},W^{(j)}\\rangle_t=\\delta_{ij}\\,dt. \\] <p>Consequently, since \\(dX_t^{(i)}=\\cdots + g(t)\\,dW_t^{(i)}\\),</p> \\[ d\\langle X^{(i)},X^{(j)}\\rangle_t=g(t)^2\\,\\delta_{ij}\\,dt. \\]"},{"location":"posts/mathematics-foundation.html#b1-from-itos-formula-to-the-generator-identity-weak-form","title":"B.1 From It\u00f4\u2019s formula to the generator identity (weak form)","text":"<p>Let \\(\\varphi\\in C_c^\\infty(\\mathbb{R}^D)\\) be a smooth test function with compact support. Define the (time-dependent) It\u00f4 generator</p> \\[ (\\mathcal{L}_t\\varphi)(x):= f(x,t)\\cdot\\nabla \\varphi(x) + \\frac{1}{2}g(t)^2\\,\\Delta \\varphi(x). \\] <p>Step 1 (It\u00f4\u2019s formula, written component-wise). Since \\(X_t\\) solves \\(dX_t=f(X_t,t)\\,dt+g(t)\\,dW_t\\), It\u00f4\u2019s formula says</p> \\[ d\\varphi(X_t) = \\sum_{i=1}^D \\partial_{x_i}\\varphi(X_t)\\,dX_t^{(i)} +\\frac12\\sum_{i,j=1}^D \\partial_{x_ix_j}\\varphi(X_t)\\,d\\langle X^{(i)},X^{(j)}\\rangle_t. \\] <p>Substitute \\(dX_t^{(i)}=f_i(X_t,t)\\,dt+g(t)\\,dW_t^{(i)}\\) and \\(d\\langle X^{(i)},X^{(j)}\\rangle_t=g(t)^2\\delta_{ij}\\,dt\\):</p> \\[ \\begin{aligned} d\\varphi(X_t) &amp;= \\sum_{i=1}^D \\partial_{x_i}\\varphi(X_t)\\,\\big(f_i(X_t,t)\\,dt+g(t)\\,dW_t^{(i)}\\big) +\\frac12\\sum_{i,j=1}^D \\partial_{x_ix_j}\\varphi(X_t)\\,g(t)^2\\delta_{ij}\\,dt \\\\ &amp;= \\Big(\\sum_{i=1}^D f_i(X_t,t)\\,\\partial_{x_i}\\varphi(X_t)\\Big)\\,dt +\\frac12 g(t)^2\\Big(\\sum_{i=1}^D \\partial_{x_ix_i}\\varphi(X_t)\\Big)\\,dt  \\;+\\; g(t)\\sum_{i=1}^D \\partial_{x_i}\\varphi(X_t)\\,dW_t^{(i)}. \\end{aligned} \\] <p>Recognizing the dot products, this is exactly</p> \\[ d\\varphi(X_t) = (\\mathcal{L}_t\\varphi)(X_t)\\,dt + g(t)\\,\\nabla\\varphi(X_t)\\cdot dW_t. \\] <p>Step 2 (integrate and take expectations). Integrate from \\(0\\) to \\(t\\):</p> \\[ \\varphi(X_t)-\\varphi(X_0) = \\int_0^t (\\mathcal{L}_s\\varphi)(X_s)\\,ds +\\int_0^t g(s)\\,\\nabla\\varphi(X_s)\\cdot dW_s. \\] <p>Taking expectations and using that the It\u00f4 stochastic integral is a martingale with zero mean (under standard square-integrability conditions),</p> \\[ \\frac{d}{dt}\\mathbb{E}[\\varphi(X_t)] = \\mathbb{E}\\big[(\\mathcal{L}_t\\varphi)(X_t)\\big]. \\tag{B.1} \\] <p>This is the weak evolution equation: it characterizes the time derivative of \\(\\mathbb{E}[\\varphi(X_t)]\\) for every test function \\(\\varphi\\).</p>"},{"location":"posts/mathematics-foundation.html#b2-convert-the-generator-identity-into-a-pde-for-p_t","title":"B.2 Convert the generator identity into a PDE for \\(p_t\\)","text":"<p>If \\(X_t\\) has density \\(p_t\\), then</p> \\[ \\mathbb{E}[\\varphi(X_t)] = \\int_{\\mathbb{R}^D}\\varphi(x)\\,p_t(x)\\,dx, \\qquad \\mathbb{E}\\big[(\\mathcal{L}_t\\varphi)(X_t)\\big] = \\int_{\\mathbb{R}^D} (\\mathcal{L}_t\\varphi)(x)\\,p_t(x)\\,dx. \\] <p>Plugging into \\((\\text{B.1})\\) gives</p> \\[ \\int_{\\mathbb{R}^D}\\varphi(x)\\,\\partial_t p_t(x)\\,dx = \\int_{\\mathbb{R}^D}\\Big(f(x,t)\\cdot\\nabla\\varphi(x) + \\frac{1}{2}g(t)^2\\,\\Delta\\varphi(x)\\Big)p_t(x)\\,dx. \\] <p>Step 1 (drift term: one integration by parts). Write the drift term coordinate-wise:</p> \\[ \\int_{\\mathbb{R}^D} f\\cdot\\nabla\\varphi \\; p_t\\,dx = \\sum_{i=1}^D \\int_{\\mathbb{R}^D} f_i(x,t)\\,\\partial_{x_i}\\varphi(x)\\;p_t(x)\\,dx. \\] <p>Integrate by parts in \\(x_i\\) (boundary terms vanish due to compact support/decay):</p> \\[ \\int_{\\mathbb{R}^D} f_i\\,(\\partial_{x_i}\\varphi)\\,p_t\\,dx = -\\int_{\\mathbb{R}^D} \\varphi(x)\\,\\partial_{x_i}\\big(f_i(x,t)\\,p_t(x)\\big)\\,dx. \\] <p>Summing over \\(i\\) yields</p> \\[ \\int_{\\mathbb{R}^D} f\\cdot\\nabla\\varphi \\; p_t\\,dx = -\\int_{\\mathbb{R}^D} \\varphi(x)\\,\\nabla\\!\\cdot\\big(f(x,t)\\,p_t(x)\\big)\\,dx. \\] <p>Step 2 (diffusion term: two integrations by parts). Since \\(g(t)\\) does not depend on \\(x\\), we can factor it out. Using that the Laplacian is formally self-adjoint under these boundary conditions,</p> \\[ \\int_{\\mathbb{R}^D} (\\Delta\\varphi)\\;p_t\\,dx = \\int_{\\mathbb{R}^D} \\varphi(x)\\,\\Delta p_t(x)\\,dx. \\] <p>One way to see this is coordinate-wise: for each \\(i\\),</p> \\[ \\int (\\partial_{x_i x_i}\\varphi)\\,p_t\\,dx = -\\int (\\partial_{x_i}\\varphi)\\,(\\partial_{x_i}p_t)\\,dx = \\int \\varphi\\,(\\partial_{x_i x_i}p_t)\\,dx, \\] <p>then sum over \\(i=1,\\dots,D\\). Therefore,</p> \\[ \\int_{\\mathbb{R}^D}\\varphi(x)\\,\\partial_t p_t(x)\\,dx = \\int_{\\mathbb{R}^D}\\varphi(x)\\Big( -\\nabla\\!\\cdot(f(x,t)p_t(x)) + \\frac{1}{2}g(t)^2\\,\\Delta p_t(x) \\Big)\\,dx. \\] <p>Since this holds for all \\(\\varphi\\in C_c^\\infty(\\mathbb{R}^D)\\), we conclude the Fokker\u2013Planck equation (in the weak sense, and pointwise under additional regularity):</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\big(f(x,t)\\,p_t(x)\\big) + \\frac{1}{2}g(t)^2\\,\\Delta p_t(x). \\tag{FP} \\]"},{"location":"posts/mathematics-foundation.html#b3-divergence-form-and-the-score","title":"B.3 Divergence form and the score","text":"<p>The Fokker\u2013Planck equation can be rewritten so that the right-hand side is a single divergence \\(-\\nabla\\!\\cdot(\\text{flux})\\), making the \u201cmass conservation\u201d structure explicit.</p> <p>Step 1 (write diffusion as divergence of a flux). Since \\(g(t)\\) is independent of \\(x\\),</p> \\[ \\frac{1}{2}g(t)^2\\,\\Delta p_t = \\frac{1}{2}g(t)^2\\,\\nabla\\!\\cdot(\\nabla p_t) = -\\nabla\\!\\cdot\\Big(-\\frac{1}{2}g(t)^2\\,\\nabla p_t\\Big) = -\\nabla\\!\\cdot\\Big(-\\frac{1}{2}g(t)^2\\,p_t\\,\\nabla\\log p_t\\Big). \\] <p>In the last equality we used \\(\\nabla p_t=p_t\\nabla\\log p_t\\), valid wherever \\(p_t&gt;0\\) (and in a weak sense under mild conditions).</p> <p>Step 2 (combine drift flux and diffusion flux). Substituting into \\((\\text{FP})\\) yields the pure-divergence form</p> \\[ \\partial_t p_t(x) = -\\nabla\\!\\cdot\\Big(f(x,t)\\,p_t(x) - \\frac12 g(t)^2\\,\\nabla_x p_t(x)\\Big) = -\\nabla\\!\\cdot\\Big(\\Big(f(x,t) - \\frac{1}{2}g(t)^2\\,\\nabla_x\\log p_t(x)\\Big)\\,p_t(x)\\Big), \\] <p>which matches the common \u201cdrift minus diffusion-times-score\u201d decomposition.</p> <p>Remark (general diffusion matrix). For a general It\u00f4 SDE \\(dX_t=b\\,dt+\\sigma\\,dW_t\\) with \\(a=\\sigma\\sigma^\\top\\), the diffusion term becomes \\(\\frac12\\sum_{ij}\\partial_{x_i}\\partial_{x_j}(a_{ij}p_t)\\). The isotropic case above corresponds to \\(a(t,x)=g(t)^2 I\\).</p>"},{"location":"posts/mathematics-foundation.html#references","title":"References","text":"<ol> <li>Chieh-Hsin Lai, Yang Song, Dongjun Kim, Yuki Mitsufuji, Stefano Ermon. The Principles of Diffusion Models. arXiv:2510.21890 (2025). <code>https://arxiv.org/abs/2510.21890</code> (DOI: <code>https://doi.org/10.48550/arXiv.2510.21890</code>). Local copy: <code>topics/diffusion/papers/the_principles_of_diffusion_models.pdf</code>.</li> </ol>"},{"location":"posts/transformer.html","title":"Transformer","text":"<ul> <li>Paper: https://arxiv.org/abs/1706.03762 (Vaswani et al., 2017, Attention Is All You Need)</li> <li>Original code (Tensor2Tensor): https://github.com/tensorflow/tensor2tensor</li> </ul> <p>Scope note: we focus on techniques relevant to modern LLMs (primarily decoder-only / autoregressive Transformers); encoder-only architectures (e.g., BERT) and purely supervised encoder models are out of scope here.</p>"},{"location":"posts/transformer.html#what-is-the-model-mathematical-representation","title":"What is the model? (Mathematical representation)","text":"<p>In standard NLP usage, you plug the Transformer into a familiar likelihood:</p>"},{"location":"posts/transformer.html#conditional-sequence-modeling-seq2seq-translation","title":"Conditional sequence modeling (seq2seq / translation)","text":"<ul> <li>Definition (seq2seq): https://en.wikipedia.org/wiki/Seq2seq</li> </ul> <p>Given a source sequence \\(x\\) and a target sequence \\(y = (y_1, \\ldots, y_T)\\), we model</p> \\[ p_\\theta(y \\mid x) = \\prod_{t=1}^{T} p_\\theta\\bigl(y_t \\mid y_{&lt;t}, x\\bigr) \\] <p>Training is maximum likelihood (cross-entropy) with teacher forcing:</p> \\[ \u03b8^* \\,=\\, \\arg\\max_\\theta \\prod_{(x,y)\\in\\mathcal{D}} p_\\theta(y\\mid x) \\,=\\, \\arg\\max_\\theta \\sum_{(x,y)\\in\\mathcal{D}} \\log p_\\theta(y\\mid x) \\,=\\, \\arg\\max_\\theta \\sum_{(x,y)\\in\\mathcal{D}} \\sum_{t=1}^{T} \\log p_\\theta\\bigl(y_t \\mid y_{&lt;t}, x\\bigr) \\]"},{"location":"posts/transformer.html#autoregressive-language-modeling-decoder-only","title":"Autoregressive language modeling (decoder-only)","text":"<p>If there is no conditioning input \\(x\\), the same factorization becomes</p> \\[ p_\\theta(y) = \\prod_{t=1}^{T} p_\\theta\\bigl(y_t \\mid y_{&lt;t}\\bigr) \\] <p>This is the \u201cAR\u201d view: the Transformer block is just a parameterization of the conditional distributions via masked self-attention.</p>"},{"location":"posts/transformer.html#discussion","title":"Discussion","text":"<ul> <li>No explicit latent probabilistic state: unlike classical sequence models such as HMMs or state-space/Markov processes, the standard Transformer LM does not introduce a stochastic hidden state \\(z_t\\) with an explicit transition \\(p(z_t\\mid z_{t-1})\\). The \u201chidden states\u201d in a Transformer are deterministic neural representations produced by forward computation, so there is no marginalization/inference over latent variables in the probabilistic formulation.</li> <li>Truncation is usually practical, not theoretical: the chain-rule factorization conditions on the entire prefix \\(y_{&lt;t}\\) in principle. In practice, models operate under a finite context window (and sometimes additional approximations such as sparse/blocked attention or external memory), which effectively limits what information the model can condition on.</li> <li>Decoding choices: implementations often expose top-\\(k\\) (or top-\\(p\\)) sampling, applied at the final next-token distribution (logits/softmax); this usually does not reduce the forward-pass compute per step, but can simplify the sampling step by restricting to a subset of the vocabulary.</li> <li>Beam search: an alternative decoding procedure that keeps multiple partial hypotheses and selects the highest-scoring sequence under the model, rather than sampling a single next token.</li> <li>Why self-attention matters next: self-attention is the key computation that constructs a context-dependent representation of the prefix, which is then used to parameterize each conditional distribution \\(p_\\theta(y_t\\mid \\cdot)\\).</li> </ul>"},{"location":"posts/transformer.html#attention-self-attention-multi-head","title":"Attention / Self-Attention / Multi-Head","text":""},{"location":"posts/transformer.html#scaled-dot-product-attention","title":"Scaled dot-product attention","text":"<p>Attention takes queries \\(Q\\), keys \\(K\\), values \\(V\\), and returns a weighted sum of values. The weights are content-dependent similarities between queries and keys.</p> \\[ \\mathrm{Attn}(Q,K,V;M) \\,=\\, \\mathrm{softmax}\\!\\left(\\frac{QK^\\top}{\\sqrt{d_k}} + M\\right) V \\] <ul> <li>\\(d_k\\) is the key/query dimension per head.</li> <li>\\(M\\) is an additive mask (typically \\(0\\) for allowed positions and \\(-\\infty\\) for disallowed ones). For decoder-only LLMs, \\(M\\) encodes the causal constraint \u201cdo not attend to the future\u201d.</li> </ul> <p></p>"},{"location":"posts/transformer.html#self-attention-vs-cross-attention","title":"Self-attention vs cross-attention","text":"<ul> <li>Self-attention: \\(Q,K,V\\) are all computed from the same sequence representation \\(X\\).</li> <li>Cross-attention (encoder-decoder): \\(Q\\) comes from the decoder states, while \\(K,V\\) come from the encoder outputs.</li> </ul> <p>In practice you form \\(Q,K,V\\) by learned linear projections, e.g. \\(Q = XW_Q\\), \\(K = XW_K\\), \\(V = XW_V\\).</p>"},{"location":"posts/transformer.html#why-the-1sqrtd_k-scale","title":"Why the \\(1/\\sqrt{d_k}\\) scale?","text":"<p>Without scaling, the dot products \\(QK^\\top\\) tend to grow with \\(d_k\\), pushing softmax into saturation and making optimization harder. The scale roughly stabilizes the magnitude.</p> <p>A common (approximate) variance argument is:</p> \\[ s \\,=\\, q^\\top k \\,=\\, \\sum_{i=1}^{d_k} q_i k_i \\] <p>Assume components are roughly zero-mean with unit variance and weakly correlated, e.g. \\(q_i, k_i\\) behave like i.i.d. with \\(\\mathbb{E}[q_i]=\\mathbb{E}[k_i]=0\\), \\(\\mathrm{Var}(q_i)=\\mathrm{Var}(k_i)=1\\). Then \\(\\mathbb{E}[q_i k_i]=0\\) and</p> \\[ \\mathrm{Var}(s) \\approx \\sum_{i=1}^{d_k} \\mathrm{Var}(q_i k_i) \\approx d_k. \\] <p>So \\(s\\) has typical scale \\(\\sqrt{d_k}\\). Dividing by \\(\\sqrt{d_k}\\) makes the logits fed to softmax stay \\(\\mathcal{O}(1)\\):</p> \\[ \\frac{s}{\\sqrt{d_k}} \\text{ has } \\mathrm{Var}\\!\\left(\\frac{s}{\\sqrt{d_k}}\\right) \\approx 1. \\] <p>This is not a fully rigorous derivation (the learned projections and LayerNorm change the exact statistics), but it explains why scaling helps: it reduces softmax saturation and keeps gradients healthier.</p> <p>Concrete example: if \\(d_k=64\\), the unscaled dot-product has a typical magnitude around \\(\\sqrt{64}=8\\). Softmax over numbers with magnitude \\(\\sim 8\\) can become very peaky early in training; scaling brings those logits back to a gentler range.</p>"},{"location":"posts/transformer.html#how-to-kill-the-sqrtd_k-where-to-put-the-scale","title":"How to \u201ckill\u201d the \\(\\sqrt{d_k}\\) (where to put the scale)","text":"<p>You can\u2019t really make the \\(\\sqrt{d_k}\\) issue disappear; you can only move the scale so the attention logits stay \\(\\mathcal{O}(1)\\). The standard choice is the explicit \\(1/\\sqrt{d_k}\\), but there are equivalent alternatives:</p> <ul> <li> <p>Use an explicit (possibly learnable) temperature: \\(\\mathrm{softmax}((QK^T)\\cdot \\alpha + M)V\\), where \\(\\alpha\\) is a scalar (or per-head scalar). Initialize \\(\\alpha=1/\\sqrt{d_k}\\). Some implementations keep \\(\\alpha\\) fixed; others learn it (a learnable \u201ctemperature\u201d \\(\u03c4\\)).</p> </li> <li> <p>Normalize queries/keys (cosine attention): replace \\(q,k\\) with \\(\\hat q=q/\\|q\\|\\) and \\(\\hat k=k/\\|k\\|\\). Then \\(\\hat q\\cdot \\hat k\\in[-1,1]\\), so logits no longer grow with \\(d_k\\). In practice you often re-introduce a learnable scale \\(g\\) (temperature) because \\([-1,1]\\) may be too \u201ccold\u201d for sharp attention.</p> </li> <li> <p>Bake the scale into the projections: if the components of \\(q\\) and \\(k\\) have variance \\(\\sigma^2\\), then \\(\\mathrm{Var}(q\\cdot k) \\approx d_k\\,\\sigma^4\\). Picking \\(\\sigma^2\\approx 1/\\sqrt{d_k}\\) (i.e., std \\(\\approx d_k^{-1/4}\\) for both \\(q\\) and \\(k\\)) keeps \\(q\\cdot k\\) at \\(\\mathcal{O}(1)\\) even without dividing by \\(\\sqrt{d_k}\\). This is equivalent to putting a factor \\(d_k^{-1/4}\\) into both \\(W_Q\\) and \\(W_K\\).</p> </li> </ul> <p>Important nuance: LayerNorm/RMSNorm stabilizes the residual stream scale, but it does not automatically control the statistics of the attention logits in a way that removes the need for a temperature/scale.</p>"},{"location":"posts/transformer.html#does-this-relate-to-temperature-or-top-k","title":"Does this relate to temperature or top-\\(k\\)?","text":"<ul> <li>Temperature: you can view the attention softmax as having a fixed \u201ctemperature\u201d \\(\\tau\\), since \\(\\mathrm{softmax}(s/\\sqrt{d_k})\\) is equivalent to \\(\\mathrm{softmax}(s/\\tau)\\) with \\(\\tau=\\sqrt{d_k}\\). This is separate from decoding temperature, which is applied to the final vocabulary logits for next-token sampling.</li> <li>Top-\\(k\\): top-\\(k\\) sampling is a decoding-time heuristic applied to the vocabulary distribution (keep the top \\(k\\) tokens, renormalize). Standard attention does not use top-\\(k\\) over positions; it computes a full distribution over allowed positions. (There are research/engineering variants like sparse/top-\\(k\\) attention, but that\u2019s a different idea.)</li> </ul>"},{"location":"posts/transformer.html#multi-head-attention-mha","title":"Multi-head attention (MHA)","text":"<p>Multi-head attention runs several attention \u201cheads\u201d in parallel with different learned projections, then concatenates their outputs:</p> \\[ \\mathrm{MHA}(X) \\,=\\, \\mathrm{Concat}\\bigl(\\mathrm{Attn}(Q_1,K_1,V_1;M),\\ldots,\\mathrm{Attn}(Q_h,K_h,V_h;M)\\bigr) W_O \\] <p>Intuition: different heads can specialize (local vs global dependencies, syntax vs coreference, etc.).</p> <p></p>"},{"location":"posts/transformer.html#minimal-pytorch-code-self-attention","title":"Minimal PyTorch code (self-attention)","text":"<pre><code>import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass SimpleMHA(nn.Module):\n    \"\"\"Minimal multi-head self-attention with fused QKV projection.\"\"\"\n\n    def __init__(self, d_model, n_heads, dropout=0.0, bias=True):\n        super().__init__()\n        assert d_model % n_heads == 0\n        self.n_heads = n_heads\n        self.d_head = d_model // n_heads\n        self.qkv = nn.Linear(d_model, 3 * d_model, bias=bias)\n        self.proj = nn.Linear(d_model, d_model, bias=bias)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, causal=False):\n        # x: (B, T, C)\n        B, T, C = x.shape\n        qkv = self.qkv(x)  # (B, T, 3C)\n        q, k, v = qkv.chunk(3, dim=-1)\n\n        # (B, nh, T, hs)\n        q = q.view(B, T, self.n_heads, self.d_head).transpose(1, 2)\n        k = k.view(B, T, self.n_heads, self.d_head).transpose(1, 2)\n        v = v.view(B, T, self.n_heads, self.d_head).transpose(1, 2)\n\n        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.d_head)  # (B, nh, T, T)\n        if causal:\n            mask = torch.tril(torch.ones(T, T, device=x.device, dtype=torch.bool))\n            att = att.masked_fill(~mask, float(\"-inf\"))\n\n        att = F.softmax(att, dim=-1)\n        att = self.dropout(att)\n        y = att @ v  # (B, nh, T, hs)\n\n        y = y.transpose(1, 2).contiguous().view(B, T, C)  # merge heads\n        return self.proj(y)\n\n\n# Example:\n# x = torch.randn(2, 128, 768)\n# y = SimpleMHA(768, 12)(x, causal=True)\n</code></pre>"},{"location":"posts/transformer.html#notes-on-compute","title":"Notes on compute","text":"<ul> <li>The attention matrix is \\(T\\times T\\) for sequence length \\(T\\), so naive attention costs \\(O(T^2)\\) memory/time per layer.</li> <li>During autoregressive decoding, KV cache avoids recomputing past \\(K,V\\) and makes each new token step incremental.</li> </ul>"},{"location":"posts/transformer.html#discussion-compute","title":"Discussion (Compute)","text":"<ul> <li>Compute reality check (what actually gets multiplied): for a decoder-only Transformer layer with batch \\(B\\),   sequence length \\(T\\), model width \\(d_{model}\\), and \\(h\\) heads (so \\(d_{head}=d_{model}/h\\)), the main   multiplications are:</li> <li>QKV projection: \\(X\\in\\mathbb{R}^{B\\times T\\times d_{model}}\\) times \\(W_{QKV}\\in\\mathbb{R}^{d_{model}\\times 3d_{model}}\\) \\(\\Rightarrow\\) about \\(3\\,B\\,T\\,d_{model}^2\\) scalar multiplies.</li> <li>Attention scores: \\(QK^\\top\\) per head is \\((T\\times d_{head})\\cdot(d_{head}\\times T)\\Rightarrow (T\\times T)\\), so across all     heads it is about \\(B\\,h\\,T^2\\,d_{head}=B\\,T^2\\,d_{model}\\) multiplies.<ul> <li>What \u201ceach head computes\u201d concretely:<ul> <li>For a fixed head \\(i\\), each score entry between a query position \\(t\\) and a key position \\(s\\) is a dot product between two     \\(d_{head}\\)-dimensional vectors: \\(q_t^{(i)}\\cdot k_s^{(i)}\\). Computing one score uses \\(d_{head}\\) scalar multiplications and     \\(d_{head}-1\\) scalar additions (sum-reduction).</li> <li>The softmax turns the \\(T\\) scores for a fixed query position \\(t\\) into a weight vector \\(\\alpha_{t,1:T}^{(i)}\\) over positions.</li> <li>The head output at position \\(t\\) is a weighted sum over the value vectors \\(v_{1:T}^{(i)}\\): it multiplies each \\(v_s^{(i)}\\) by     \\(\\alpha_{t,s}^{(i)}\\) and sums over \\(s\\). This is exactly the matrix multiply \\(\\alpha^{(i)}V^{(i)}\\) (often written as     \\(\\mathrm{Attn}\\cdot V\\)).</li> </ul> </li> </ul> </li> <li>Weighted sum: \\(\\mathrm{Attn}\\cdot V\\) has the same order as scores, another \\(B\\,T^2\\,d_{model}\\) multiplies.</li> <li>Output projection: concatenated heads \\((B\\times T\\times d_{model})\\) times \\(W_O\\in\\mathbb{R}^{d_{model}\\times d_{model}}\\) \\(\\Rightarrow\\) about \\(B\\,T\\,d_{model}^2\\) multiplies.</li> <li>Takeaway: splitting into heads does not automatically reduce total compute at fixed \\(d_{model}\\); it mostly changes     how compute is structured/parallelized. Naively, the attention matrix itself has \\(B\\,h\\,T^2\\) elements, which is why     attention is often described as \\(O(T^2)\\) in time/memory (unless using optimized kernels like FlashAttention that avoid     materializing the full \\(T\\times T\\) matrix).</li> </ul>"},{"location":"posts/transformer.html#normalization-layernorm-rmsnorm","title":"Normalization (LayerNorm / RMSNorm)","text":"<p>Transformers rely heavily on normalization for stable optimization at depth.</p>"},{"location":"posts/transformer.html#layernorm-ln","title":"LayerNorm (LN)","text":"<p>LayerNorm normalizes each token\u2019s feature vector across the model dimension. For a vector \\(x\\in\\mathbb{R}^{d_{model}}\\) (one token, one layer):</p> \\[ \\mathrm{LN}(x) = \\gamma\\odot \\frac{x-\\mu}{\\sqrt{\\sigma^2+\\epsilon}} + \\beta, \\qquad \\mu=\\frac{1}{d_{model}}\\sum_j x_j,\\ \\ \\sigma^2=\\frac{1}{d_{model}}\\sum_j (x_j-\\mu)^2. \\] <p>Key properties:</p> <ul> <li>It is per-token (no dependence on batch size), so it works well for variable-length sequences and small batches.</li> <li>The learned \\(\\gamma,\\beta\\) let the network recover useful scales after normalization.</li> </ul>"},{"location":"posts/transformer.html#pre-ln-vs-post-ln-where-ln-sits","title":"Pre-LN vs Post-LN (where LN sits)","text":"<ul> <li>Post-LN (original 2017 diagram): \\(y=\\mathrm{LN}(x+\\mathrm{Sublayer}(x))\\).</li> <li>Pre-LN (common in modern LLMs): \\(y=x+\\mathrm{Sublayer}(\\mathrm{LN}(x))\\).</li> </ul> <p>Pre-LN typically trains more reliably for very deep models because gradients can flow through the residual path more directly.</p>"},{"location":"posts/transformer.html#rmsnorm-common-modern-variant","title":"RMSNorm (common modern variant)","text":"<p>RMSNorm removes the mean-subtraction and normalizes by root-mean-square only (cheaper, often similar in practice):</p> \\[ \\mathrm{RMSNorm}(x) = \\gamma\\odot \\frac{x}{\\sqrt{\\frac{1}{d_{model}}\\sum_j x_j^2 + \\epsilon}}. \\] <p>Relation to the \\(1/\\sqrt{d_k}\\) attention scale: LN/RMSNorm helps keep activations in a sane range across layers, but attention still needs an explicit or implicit temperature to prevent dot-product logits from becoming too large as dimensions change.</p>"},{"location":"posts/transformer.html#positional-encoding-embeddings","title":"Positional encoding / embeddings","text":"<p>Self-attention alone is permutation-invariant: without position information, the model cannot distinguish sequences that are just token-permutations. In Transformers, position is typically injected by adding a position-dependent vector to the token embedding at the input of each layer (or at least the first layer).</p>"},{"location":"posts/transformer.html#original-sinusoidal-positional-encoding-vaswani-et-al-2017","title":"Original sinusoidal positional encoding (Vaswani et al., 2017)","text":"<p>The paper uses a fixed (non-learned) sinusoidal encoding with dimension \\(d_{model}\\). For position \\(pos\\) and dimension index \\(i\\in\\{0,\\ldots, d_{model}/2-1\\}\\):</p> \\[ \\mathrm{PE}(pos, 2i) = \\sin\\bigl(pos / 10000^{2i/d_{model}}\\bigr) \\] \\[ \\mathrm{PE}(pos, 2i+1) = \\cos\\bigl(pos / 10000^{2i/d_{model}}\\bigr) \\] <p>Then the model uses \\(X_{in}(pos) = \\mathrm{Embed}(token) + \\mathrm{PE}(pos)\\).</p> <p>Practical note: many modern LLMs use learned absolute positional embeddings, relative position biases, or RoPE; the sinusoidal version is still useful as a clean reference and can generalize to longer lengths than seen in training.</p>"},{"location":"posts/transformer.html#angle-phase-interpretation-why-sincos-helps","title":"\u201cAngle / phase\u201d interpretation (why sin/cos helps)","text":"<p>Define a frequency per pair \\(i\\):</p> \\[ \\omega_i = 10000^{-2i/d_{model}}. \\] <p>Each 2D pair \\((\\mathrm{PE}_{2i}, \\mathrm{PE}_{2i+1})\\) is a unit-circle point at angle \\(\\omega_i\\,pos\\):</p> \\[ \\bigl[\\sin(\\omega_i\\,pos),\\ \\cos(\\omega_i\\,pos)\\bigr]. \\] <p>So increasing the position by \\(\\Delta\\) corresponds to a rotation by angle \\(\\omega_i\\,\\Delta\\) in that 2D plane.</p> <p>Two useful consequences:</p> <ul> <li>Relative offsets show up as phase differences: the dot product of the two unit vectors at positions \\(p\\) and \\(q\\) is   \\(\\cos(\\omega_i(p-q))\\). So a simple bilinear form can access functions of \\(p-q\\) (relative position), not just \\(p\\) itself.</li> <li>Shift structure is linear in \\(\\sin/\\cos\\): using trig identities,   \\(\\sin(\\omega(p+\\Delta))\\) and \\(\\cos(\\omega(p+\\Delta))\\) can be written as a fixed linear transform of   \\(\\sin(\\omega p)\\) and \\(\\cos(\\omega p)\\) (with coefficients depending only on \\(\\Delta\\)). This makes it easier for attention   layers to learn \u201crelative position\u201d patterns using linear projections.</li> </ul>"},{"location":"posts/transformer.html#rope-rotary-positional-embedding","title":"RoPE (Rotary Positional Embedding)","text":"<p>RoPE is a widely used alternative in modern decoder-only LLMs. Instead of adding a positional vector to the token embedding, it rotates the query/key vectors in 2D subspaces as a function of position. Intuitively, position becomes a phase that lives inside the attention dot product.</p> <p>Take one head and one position \\(pos\\). For each 2D pair of channels \\((2i, 2i+1)\\), define a position-dependent angle \\(\u03b8_i(pos)\\) (often using the same frequency schedule as sinusoidal PE):</p> \\[ \u03b8_i(pos) = pos\\cdot 10000^{-2i/d_{head}}. \\] <p>Apply a rotation to the \\(q\\) and \\(k\\) components in that 2D plane:</p> \\[ \\begin{bmatrix} q'_{2i} \\\\ q'_{2i+1} \\end{bmatrix} = \\begin{bmatrix} \\cos(\u03b8_i) &amp; -\\sin(\u03b8_i) \\\\ \\sin(\u03b8_i) &amp; \\cos(\u03b8_i) \\end{bmatrix} \\begin{bmatrix} q_{2i} \\\\ q_{2i+1} \\end{bmatrix}, \\qquad \\begin{bmatrix} k'_{2i} \\\\ k'_{2i+1} \\end{bmatrix} = \\begin{bmatrix} \\cos(\u03b8_i) &amp; -\\sin(\u03b8_i) \\\\ \\sin(\u03b8_i) &amp; \\cos(\u03b8_i) \\end{bmatrix} \\begin{bmatrix} k_{2i} \\\\ k_{2i+1} \\end{bmatrix}. \\] <p>Then attention uses \\(q'\\cdot k'\\) as usual.</p> <p>Why this helps:</p> <ul> <li>Relative-position behavior \u201cfor free\u201d: because rotations compose, the dot product between rotated vectors depends on the   angle difference, which is a function of \\((pos_q - pos_k)\\). This makes it natural for the model to learn relative-offset   patterns without explicit relative-position embeddings.</li> <li>Extrapolation: RoPE often behaves better than learned absolute embeddings when evaluating at longer context lengths.</li> </ul> <p>Practical note: RoPE is typically applied only to a prefix of head dimensions (or with variants like partial rotary / scaling) depending on the architecture.</p>"},{"location":"posts/transformer.html#causal-masking-and-generative-vs-discriminative-discussion","title":"Causal masking and \u201cgenerative vs discriminative\u201d discussion","text":""},{"location":"posts/transformer.html#what-is-the-causal-mask","title":"What is the causal mask?","text":"<p>In a decoder-only (autoregressive) Transformer, token \\(t\\) is only allowed to attend to positions \\(\\le t\\). This is enforced by an additive mask \\(M\\) inside attention:</p> \\[ \\mathrm{Attn}(Q,K,V;M) = \\mathrm{softmax}\\!\\left(\\frac{QK^T}{\\sqrt{d_k}} + M\\right)V. \\] <p>A standard causal mask is</p> \\[ M_{t,s} = \\begin{cases} 0, &amp; s\\le t\\\\ -\\infty, &amp; s&gt;t. \\end{cases} \\] <p>So future positions get \\(-\\infty\\) logits and therefore zero probability after softmax.</p> <p>Two practical notes:</p> <ul> <li>Training can still be parallel: even though the model is \u201cleft-to-right\u201d, we compute all \\(t\\) in one forward pass by masking.</li> <li>In generation, the same constraint is what makes incremental decoding valid: the next-token distribution depends only on the prefix.</li> </ul>"},{"location":"posts/transformer.html#why-does-causal-masking-make-it-a-generative-model","title":"Why does causal masking make it a generative model?","text":"<p>With the causal mask, the model parameterizes a proper left-to-right factorization of a joint distribution over sequences:</p> \\[ p_\\theta(y) = \\prod_{t=1}^{T} p_\\theta(y_t\\mid y_{&lt;t}). \\] <p>Because the conditionals are defined for every position \\(t\\), we can generate a sequence by sampling or taking argmax repeatedly: start from a BOS token, sample \\(y_1\\sim p(y_1)\\), then \\(y_2\\sim p(y_2\\mid y_1)\\), etc. (In practice we use decoding algorithms such as greedy, top-\\(k\\), top-\\(p\\), beam search.)</p> <p>This is what people usually mean by \u201cgenerative\u201d in the LLM context: the model defines a sequential process that produces the whole string.</p>"},{"location":"posts/transformer.html#softmax-does-not-decide-generative-vs-discriminative","title":"Softmax does not decide generative vs discriminative","text":"<p>Softmax is just a way to turn logits into a normalized categorical distribution.</p> <ul> <li>In an LM, softmax is over the vocabulary and represents \\(p_\\theta(y_t\\mid y_{&lt;t})\\) (a conditional distribution used to build a joint by the product rule).</li> <li>In a classifier, softmax is over labels and represents \\(p_\\theta(label\\mid x)\\) (a conditional distribution directly optimized for prediction).</li> </ul> <p>So \u201cusing softmax\u201d does not imply discriminative or generative; the training objective and factorization decide that.</p>"},{"location":"posts/transformer.html#where-does-bert-fit","title":"Where does BERT fit?","text":"<p>BERT uses bidirectional self-attention (no causal mask) and is pretrained with masked language modeling (MLM): predict masked tokens given the surrounding context on both sides.</p> <p>That objective learns strong representations for understanding tasks and is typically used in a discriminative setting (classification, tagging, retrieval): you feed \\(x\\) and predict labels \\(y\\), i.e. \\(p(y\\mid x)\\).</p> <p>MLM itself is a conditional / denoising objective and does not directly define a clean left-to-right joint \\(p(x)=\\prod_t p(x_t\\mid x_{&lt;t})\\), which is why BERT is not the default choice for straightforward next-token generation. (There are ways to sample from an MLM with iterative masking / Gibbs-style updates, but that is a different generation mechanism and usually less convenient than AR decoding.)</p>"},{"location":"posts/transformer.html#minimal-code-an-attention-block-with-residual-pathway","title":"Minimal code: an attention block (with residual pathway)","text":"<p>Below is a minimal \u201cTransformer block\u201d around self-attention (Pre-LN style). It reuses the <code>SimpleMHA</code> module defined earlier in this note.</p> <pre><code>import torch\nimport torch.nn as nn\n\n\nclass MLP(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.0):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(d_model, d_ff),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_ff, d_model),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass TransformerBlock(nn.Module):\n    \"\"\"Pre-LN decoder block: x &lt;- x + Attn(LN(x)); x &lt;- x + MLP(LN(x)).\"\"\"\n\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.0):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(d_model)\n        self.attn = SimpleMHA(d_model, n_heads, dropout=dropout)\n        self.ln2 = nn.LayerNorm(d_model)\n        self.mlp = MLP(d_model, d_ff, dropout=dropout)\n\n    def forward(self, x, causal=True):\n        # Residual (skip) pathway:\n        x = x + self.attn(self.ln1(x), causal=causal)\n        x = x + self.mlp(self.ln2(x))\n        return x\n\n\n# Example:\n# x = torch.randn(2, 128, 768)\n# block = TransformerBlock(d_model=768, n_heads=12, d_ff=3072, dropout=0.1)\n# y = block(x, causal=True)\n</code></pre>"},{"location":"posts/transformer.html#passway-the-resnet-style-skip-connection-in-this-context","title":"\u201cPassway\u201d = the ResNet-style skip connection (in this context)","text":"<p>The key line is <code>x = x + F(x)</code> (here, <code>F</code> is attention or MLP applied to a normalized input). That <code>+ x</code> term is exactly the ResNet skip/residual pathway:</p> <ul> <li>In ResNet you often write \\(x_{\\ell+1} = x_{\\ell} + F(x_{\\ell})\\).</li> <li>In a Pre-LN Transformer block you have \\(x_{\\ell+1} = x_{\\ell} + \\mathrm{Attn}(\\mathrm{LN}(x_{\\ell}))\\) (and then another residual for the MLP).</li> </ul> <p>This \u201cidentity passway\u201d makes optimization much easier: even if \\(F\\) starts near zero, information and gradients can flow through the identity path.</p>"},{"location":"posts/transformer.html#relation-to-odes-depth-as-time-intuition","title":"Relation to ODEs (depth-as-time intuition)","text":"<p>If you view layer index \\(\\ell\\) as a discrete \u201ctime\u201d step, then a residual update</p> \\[ x_{\\ell+1} = x_{\\ell} + h\\,f(x_{\\ell},\\ell) \\] <p>looks like a forward Euler discretization of an ODE \\(\\frac{dx}{dt} = f(x,t)\\). In this analogy:</p> <ul> <li>the residual branch (attention/MLP) is the vector field \\(f\\),</li> <li>the skip connection is the \\(+x_{\\ell}\\) term in Euler\u2019s method,</li> <li>and (sometimes) you can interpret hyperparameters / scaling as affecting the effective step size \\(h\\).</li> </ul> <p>In the Transformer context this is mainly an intuition for why residual networks train stably and how depth composes small updates; it is not required to treat the model as a true continuous-time system.</p>"},{"location":"posts/transformer.html#guide-how-far-this-is-from-gpt-3-level-detail-and-whats-next","title":"Guide: how far this is from GPT-3-level detail (and what\u2019s next)","text":"<p>This note covers the \u201ccore math blocks\u201d (AR factorization, attention, masks, normalization, positional methods, residual pathway), but it is still far from a full GPT-3-style training + systems picture. Below is a concrete checklist of what\u2019s missing mainly in knowledge details which we will talk about in the furute.</p> <p>What this article is still missing vs a GPT-3-level understanding:</p> <ul> <li>Exact architecture details used in modern LLMs: Pre-LN vs Post-LN variants in the wild, RMSNorm vs LayerNorm choices, MLP variants (GeLU vs SwiGLU), and common efficiency tweaks (MQA/GQA, grouped QK/V layouts).</li> <li>Tokenization and text normalization: BPE/unigram tokenizers, byte-level vs unicode handling, special tokens, and how tokenization choices affect context length and compute.</li> <li>Training objective details: next-token loss implementation details (label shifting, padding/masking), how perplexity is computed, and what is (and isn\u2019t) \u201cteacher forcing\u201d in practice.</li> <li>Optimization recipe: AdamW vs variants, weight decay placement, learning-rate schedules (warmup + cosine/linear), gradient clipping, dropout usage, and typical hyperparameter ranges.</li> <li>Initialization and stability tricks: residual scaling, logit scaling, norm/activation scaling, and what breaks at depth/width.</li> <li>Data pipeline: dataset composition, deduplication, filtering, mixing ratios, curriculum/order effects, and contamination issues.</li> <li>Evaluation + monitoring: held-out loss curves, downstream benchmarks, calibration, memorization tests, and how to interpret regressions.</li> <li>Systems/engineering: distributed training (data/tensor/pipeline parallelism), mixed precision, activation checkpointing, optimizer state sharding, throughput bottlenecks, and kernel-level attention optimizations.</li> </ul>"},{"location":"posts/transformer.html#references","title":"References","text":"<ul> <li> <p>Local note: vit-dit.md (ViT and DiT)</p> </li> <li> <p>Paper: https://arxiv.org/pdf/1409.3215 (Sutskever et al., 2014, Sequence to Sequence Learning with Neural Networks)</p> </li> <li>Course: https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html (Lena Voita, NLP Course: Seq2Seq and Attention)</li> <li>Tech report: https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf (Radford et al., 2019, Language Models are Unsupervised Multitask Learners; GPT-2)</li> <li>Paper: https://arxiv.org/abs/2005.14165 (Brown et al., 2020, Language Models are Few-Shot Learners; GPT-3)</li> <li>Video: https://www.youtube.com/watch?v=kCc8FmEb1nY (Andrej Karpathy, Let's build GPT: from scratch, in code, spelled out.)</li> <li>Code: https://github.com/karpathy/minGPT (Andrej Karpathy, minGPT code)</li> <li>Code: https://github.com/karpathy/nanoGPT (Andrej Karpathy, nanoGPT code)</li> </ul>"},{"location":"posts/vit-dit.html","title":"ViT and DiT","text":""},{"location":"posts/vit-dit.html#quick-map","title":"Quick map","text":"<ul> <li>ViT (Vision Transformer): use the Transformer encoder (bidirectional self-attention; no causal mask) over a sequence of image patch tokens for classification and representation learning.</li> <li>DiT (Diffusion Transformer): (standard DiT) also uses an encoder-style Transformer backbone (bidirectional self-attention; no causal mask) inside a diffusion model to predict noise / velocity / score-like targets over latent/image tokens.</li> </ul> <p>If you\u2019re coming from the LLM note, see the self-attention recap in transformer.md.</p>"},{"location":"posts/vit-dit.html#vit-vision-transformer","title":"ViT (Vision Transformer)","text":""},{"location":"posts/vit-dit.html#core-idea","title":"Core idea","text":"<ul> <li>Tokenization: split an image into fixed-size patches (e.g., 16\u00d716), flatten each patch, and project to an embedding dimension.</li> <li>Add positional embeddings (learned or sinusoidal-like), then run a Transformer encoder.</li> <li>Use a special classification token <code>[CLS]</code> (original ViT) or pooled token features for classification.</li> </ul> <p>A common abstraction:</p> <ul> <li>Patches: \\(x \\in \\mathbb{R}^{H\\times W\\times C}\\) \u2192 \\(N\\) patches \u2192 \\(X \\in \\mathbb{R}^{N\\times d}\\)</li> <li>Encoder: \\(Z = \\mathrm{Encoder}(X + \\mathrm{PosEmbed})\\)</li> <li>Class head: \\(\\hat y = \\mathrm{head}(Z_{\\mathrm{cls}})\\) (if using <code>[CLS]</code>)</li> </ul> <p></p>"},{"location":"posts/vit-dit.html#what-to-pay-attention-to-implementation-details","title":"What to pay attention to (implementation details)","text":"<ul> <li>Patch embedding layer: typically <code>Conv2d(kernel=p, stride=p)</code> is equivalent to patchify + linear.</li> <li>Positional embeddings: learned absolute embeddings are common; resizing/interpolation is needed when changing resolution.</li> <li>Regularization and data: ViT often needs strong augmentation and large-scale pretraining to match CNN baselines.</li> </ul> <p>Minimal code sketch (patch embedding + tokens):</p> <pre><code>import torch\nimport torch.nn as nn\n\n\nclass PatchEmbed(nn.Module):\n    \"\"\"Image -&gt; patch tokens using a strided conv.\"\"\"\n\n    def __init__(self, in_chans=3, d_model=768, patch_size=16):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_chans, d_model, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        # x: (B, C, H, W) with H,W divisible by patch_size\n        x = self.proj(x)              # (B, d_model, H/p, W/p)\n        x = x.flatten(2).transpose(1, 2)  # (B, N, d_model)\n        return x\n\n\ndef make_vit_tokens(x, patch_embed, cls_token, pos_embed):\n    \"\"\"Returns token sequence ready for a Transformer encoder.\"\"\"\n    tok = patch_embed(x)  # (B, N, d)\n    B = tok.shape[0]\n    cls = cls_token.expand(B, -1, -1)  # (B, 1, d)\n    tok = torch.cat([cls, tok], dim=1)  # (B, 1+N, d)\n    tok = tok + pos_embed[:, : tok.shape[1]]\n    return tok\n\n\n# Example shapes (not a full model):\n# x = torch.randn(2, 3, 224, 224)\n# patch = PatchEmbed(in_chans=3, d_model=192, patch_size=16)\n# cls_token = nn.Parameter(torch.zeros(1, 1, 192))\n# pos_embed = nn.Parameter(torch.zeros(1, 1 + (224 // 16) ** 2, 192))\n# tokens = make_vit_tokens(x, patch, cls_token, pos_embed)\n</code></pre> <p>Minimal attention block (ViT encoder block):</p> <pre><code>import torch\nimport torch.nn as nn\n\n\nclass ViTEncoderBlock(nn.Module):\n    \"\"\"Pre-LN encoder block used in most ViT-style implementations.\"\"\"\n\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.0):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(d_model)\n        self.attn = nn.MultiheadAttention(\n            embed_dim=d_model,\n            num_heads=n_heads,\n            dropout=dropout,\n            batch_first=True,  # x: (B, N, C)\n        )\n        self.ln2 = nn.LayerNorm(d_model)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model, d_ff),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_ff, d_model),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        # x: (B, N, d_model)\n        # Residual pathway (same ResNet-style \"passway\"): x &lt;- x + F(x)\n        attn_out, _ = self.attn(self.ln1(x), self.ln1(x), self.ln1(x), need_weights=False)\n        x = x + attn_out\n        x = x + self.mlp(self.ln2(x))\n        return x\n</code></pre> <p>Minimal full ViT encoder skeleton (patch embed -&gt; blocks -&gt; head):</p> <pre><code>import torch\nimport torch.nn as nn\n\n\nclass ViT(nn.Module):\n    def __init__(\n        self,\n        image_size=224,\n        patch_size=16,\n        in_chans=3,\n        n_classes=1000,\n        d_model=768,\n        depth=12,\n        n_heads=12,\n        d_ff=3072,\n        dropout=0.0,\n    ):\n        super().__init__()\n        assert image_size % patch_size == 0\n        n_patches = (image_size // patch_size) ** 2\n\n        self.patch = PatchEmbed(in_chans=in_chans, d_model=d_model, patch_size=patch_size)\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + n_patches, d_model))\n        self.drop = nn.Dropout(dropout)\n\n        self.blocks = nn.ModuleList(\n            [ViTEncoderBlock(d_model, n_heads, d_ff, dropout=dropout) for _ in range(depth)]\n        )\n        self.norm = nn.LayerNorm(d_model)\n        self.head = nn.Linear(d_model, n_classes)\n\n    def forward(self, x):\n        # x: (B, C, H, W)\n        tok = make_vit_tokens(x, self.patch, self.cls_token, self.pos_embed)\n        tok = self.drop(tok)\n        for blk in self.blocks:\n            tok = blk(tok)\n        tok = self.norm(tok)\n        cls = tok[:, 0]  # [CLS]\n        return self.head(cls)\n\n\n# Example:\n# model = ViT(image_size=224, patch_size=16, d_model=192, depth=6, n_heads=3, d_ff=768)\n# x = torch.randn(2, 3, 224, 224)\n# logits = model(x)\n</code></pre>"},{"location":"posts/vit-dit.html#references-paper-code","title":"References (paper + code)","text":"<ul> <li>Paper: https://arxiv.org/abs/2010.11929 (Dosovitskiy et al., 2020, An Image is Worth 16x16 Words)</li> <li>Code (Google research): https://github.com/google-research/vision_transformer</li> <li>Code (PyTorch models / baseline impls): https://github.com/rwightman/pytorch-image-models (timm)</li> </ul>"},{"location":"posts/vit-dit.html#dit-diffusion-transformer","title":"DiT (Diffusion Transformer)","text":""},{"location":"posts/vit-dit.html#core-idea_1","title":"Core idea","text":"<p>Diffusion models learn to denoise a noisy sample \\(x_t\\) at time \\(t\\). A DiT replaces the usual U-Net backbone with a Transformer that operates on tokenized image/latent representations.</p> <p>Typical training target choices include (depending on formulation):</p> <ul> <li>Predict noise \\(\\epsilon\\)</li> <li>Predict velocity \\(v\\)</li> <li>Predict the clean sample \\(x_0\\)</li> </ul> <p>The Transformer is conditioned on the diffusion timestep \\(t\\) (and sometimes on class labels / text embeddings). Conditioning is often injected via adaptive normalization (FiLM/AdaLN-style) rather than plain concatenation.</p> <p></p>"},{"location":"posts/vit-dit.html#what-to-pay-attention-to-implementation-details_1","title":"What to pay attention to (implementation details)","text":"<ul> <li>Tokenization: operate in pixel space or (more common) in VAE latent space (Stable Diffusion-style).</li> <li>Timestep conditioning: how \\(t\\) embeds and modulates blocks (often via AdaLN).</li> <li>Attention pattern: full attention vs windowed/local attention for high-resolution.</li> <li>Objective choice: \\(\\epsilon\\) vs \\(v\\) parameterization and how it affects stability/sampling.</li> </ul> <p>Minimal code sketch (DDPM-specific parts: timestep + conditioning injection):</p> <pre><code>import math\nimport torch\nimport torch.nn as nn\n\n\ndef timestep_embedding(t, dim, max_period=10000):\n    \"\"\"Sinusoidal embedding for diffusion timesteps.\n\n    t: (B,) int/float tensor\n    Returns: (B, dim)\n    \"\"\"\n    half = dim // 2\n    freqs = torch.exp(\n        -math.log(max_period) * torch.arange(0, half, device=t.device, dtype=torch.float32) / half\n    )\n    args = t.float()[:, None] * freqs[None]\n    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n    if dim % 2 == 1:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n    return emb\n\n\nclass AdaLN(nn.Module):\n    \"\"\"Adaptive LayerNorm: produces per-channel scale/shift from a condition vector.\"\"\"\n\n    def __init__(self, d_model, cond_dim):\n        super().__init__()\n        self.ln = nn.LayerNorm(d_model, elementwise_affine=False)\n        self.to_scale_shift = nn.Linear(cond_dim, 2 * d_model)\n\n    def forward(self, x, cond):\n        # x: (B, N, C), cond: (B, cond_dim)\n        x = self.ln(x)\n        s, b = self.to_scale_shift(cond).chunk(2, dim=-1)  # (B, C), (B, C)\n        return x * (1 + s[:, None, :]) + b[:, None, :]\n\n\nclass DiTBlock(nn.Module):\n    \"\"\"Encoder-style Transformer block with timestep/class conditioning via AdaLN.\n\n    This is the key structural difference vs a plain ViT block: the diffusion timestep (and optional semantic condition)\n    modulates normalization inside each block.\n    \"\"\"\n\n    def __init__(self, d_model, n_heads, d_ff, cond_dim, dropout=0.0):\n        super().__init__()\n        self.ada1 = AdaLN(d_model, cond_dim)\n        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n        self.ada2 = AdaLN(d_model, cond_dim)\n        self.mlp = nn.Sequential(\n            nn.Linear(d_model, d_ff),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_ff, d_model),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x, cond):\n        # x: (B, N, C)\n        a, _ = self.attn(self.ada1(x, cond), self.ada1(x, cond), self.ada1(x, cond), need_weights=False)\n        x = x + a\n        x = x + self.mlp(self.ada2(x, cond))\n        return x\n\n\nclass DiT(nn.Module):\n    \"\"\"Minimal DiT-like backbone (latent tokens -&gt; denoising prediction).\"\"\"\n\n    def __init__(self, d_model=768, depth=12, n_heads=12, d_ff=3072, n_classes=None, time_dim=256, dropout=0.0):\n        super().__init__()\n        cond_dim = time_dim\n        self.time_mlp = nn.Sequential(\n            nn.Linear(time_dim, cond_dim),\n            nn.SiLU(),\n            nn.Linear(cond_dim, cond_dim),\n        )\n        self.class_emb = nn.Embedding(n_classes, cond_dim) if n_classes is not None else None\n        self.blocks = nn.ModuleList(\n            [DiTBlock(d_model, n_heads, d_ff, cond_dim=cond_dim, dropout=dropout) for _ in range(depth)]\n        )\n        self.norm = nn.LayerNorm(d_model)\n        self.out = nn.Linear(d_model, d_model)  # placeholder: map tokens back to token-space prediction\n\n    def forward(self, x_tokens, t, y=None):\n        # x_tokens: (B, N, C) tokens of x_t (often VAE latents patchified)\n        cond = self.time_mlp(timestep_embedding(t, self.time_mlp[0].in_features))\n        if self.class_emb is not None and y is not None:\n            cond = cond + self.class_emb(y)\n        for blk in self.blocks:\n            x_tokens = blk(x_tokens, cond)\n        x_tokens = self.norm(x_tokens)\n        return self.out(x_tokens)\n\n\n# Notes:\n# - In a real diffusion model, x_tokens represent a noised sample x_t, and the output is interpreted as epsilon/v/x0 in the same space.\n# - The *DDPM-specific* part is the conditioning on t (and optional y/text) + the training/sampling process around this network.\n</code></pre> <p>Quick contrast vs VGG/CNNs (why this is a \u201cstructure\u201d story):</p> <ul> <li>VGG/CNNs bake in strong inductive biases (locality + translation equivariance via convolutions). ViT/DiT rely more on data/scale and attention\u2019s global mixing.</li> <li>ViT is usually a single-pass supervised encoder (classification/representation). DiT is used inside an iterative denoising procedure (DDPM/DDIM sampling), so the same network is called many times.</li> <li>The key DiT-specific knobs are timestep embedding \\(t\\), how conditioning is injected (AdaLN/FiLM vs cross-attention vs extra tokens), and which target you predict (\\(\\epsilon\\)/\\(v\\)/\\(x_0\\)).</li> </ul>"},{"location":"posts/vit-dit.html#references-paper-code_1","title":"References (paper + code)","text":"<ul> <li>Paper: https://arxiv.org/abs/2212.09748 (Peebles &amp; Xie, 2022, Scalable Diffusion Models with Transformers)</li> <li>Code (official-ish / common reference): https://github.com/facebookresearch/DiT</li> <li>Video: https://www.youtube.com/watch?v=vXtapCFctTI</li> </ul>"},{"location":"posts/vit-dit.html#file-references-inside-this-repo","title":"File references (inside this repo)","text":"<ul> <li>LLM/AR Transformer background: transformer.md</li> <li>Figures used by the Transformer note: assets/figures/</li> </ul>"},{"location":"posts/vit-dit.html#code-references-external","title":"Code references (external)","text":"<ul> <li>ViT implementations: timm ViT variants and Google\u2019s JAX reference (links above)</li> <li>DiT implementation: Meta\u2019s DiT repo (link above)</li> </ul>"},{"location":"posts/vit-dit.html#next-topics-to-expand-pick-one-per-installment","title":"Next topics to expand (pick one per installment)","text":"<ul> <li>ViT patch embedding math + positional embedding resizing</li> <li>ViT pretraining recipes (augmentation, regularization, distillation)</li> <li>Diffusion basics: forward/noise schedule and what the model predicts (\\(\\epsilon\\), \\(v\\), \\(x_0\\))</li> <li>DiT conditioning (AdaLN/FiLM) and why U-Nets were dominant historically</li> <li>Sampling: DDPM/DDIM and classifier-free guidance (CFG)</li> </ul>"}]}